{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U7w8uY9x9kC7",
        "ZC1HoI679mty",
        "81BF9V0hmbO6",
        "b3-Yj5ZtmoM1",
        "kW6Cc2ybRgME"
      ],
      "mount_file_id": "1dzGsvG03ZrTS-njcyAB2n2A3y_Aqy4mo",
      "authorship_tag": "ABX9TyMhyhz5vpdZmpUsxuoKZZ1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyanshuSheth/dialog-systems-evaluation/blob/main/gpt3_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r sample_data\n",
        "! pip -q install transformers\n",
        "! pip -q install pytorch-lightning\n",
        "! pip -q install datasets\n",
        "! pip -q install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZulggTpT0Py",
        "outputId": "90ae7e63-e206-4a9a-edaa-db9ce8d73005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 34.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 102.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 85.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 708 kB 12.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 66.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 431 kB 37.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 99.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 163 kB 69.6 MB/s \n",
            "\u001b[?25h  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from pytorch_lightning import seed_everything\n",
        "os.chdir(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation\")\n",
        "import openai\n",
        "RANDOM_SEED = 42\n",
        "seed_everything(RANDOM_SEED)\n",
        "# openai.api_key = \"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\" #1\n",
        "# openai.api_key = \"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\" #mum's phone\n",
        "# openai.api_key = \"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\" #colab1\n",
        "openai.api_key = \"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\" #colab2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz_LAuGeT171",
        "outputId": "e0e62c32-a5aa-4ab6-e4ba-250b7407d59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q \"http://shikib.com/tc_usr_data.json\" -O \"five_point_dialog_eval_tc_usr_data.json\"\n",
        "! wget -q \"http://shikib.com/pc_usr_data.json\" -O \"five_point_dialog_eval_pc_usr_data.json\""
      ],
      "metadata": {
        "id": "cHorayWrW1gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_tc_usr_data.json\", \"r\") as f1:\n",
        "    tc_usr_data = json.load(f1)\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_pc_usr_data.json\", \"r\") as f1:\n",
        "    pc_usr_data = json.load(f1)"
      ],
      "metadata": {
        "id": "Lx6yW9pxW1eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(pc_usr_data[0])"
      ],
      "metadata": {
        "id": "GnoF_yob0puZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_usr_data[0]['context'].split('\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz3r6b8RW1cE",
        "outputId": "c04dd4a1-eadd-46f6-f329-ff7efd6c0470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \", \" sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \", '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in tc_usr_data:\n",
        "    if len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        count += 1\n",
        "print(len(tc_usr_data))\n",
        "print(count)"
      ],
      "metadata": {
        "id": "uWUAdZ1r7roZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b7902e-e21b-446f-d592-168e4d7bbe09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each = tc_usr_data[0]\n",
        "print([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghv0x_bbDER0",
        "outputId": "31e3d965-4801-4439-d327-a4a5201d4dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"so , i 'm reading the latest film from studio ghibli is out the tale of princess kaguya . dunno if you 're familiar with them , but studio ghibli has made a lot of great animated films , like spirited away , and princess mononoke \", \" i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \", ' yeah , sadly , disney ( which owns the american rights to the films ) does n\\'t tend to promote them very much . i think they \\'re worried they \\'ll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they \\'re worth checking out . ', \" i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \", \" sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_tc_usr_data.json\", \"r\") as f1:\n",
        "    tc_usr_data = json.load(f1)\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_pc_usr_data.json\", \"r\") as f1:\n",
        "    pc_usr_data = json.load(f1)\n",
        "# tc_pc_combined_context4 = []\n",
        "tc_context4 = []\n",
        "pc_context4 = []\n",
        "for each in tc_usr_data:\n",
        "    if not len([p for p in each[\"context\"].split(\"\\n\") if p != \"\"]) < 4:\n",
        "        copy = each\n",
        "        copy[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"][-4:])\n",
        "        # print(each)\n",
        "        tc_context4.append(copy)\n",
        "    else:\n",
        "        tc_context4.append(each)\n",
        "for each in pc_usr_data:\n",
        "    if not len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        copy = each\n",
        "        copy[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"][-4:])\n",
        "        pc_context4.append(copy)\n",
        "    else:\n",
        "        pc_context4.append(each)\n",
        "\n",
        "for each in tc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        # print(each)\n",
        "for each in pc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        # print(each)"
      ],
      "metadata": {
        "id": "p9WTmbv88bCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in tc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        # each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        print(\"sda\")\n",
        "for each in pc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        # each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        print(\"sda\")"
      ],
      "metadata": {
        "id": "Dybc-eAtSD7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_context4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_context4, f1)\n",
        "with open(\"pc_context4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_context4, f1)"
      ],
      "metadata": {
        "id": "Ztyr4shVRcmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in tc_context4:\n",
        "    if each == None:\n",
        "        print('dsa')\n",
        "for each in pc_context4:\n",
        "    if each == None:\n",
        "        print('dsa')"
      ],
      "metadata": {
        "id": "tP0rLsbi-olW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in tc_context4:\n",
        "    print(len(each['context'].split(\"\\n\")))"
      ],
      "metadata": {
        "id": "bOfu5eaJ--tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in pc_context4:\n",
        "    print(len(each['context'].split(\"\\n\")))"
      ],
      "metadata": {
        "id": "qAfCSgtDFp5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_context4[4]['context'].split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzrR9_nr_L88",
        "outputId": "26b69671-a4e8-4a07-fa5d-c5465d7ecd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' i ve done it traveling , you ve got to really know the team and all of the players names . it was so much harder . ',\n",
              " ' do you have a favorite nfl team . like i said , i lived in dc for a while so kind of follow them . now in northern ohio , the browns are a difficult team to support . ',\n",
              " ' i feel you there , living in florida here . dolphins are hard to root for and feel proud . ',\n",
              " ' it could be worse , i read about this team that lost 220 - 0 . it would be hard to watch to the end . ']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_context4[6]['context'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4rd9kMf9C0x",
        "outputId": "18c1e333-21e2-4d2e-fb20-4cc9f11efc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey . where are you from ? i'm from a farm in wisconsin\n",
            "i love ice cream what is your favorite ? mine is chocolate\n",
            "mine is mint chocolate chip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in tc_pc_combined_context4:\n",
        "    if len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        count += 1\n",
        "print(len(tc_pc_combined_context4))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxyOoU6n9ET-",
        "outputId": "97d2ef5d-cb25-4b13-d8a3-e9208ce3b1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n",
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in pc_usr_data:\n",
        "    if len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        count += 1\n",
        "print(len(pc_usr_data))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XMLQ5Xy8T6T",
        "outputId": "ced06de1-8211-4594-d7da-c3260366d2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapoints_count = 0\n",
        "for each in tc_context4:\n",
        "    # print(len(each['responses']))\n",
        "    datapoints_count += len(each['responses'])\n",
        "print(datapoints_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZDw44_mD7qG",
        "outputId": "8fda95bd-980b-4461-e0fb-9f6c2d57d8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tc_context4[6][\"responses\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjwj50gfIYCR",
        "outputId": "3764fc2e-7112-430c-9b70-201e0b815c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapoints_count = 0\n",
        "for each in pc_context4:\n",
        "    # print(len(each['responses']))\n",
        "    datapoints_count += len(each['responses'])\n",
        "print(datapoints_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCQ93K_3IVE1",
        "outputId": "91e57dcb-1d10-475c-d1cc-e3e2c80a34f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pc_context4[5][\"responses\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Ur1jXoIb7T",
        "outputId": "f8f539d6-cd17-40fd-e291-02b9be33b23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tc_all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KWPre3wIiq6",
        "outputId": "0e2b643d-05ff-400d-be29-c3eab73c9bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_context4[0][\"fact\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUbJPqLpJZ3y",
        "outputId": "344718a6-a961-46a9-dbe3-549df1c24796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from left , emma baker , daniel saperstein and taylor mulitz of flasher will perform this summer 's final fort reno concert . ( jared soares for the washington post ) monday , july 30 25th birthday celebration at national postal museum : celebrate 25 years of this institution devoted to the long history of the u.s . postal service with daytime festivities that include cupcakes , birthday postcards , a photo booth and a special scavenger hunt with prizes . 11 a.m. to 2 p.m. free . tuesday , july 31 \" the color purple \" at kennedy center : the tony award - winning musical revival , based on the pulitzer prize - winning alice walker novel of the same name , features jazz , ragtime , gospel and blues with a story about an african american woman named celie surviving poverty in the south during the 1930s . through aug . 26 . $ 69-$149 . ask a harry potter scholar at southeast neighborhood library : come to this talk from tolanda henderson , a librarian from george washington university , who has used the j.k . rowling book series as a text in academia . commune with other muggles who prove that it 's not just kids and young adults who obsess about the boy who lived . 7 p.m. free . wednesday , aug . 1 rico nasty at the fillmore silver spring : two summers ago , rico nasty was a teenage loudmouth from the maryland suburbs , generating buzz on youtube for spitting surly , rainbow - tinted rhymes . now , after signing a deal with atlantic records , the 21-year - old singer is on her way to becoming one of the brightest voices in rap music .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pc_context4"
      ],
      "metadata": {
        "id": "nDvfN-FnJbt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_context4[0][\"fact\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El0ZFZFdI-F1",
        "outputId": "908559ce-65f2-4778-bff2-f7fa36ea298e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your persona: i also have a dog walking business.\n",
            "your persona: i've three dogs.\n",
            "your persona: my father was a door to door salesman.\n",
            "your persona: i am in an open polyamorous relationship.\n",
            "your persona: i like to watch the olympics.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_all_prompts[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ciIQDOaL_AC",
        "outputId": "77ca7bf2-bde9-4fc1-e0b8-295b0898cdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
            "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
            "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
            "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
            "\n",
            "Facts:\n",
            "the raiders sacked goff only once , on a play during which bruce irvin forced a fumble . other than that , the oakland defense could put almost no pressure on goff . the absence of mack , the former nfl defensive player of the year , was glaring . in the first half sunday night , mack had a sack , a forced fumble , a fumble recovery , an interception and a touchdown on defense . he and the bears could not sustain that , and they succumbed to the second - half exploits of packers quarterback aaron rodgers . but mack reinforced what a game - changing , difference - making player he is . he left little doubt that he is worth the six - year , $ 141 million contract given to him by the bears , making him the league 's highest - paid defensive player . [ the nfl teams that have serious reasons to worry , versus the ones that do n't ] mack , while still with the raiders , had been holding out , seeking such a deal . the raiders did n't want to give it to him . they have a $ 125 million quarterback in carr . they have a $ 100 million coach in gruden . they drew the line at handing out another mammoth deal , not wanting to further strain their budget or push the boundaries of the salary cap . they regarded the king 's ransom of draft picks put forth by the bears , including a pair of first - rounders , as an offer they could n't refuse . in truth , they could have refused it .\n",
            "\n",
            "Generated response: \n",
            "Person 1: i like the eagles . i think they are doing well this season .\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts[3])"
      ],
      "metadata": {
        "id": "G0zKudlFcUD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "print(pc_all_prompts[i] + pc_all_prompts[i + 1])"
      ],
      "metadata": {
        "id": "KynY5Jq5XuJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_likert_feedback(gpt3_feedback_format_texts, prefix=\"\"):\n",
        "    feedbacks = []\n",
        "    for each in gpt3_feedback_format_texts:\n",
        "        instance_prompt = prefix + each.rstrip()\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-002\",\n",
        "            prompt=instance_prompt,\n",
        "            temperature=0.1,\n",
        "            max_tokens=1000,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "        )\n",
        "        # print(each + response['choices'][0]['text'])\n",
        "        feedbacks.append(response['choices'][0]['text'])\n",
        "    return feedbacks"
      ],
      "metadata": {
        "id": "cGj0grMTfN7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prefix + all_prompts[0])"
      ],
      "metadata": {
        "id": "GvJLpAKBqcU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_prompts[100])"
      ],
      "metadata": {
        "id": "oei1EHfC8XTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts[0])"
      ],
      "metadata": {
        "id": "0rivsDqafVmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_prefix_twoshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1: lead singer for a band , music teacher\n",
        "Person 2: wow nice are you really good ?\n",
        "Person 1: millions of plays on soundcloud\n",
        "Person 2: really would you share or are you shy\n",
        "\n",
        "Facts:\n",
        "Person 1's statement: i also have a dog walking business.\n",
        "Person 1's statement: i've three dogs.\n",
        "Person 1's statement: my father was a door to door salesman.\n",
        "Person 1's statement: i am in an open polyamorous relationship.\n",
        "Person 1's statement: i like to watch the olympics.\n",
        "\n",
        "Generated response: \n",
        "Person 1: i know what you mean spend most nights cuddling my dog and star watching\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 1\n",
        "2. 3\n",
        "3. 1\n",
        "4. 3\n",
        "5. 1\n",
        "6. 2\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1: as long as i have my french fries !\n",
        "Person 2: well everyone can cheat once in a while\n",
        "Person 1: of course . now all of this has made me hungry .\n",
        "Person 2: you can go for some grub\n",
        "\n",
        "Facts:\n",
        "Person 1's statement: i like to take walks.\n",
        "Person 1's statement: i don't drink soda.\n",
        "Person 1's statement: i've a boyfriend.\n",
        "Person 1's statement: i like to eat hamburgers and french fries.\n",
        "\n",
        "Generated response: \n",
        "Person 1: maybe i'll take go for a walk and get a burger after .\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 1\n",
        "2. 3\n",
        "3. 3\n",
        "4. 1\n",
        "5. 5\"\"\""
      ],
      "metadata": {
        "id": "-28aUn4Jee_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_prefix_twoshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
        "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
        "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
        "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
        "\n",
        "Facts:\n",
        "from left , emma baker , daniel saperstein and taylor mulitz of flasher will perform this summer 's final fort reno concert . ( jared soares for the washington post ) monday , july 30 25th birthday celebration at national postal museum : celebrate 25 years of this institution devoted to the long history of the u.s . postal service with daytime festivities that include cupcakes , birthday postcards , a photo booth and a special scavenger hunt with prizes . 11 a.m. to 2 p.m. free . tuesday , july 31 \" the color purple \" at kennedy center : the tony award - winning musical revival , based on the pulitzer prize - winning alice walker novel of the same name , features jazz , ragtime , gospel and blues with a story about an african american woman named celie surviving poverty in the south during the 1930s . through aug . 26 . $ 69-$149 . ask a harry potter scholar at southeast neighborhood library : come to this talk from tolanda henderson , a librarian from george washington university , who has used the j.k . rowling book series as a text in academia . commune with other muggles who prove that it 's not just kids and young adults who obsess about the boy who lived . 7 p.m. free . wednesday , aug . 1 rico nasty at the fillmore silver spring : two summers ago , rico nasty was a teenage loudmouth from the maryland suburbs , generating buzz on youtube for spitting surly , rainbow - tinted rhymes . now , after signing a deal with atlantic records , the 21-year - old singer is on her way to becoming one of the brightest voices in rap music .\n",
        "\n",
        "Generated response: \n",
        "Person 1: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 1\n",
        "2. 3\n",
        "3. 3\n",
        "4. 3\n",
        "5. 1\n",
        "6. 5\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
        "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
        "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
        "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
        "\n",
        "Facts:\n",
        "the raiders sacked goff only once , on a play during which bruce irvin forced a fumble . other than that , the oakland defense could put almost no pressure on goff . the absence of mack , the former nfl defensive player of the year , was glaring . in the first half sunday night , mack had a sack , a forced fumble , a fumble recovery , an interception and a touchdown on defense . he and the bears could not sustain that , and they succumbed to the second - half exploits of packers quarterback aaron rodgers . but mack reinforced what a game - changing , difference - making player he is . he left little doubt that he is worth the six - year , $ 141 million contract given to him by the bears , making him the league 's highest - paid defensive player . [ the nfl teams that have serious reasons to worry , versus the ones that do n't ] mack , while still with the raiders , had been holding out , seeking such a deal . the raiders did n't want to give it to him . they have a $ 125 million quarterback in carr . they have a $ 100 million coach in gruden . they drew the line at handing out another mammoth deal , not wanting to further strain their budget or push the boundaries of the salary cap . they regarded the king 's ransom of draft picks put forth by the bears , including a pair of first - rounders , as an offer they could n't refuse . in truth , they could have refused it .\n",
        "\n",
        "Generated response: \n",
        "Person 1: i like a little bit . i have a lot of friends . i do nt have a team that great fans are a fan . i would like to know why they would do that .\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 0\n",
        "2. 1\n",
        "3. 1\n",
        "4. 1\n",
        "5. 0\n",
        "6. 1\"\"\""
      ],
      "metadata": {
        "id": "5COp05fWj8fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_all_prompts[9])"
      ],
      "metadata": {
        "id": "Vn9lhRFxlBtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_all_prompts[1])"
      ],
      "metadata": {
        "id": "RCH6Aoy5kBaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pc_all_prompts[10:100])"
      ],
      "metadata": {
        "id": "XbfdagR8h0yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tc_context4[0][\"responses\"]))"
      ],
      "metadata": {
        "id": "eQcw_lr1l7wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result_part1 = get_likert_feedback(pc_all_prompts[10:100], pc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "yuXISB9LhL22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result_part1 = get_likert_feedback(tc_all_prompts[12:112], tc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "XM6pbelhl5YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pc_result_part1.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_result_part1, f1)"
      ],
      "metadata": {
        "id": "Llf4qNeNosaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_result_part1.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part1, f1)"
      ],
      "metadata": {
        "id": "KTu1VyVjYN4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result_part2 = get_likert_feedback(pc_all_prompts[100:190], pc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "kGXWP3sXiTC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result_part2 = get_likert_feedback(tc_all_prompts[112:170], tc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "LnEKyu72mq9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pc_result_part2.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_result_part2, f1)"
      ],
      "metadata": {
        "id": "vsowbibzZAIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_result_part2.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part2, f1)"
      ],
      "metadata": {
        "id": "tSOtleZsmuZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result_part3 = get_likert_feedback(pc_all_prompts[190:300], pc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "f9fYv4ekjaV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pc_result_part3.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_result_part3, f1)"
      ],
      "metadata": {
        "id": "ZOXyLxRLZFE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result_part31 = get_likert_feedback(tc_all_prompts[170:200], tc_prefix_twoshot)\n",
        "time.sleep(60)\n",
        "tc_result_part32 = get_likert_feedback(tc_all_prompts[200:230], tc_prefix_twoshot)\n",
        "tc_result_part3 = tc_result_part31 + tc_result_part32\n",
        "with open(\"tc_result_part3.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part3, f1)\n",
        "time.sleep(60)\n",
        "tc_result_part41 = get_likert_feedback(tc_all_prompts[230:260], tc_prefix_twoshot)\n",
        "time.sleep(60)\n",
        "tc_result_part42 = get_likert_feedback(tc_all_prompts[260:290], tc_prefix_twoshot)\n",
        "tc_result_part4 = tc_result_part41 + tc_result_part42\n",
        "with open(\"tc_result_part4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part4, f1)"
      ],
      "metadata": {
        "id": "AcWJcUdCnvr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(60)\n",
        "tc_result_part51 = get_likert_feedback(tc_all_prompts[290:320], tc_prefix_twoshot)\n",
        "time.sleep(60)\n",
        "tc_result_part52 = get_likert_feedback(tc_all_prompts[320:], tc_prefix_twoshot)\n",
        "tc_result_part5 = tc_result_part51 + tc_result_part52\n",
        "with open(\"tc_result_part5.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part5, f1)"
      ],
      "metadata": {
        "id": "EJ3Nd8PGostz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result = pc_result_part1 + pc_result_part2 + pc_result_part3"
      ],
      "metadata": {
        "id": "12eesM-oYupL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result = tc_result_part1 + tc_result_part2 + tc_result_part3 + tc_result_part4 + tc_result_part5"
      ],
      "metadata": {
        "id": "0XvdkXYwozU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_prefix_twoshot + pc_all_prompts[9])"
      ],
      "metadata": {
        "id": "cNq505IKg7hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts[9])"
      ],
      "metadata": {
        "id": "55g1cZmVgm_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_a1a2a3(all_labels, result):\n",
        "    annotator_1 = []\n",
        "    annotator_2 = []\n",
        "    annotator_3 = []\n",
        "    for each in all_labels:\n",
        "        a1_here = []\n",
        "        a2_here = []\n",
        "        a3_here = []\n",
        "        for e in each:\n",
        "            a1_here.append(e[0])\n",
        "            a2_here.append(e[1])\n",
        "            a3_here.append(e[2])\n",
        "        annotator_1.append(a1_here)\n",
        "        annotator_2.append(a2_here)\n",
        "        annotator_3.append(a3_here)\n",
        "    return annotator_1, annotator_2, annotator_3"
      ],
      "metadata": {
        "id": "s3htltMn96cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_all_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WyicKvrcKtg",
        "outputId": "eb6a1d32-4238-4a55-fbd9-debc9e234ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1], [3, 3, 3], [3, 3, 3], [1, 2, 1], [0, 0, 0], [3, 4, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flG_brh4cIRl",
        "outputId": "fd6a0a2b-939e-48c4-89ac-35bd6960e56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 3, 3, 1, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1, a2, a3 = get_a1a2a3(pc_all_labels[10:300], pc_result)"
      ],
      "metadata": {
        "id": "PD9kiDRnAeQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1, a2, a3 = get_a1a2a3(tc_all_labels[12:360], tc_result)"
      ],
      "metadata": {
        "id": "MoVfIcDqvwqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_result_predictions(result):\n",
        "    all_preds = []\n",
        "    for each in result:\n",
        "        splits = each.split(\"\\n\")[1:]\n",
        "        predictions = [int(p[-1]) for p in splits]\n",
        "        all_preds.append(predictions)\n",
        "    return all_preds"
      ],
      "metadata": {
        "id": "QKkTxTuuCZy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = get_result_predictions(pc_result)"
      ],
      "metadata": {
        "id": "KTz31i8PDGRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = get_result_predictions(tc_result)"
      ],
      "metadata": {
        "id": "u0GERGZYv2yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1_q1 = [each[0] for each in a1]\n",
        "a1_q2 = [each[1] for each in a1]\n",
        "a1_q3 = [each[2] for each in a1]\n",
        "a1_q4 = [each[3] for each in a1]\n",
        "a1_q5 = [each[4] for each in a1]\n",
        "a1_q6 = [each[5] for each in a1]\n",
        "\n",
        "a2_q1 = [each[0] for each in a2]\n",
        "a2_q2 = [each[1] for each in a2]\n",
        "a2_q3 = [each[2] for each in a2]\n",
        "a2_q4 = [each[3] for each in a2]\n",
        "a2_q5 = [each[4] for each in a2]\n",
        "a2_q6 = [each[5] for each in a2]\n",
        "\n",
        "a3_q1 = [each[0] for each in a3]\n",
        "a3_q2 = [each[1] for each in a3]\n",
        "a3_q3 = [each[2] for each in a3]\n",
        "a3_q4 = [each[3] for each in a3]\n",
        "a3_q5 = [each[4] for each in a3]\n",
        "a3_q6 = [each[5] for each in a3]\n",
        "\n",
        "preds_q1 = [each[0] for each in all_preds]\n",
        "preds_q2 = [each[1] for each in all_preds]\n",
        "preds_q3 = [each[2] for each in all_preds]\n",
        "preds_q4 = [each[3] for each in all_preds]\n",
        "preds_q5 = [each[4] for each in all_preds]\n",
        "preds_q6 = [each[4] for each in all_preds]\n",
        "\n",
        "avg_q1 = [(p + q + r) / 3 for p, q, r in zip(a1_q1, a2_q1, a3_q1)]\n",
        "avg_q2 = [(p + q + r) / 3 for p, q, r in zip(a1_q2, a2_q2, a3_q2)]\n",
        "avg_q3 = [(p + q + r) / 3 for p, q, r in zip(a1_q3, a2_q3, a3_q3)]\n",
        "avg_q4 = [(p + q + r) / 3 for p, q, r in zip(a1_q4, a2_q4, a3_q4)]\n",
        "avg_q5 = [(p + q + r) / 3 for p, q, r in zip(a1_q5, a2_q5, a3_q5)]\n",
        "avg_q6 = [(p + q + r) / 3 for p, q, r in zip(a1_q6, a2_q6, a3_q6)]"
      ],
      "metadata": {
        "id": "D9QXSP0iDoqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_q1"
      ],
      "metadata": {
        "id": "ZVt5DkZUbKE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b, c in zip(a1_q1, a2_q1, a3_q1):\n",
        "    print(a, b, c)"
      ],
      "metadata": {
        "id": "gp7AutIVac-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in all_prompts[36:72]:\n",
        "    print(each)"
      ],
      "metadata": {
        "id": "IX-CZ6m2JbM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot TC\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685a9a8f-34cf-46df-cad7-027c87c89bc0",
        "id": "U9Oe3LTGwaps"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  0.27439242143985465\n",
            "p =  1.9879625220522456e-07\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.334544070993657\n",
            "p =  1.5152099326200143e-10\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.31702533060441584\n",
            "p =  1.4529195844553958e-09\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.38310134474756563\n",
            "p =  1.3077732149719403e-13\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.5207202296292283\n",
            "p =  1.4081152879378415e-25\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.44192629542108725\n",
            "p =  4.5344950005935225e-18\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot TC\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208b638b-676a-49ba-8881-0f3918093ffc",
        "id": "vMvgbIMSwaps"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  0.26636125681997547\n",
            "p =  4.597017877523339e-07\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.32436415028537324\n",
            "p =  5.7358477955303e-10\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.31058464198509994\n",
            "p =  3.2179272216892623e-09\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.3515321357715196\n",
            "p =  1.4701022970810943e-11\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.5276249389291235\n",
            "p =  2.4724414945777766e-26\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.44240844151950665\n",
            "p =  4.1328351059246755e-18\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot PC\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy3hCTRIbVgo",
        "outputId": "1f90d2eb-d53c-42de-99ef-39385bed14a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  0.001987256992043949\n",
            "p =  0.9731198554098119\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.3796573439048053\n",
            "p =  2.238772236339354e-11\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.42120532910187497\n",
            "p =  6.711196774591265e-14\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.2564979136932833\n",
            "p =  9.717737938515492e-06\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.47661744686295093\n",
            "p =  7.469723156893223e-18\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.5236070064165446\n",
            "p =  8.122723895575865e-22\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot PC\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0qUgmQMeFbx",
        "outputId": "8a2e8efc-95ce-40ef-e23f-5e648ab40b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  -0.010621345273839438\n",
            "p =  0.8570749352156075\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.38470138000725124\n",
            "p =  1.1538979684068542e-11\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.43842256638155735\n",
            "p =  4.726455044586849e-15\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.20937012546191983\n",
            "p =  0.0003307866781860974\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.46790083832213636\n",
            "p =  3.497698902104082e-17\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.5128384528035694\n",
            "p =  7.461495239602863e-21\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}