{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WOo3yMBdBiMc",
        "3YN57Ed3zfwA",
        "SCb0yf9Fyzya"
      ],
      "mount_file_id": "1th0LmiTOa9PjUelZg3UeynvhEvIZvFKP",
      "authorship_tag": "ABX9TyOTmGW4SwSfATKH4nYeTcPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f23810630a8b4443837af97796ecc45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b614f10e1af461bb0828124d2f8a25a",
              "IPY_MODEL_1bed825117dc411fbf5d4e8416d9cc33",
              "IPY_MODEL_fd6c68f7257c487498fc41987000b78c"
            ],
            "layout": "IPY_MODEL_67384a55ff984d12b8f57ea7a6e93a0b"
          }
        },
        "4b614f10e1af461bb0828124d2f8a25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d65ff9fc5274a42953d9dc81f5433e7",
            "placeholder": "​",
            "style": "IPY_MODEL_ed2a912e2899480dafe19ee410a45298",
            "value": ""
          }
        },
        "1bed825117dc411fbf5d4e8416d9cc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34db7bc35c544ad18abf0ae8004634db",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba0108758df14802a60a237f97328688",
            "value": 0
          }
        },
        "fd6c68f7257c487498fc41987000b78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566d1fa7db0a4a829c4058c4939c1f10",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac5e2de835e4f838210c4d99ac1296d",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "67384a55ff984d12b8f57ea7a6e93a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d65ff9fc5274a42953d9dc81f5433e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2a912e2899480dafe19ee410a45298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34db7bc35c544ad18abf0ae8004634db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ba0108758df14802a60a237f97328688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "566d1fa7db0a4a829c4058c4939c1f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac5e2de835e4f838210c4d99ac1296d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12dd627a357e4aadaa94d446a728cc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48705b0fceab476885eff627428b9518",
              "IPY_MODEL_28ad9831d5184727b0dcc9e737f0d727",
              "IPY_MODEL_f4d1827914524f00a0dc9263f39dc43f"
            ],
            "layout": "IPY_MODEL_e3d5721cc5e549b4b291a0eb1e5b44e9"
          }
        },
        "48705b0fceab476885eff627428b9518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952795bb81d2412baf5d9f59775f0e54",
            "placeholder": "​",
            "style": "IPY_MODEL_147d74777d824fb78d5dd43c8c58bbe6",
            "value": "Downloading: 100%"
          }
        },
        "28ad9831d5184727b0dcc9e737f0d727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c6f5ad09934375ac83422a67a7d572",
            "max": 222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbed481764024ad7bbbd8f6fa7546c1d",
            "value": 222
          }
        },
        "f4d1827914524f00a0dc9263f39dc43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db2c71585e84aec9ae278c8b65f42db",
            "placeholder": "​",
            "style": "IPY_MODEL_9d9b34ebf15c4104a1a67cc615332ec8",
            "value": " 222/222 [00:00&lt;00:00, 6.73kB/s]"
          }
        },
        "e3d5721cc5e549b4b291a0eb1e5b44e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952795bb81d2412baf5d9f59775f0e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147d74777d824fb78d5dd43c8c58bbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c6f5ad09934375ac83422a67a7d572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbed481764024ad7bbbd8f6fa7546c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3db2c71585e84aec9ae278c8b65f42db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d9b34ebf15c4104a1a67cc615332ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6eea0f6b52149ae90cfac0d9d06db01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53501bc048a64e70a673f8f2b7e58718",
              "IPY_MODEL_d247d718598f40e59e61113708058352",
              "IPY_MODEL_8f5bc2d8c08a420a83d18d5fa6779949"
            ],
            "layout": "IPY_MODEL_7716d9761d0b4a76b8c21e4e7085cdbe"
          }
        },
        "53501bc048a64e70a673f8f2b7e58718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c59a42d65144ada405a3c60816ca2d",
            "placeholder": "​",
            "style": "IPY_MODEL_df00517a9d194c9d92105bcd3998dd49",
            "value": "Downloading: 100%"
          }
        },
        "d247d718598f40e59e61113708058352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6595ad303874c3aa9e4282116e1e598",
            "max": 14500438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfe57bdda43e4b83a77eb9790cd00439",
            "value": 14500438
          }
        },
        "8f5bc2d8c08a420a83d18d5fa6779949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61c1a95560d4dc08ea24f4e07e0f4f1",
            "placeholder": "​",
            "style": "IPY_MODEL_3191a63890484b00b7d386090681a8d3",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 33.9MB/s]"
          }
        },
        "7716d9761d0b4a76b8c21e4e7085cdbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c59a42d65144ada405a3c60816ca2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df00517a9d194c9d92105bcd3998dd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6595ad303874c3aa9e4282116e1e598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe57bdda43e4b83a77eb9790cd00439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e61c1a95560d4dc08ea24f4e07e0f4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3191a63890484b00b7d386090681a8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c165cf56584e4760b87f845f8f267e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aad8ea102e3e4f70995357a26b99dcc1",
              "IPY_MODEL_188282d5d81245f7a70290bb7100adee",
              "IPY_MODEL_1d501f61d20743288acaa71588efc998"
            ],
            "layout": "IPY_MODEL_ba26cdac76764dbebb336f199019c873"
          }
        },
        "aad8ea102e3e4f70995357a26b99dcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e88564dad9499fa84515e0d5344b8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e0db174c60ab499eadebfc4c15c49d65",
            "value": "Downloading: 100%"
          }
        },
        "188282d5d81245f7a70290bb7100adee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853d7f8b43bb49dab7ceb5428cd48f07",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9de6599b63d54291b35c34303978f8fa",
            "value": 85
          }
        },
        "1d501f61d20743288acaa71588efc998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096444d5998e4152b825344d95bd6491",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d33e406b2f4a6f80d68007ad087f23",
            "value": " 85.0/85.0 [00:00&lt;00:00, 2.73kB/s]"
          }
        },
        "ba26cdac76764dbebb336f199019c873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e88564dad9499fa84515e0d5344b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0db174c60ab499eadebfc4c15c49d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "853d7f8b43bb49dab7ceb5428cd48f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de6599b63d54291b35c34303978f8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "096444d5998e4152b825344d95bd6491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d33e406b2f4a6f80d68007ad087f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86825ac4395c43b5b868dd1e58177be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1c6f1701cec4d04bb45661f90681ad7",
              "IPY_MODEL_ab177ef17a004bc29785cbcf7a21c694",
              "IPY_MODEL_4a07adb2d6f848c7b85d0bcaa2aaf1a8"
            ],
            "layout": "IPY_MODEL_d04f6e22e04849c59c16b741ea7a374f"
          }
        },
        "e1c6f1701cec4d04bb45661f90681ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752b40210dea407fbad70017a2c31950",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb690543c33495397518cdb081622c0",
            "value": "Downloading: 100%"
          }
        },
        "ab177ef17a004bc29785cbcf7a21c694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f6209277ad4a178ab43c97cbbe2b2a",
            "max": 710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7910ea1364a449f0816cf9ecae227608",
            "value": 710
          }
        },
        "4a07adb2d6f848c7b85d0bcaa2aaf1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94192cddf19847a0b7fc3c995e3c5b9c",
            "placeholder": "​",
            "style": "IPY_MODEL_e640c3b60d1b48a6a579c64b91faea79",
            "value": " 710/710 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "d04f6e22e04849c59c16b741ea7a374f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752b40210dea407fbad70017a2c31950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb690543c33495397518cdb081622c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f6209277ad4a178ab43c97cbbe2b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7910ea1364a449f0816cf9ecae227608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94192cddf19847a0b7fc3c995e3c5b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e640c3b60d1b48a6a579c64b91faea79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d503f8c8c4e47a8a0e85504a40b353d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4444bb6f7a80414e8d6e077a34692bc8",
              "IPY_MODEL_119135e7a95c4fb8907951f766be6f80",
              "IPY_MODEL_9c127d6f936d47a89406070c9fb1c99a"
            ],
            "layout": "IPY_MODEL_707fd6df8f2b45598c7f8d71cf42f4c1"
          }
        },
        "4444bb6f7a80414e8d6e077a34692bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0026c32cc2f41eeb587ea97a89ed7e8",
            "placeholder": "​",
            "style": "IPY_MODEL_0b700844997e48d7bdf8f02f4c024268",
            "value": "Downloading: 100%"
          }
        },
        "119135e7a95c4fb8907951f766be6f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76af1fdd5a45496c8132f63107280429",
            "max": 1118531895,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed16a9cc2adc45d9b43ba7757d15b174",
            "value": 1118531895
          }
        },
        "9c127d6f936d47a89406070c9fb1c99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729b18457ca247a896a4305d85c7d6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_805031bd3ef54063b059e34921c2f126",
            "value": " 1.12G/1.12G [00:28&lt;00:00, 57.2MB/s]"
          }
        },
        "707fd6df8f2b45598c7f8d71cf42f4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0026c32cc2f41eeb587ea97a89ed7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b700844997e48d7bdf8f02f4c024268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76af1fdd5a45496c8132f63107280429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed16a9cc2adc45d9b43ba7757d15b174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "729b18457ca247a896a4305d85c7d6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805031bd3ef54063b059e34921c2f126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyanshuSheth/dialog-systems-evaluation/blob/main/run_gpt2_lm_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6FC-FMDBrBq",
        "outputId": "f8aa1c8d-4f00-4811-9d2f-a3bd4748a671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 68.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 708 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 24.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 22.6 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 431 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 73.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 68.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! rm -r sample_data\n",
        "! pip -q install transformers\n",
        "! pip -q install pytorch-lightning\n",
        "! pip -q install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from pytorch_lightning import seed_everything\n",
        "import pickle as pkl\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "os.chdir(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation\")\n",
        "RANDOM_SEED = 42\n",
        "seed_everything(RANDOM_SEED)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "YTHRiW_GB2VR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "f23810630a8b4443837af97796ecc45a",
            "4b614f10e1af461bb0828124d2f8a25a",
            "1bed825117dc411fbf5d4e8416d9cc33",
            "fd6c68f7257c487498fc41987000b78c",
            "67384a55ff984d12b8f57ea7a6e93a0b",
            "0d65ff9fc5274a42953d9dc81f5433e7",
            "ed2a912e2899480dafe19ee410a45298",
            "34db7bc35c544ad18abf0ae8004634db",
            "ba0108758df14802a60a237f97328688",
            "566d1fa7db0a4a829c4058c4939c1f10",
            "9ac5e2de835e4f838210c4d99ac1296d"
          ]
        },
        "outputId": "31afefb3-5021-45bb-d79c-d808edabf34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f23810630a8b4443837af97796ecc45a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompts Training**"
      ],
      "metadata": {
        "id": "6EWCZyQmVy2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\"\"\""
      ],
      "metadata": {
        "id": "Et0uv1m1kmYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/tc_all_prompts.pkl\", \"rb\") as f1:\n",
        "    tc_all_prompts = pkl.load(f1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/tc_all_labels.pkl\", \"rb\") as f1:\n",
        "    tc_all_labels = pkl.load(f1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/pc_all_prompts.pkl\", \"rb\") as f1:\n",
        "    pc_all_prompts = pkl.load(f1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/pc_all_labels.pkl\", \"rb\") as f1:\n",
        "    pc_all_labels = pkl.load(f1)\n",
        "\n",
        "pc_all_prompts_labelled = [-1] * len(pc_all_prompts)\n",
        "tc_all_prompts_labelled = [-1] * len(tc_all_prompts)\n",
        "for i, each in enumerate(pc_all_prompts):\n",
        "    prompt_here = pc_all_prompts[i]\n",
        "    label_1 = round(np.mean(np.array(pc_all_labels[i][0])))\n",
        "    label_2 = round(np.mean(np.array(pc_all_labels[i][1])))\n",
        "    label_3 = round(np.mean(np.array(pc_all_labels[i][2])))\n",
        "    label_4 = round(np.mean(np.array(pc_all_labels[i][3])))\n",
        "    label_5 = round(np.mean(np.array(pc_all_labels[i][4])))\n",
        "    label_6 = round(np.mean(np.array(pc_all_labels[i][5])))\n",
        "    # all_prompts[i] = prefix + each + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Overall Quality: {str(label_5)}\"\n",
        "    # pc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Uses Knowledge: {str(label_5)}\\n6. Overall Quality: {str(label_6)}\"\n",
        "    pc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. {str(label_1)}\\n2. {str(label_2)}\\n3. {str(label_3)}\\n4. {str(label_4)}\\n5. {str(label_5)}\\n6. {str(label_6)}\"\n",
        "\n",
        "for i, each in enumerate(tc_all_prompts):\n",
        "    prompt_here = tc_all_prompts[i]\n",
        "    label_1 = round(np.mean(np.array(tc_all_labels[i][0])))\n",
        "    label_2 = round(np.mean(np.array(tc_all_labels[i][1])))\n",
        "    label_3 = round(np.mean(np.array(tc_all_labels[i][2])))\n",
        "    label_4 = round(np.mean(np.array(tc_all_labels[i][3])))\n",
        "    label_5 = round(np.mean(np.array(tc_all_labels[i][4])))\n",
        "    label_6 = round(np.mean(np.array(tc_all_labels[i][5])))\n",
        "    # all_prompts[i] = prefix + each + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Overall Quality: {str(label_5)}\"\n",
        "    # tc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Uses Knowledge: {str(label_5)}\\n6. Overall Quality: {str(label_6)}\"\n",
        "    tc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. {str(label_1)}\\n2. {str(label_2)}\\n3. {str(label_3)}\\n4. {str(label_4)}\\n5. {str(label_5)}\\n6. {str(label_6)}\""
      ],
      "metadata": {
        "id": "EEpo1Yk4V2-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts_labelled[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yfLe0zl2hln",
        "outputId": "b04b96c5-053f-4f6b-d6fe-6b063b430c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "Person 1: lead singer for a band , music teacher\n",
            "Person 2: wow nice are you really good ?\n",
            "Person 1: millions of plays on soundcloud\n",
            "Person 2: really would you share or are you shy\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i also have a dog walking business.\n",
            "Person 1's statement: i've three dogs.\n",
            "Person 1's statement: my father was a door to door salesman.\n",
            "Person 1's statement: i am in an open polyamorous relationship.\n",
            "Person 1's statement: i like to watch the olympics.\n",
            "\n",
            "Generated response: \n",
            "Person 1: ha ha i'm so shy\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n",
            "1. 1\n",
            "2. 3\n",
            "3. 3\n",
            "4. 1\n",
            "5. 0\n",
            "6. 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPTNeoForCausalLM, GPTNeoModel, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import random\n",
        "from torch import cuda\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "skcyesH4ZwRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to a fixed value to get reproducible results \n",
        "# torch.manual_seed(42)\n",
        "# Download the pre-trained GPT-Neo model's tokenizer\n",
        "# Add the custom tokens denoting the beginning and the end \n",
        "# of the sequence and a special token for padding\n",
        "\n",
        "# model_checkpoint = \"gpt2-medium\"\n",
        "# model_checkpoint = \"gpt2-large\"\n",
        "model_checkpoint = \"bigscience/bloom-560m\"\n",
        "# model_checkpoint = \"bigscience/bloom-1b1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint,\n",
        "#                             bos_token=\"<|startoftext|>\",\n",
        "#                             eos_token=\"<|endoftext|>\",\n",
        "#                             pad_token=\"<|pad|>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "12dd627a357e4aadaa94d446a728cc47",
            "48705b0fceab476885eff627428b9518",
            "28ad9831d5184727b0dcc9e737f0d727",
            "f4d1827914524f00a0dc9263f39dc43f",
            "e3d5721cc5e549b4b291a0eb1e5b44e9",
            "952795bb81d2412baf5d9f59775f0e54",
            "147d74777d824fb78d5dd43c8c58bbe6",
            "51c6f5ad09934375ac83422a67a7d572",
            "bbed481764024ad7bbbd8f6fa7546c1d",
            "3db2c71585e84aec9ae278c8b65f42db",
            "9d9b34ebf15c4104a1a67cc615332ec8",
            "e6eea0f6b52149ae90cfac0d9d06db01",
            "53501bc048a64e70a673f8f2b7e58718",
            "d247d718598f40e59e61113708058352",
            "8f5bc2d8c08a420a83d18d5fa6779949",
            "7716d9761d0b4a76b8c21e4e7085cdbe",
            "88c59a42d65144ada405a3c60816ca2d",
            "df00517a9d194c9d92105bcd3998dd49",
            "b6595ad303874c3aa9e4282116e1e598",
            "bfe57bdda43e4b83a77eb9790cd00439",
            "e61c1a95560d4dc08ea24f4e07e0f4f1",
            "3191a63890484b00b7d386090681a8d3",
            "c165cf56584e4760b87f845f8f267e55",
            "aad8ea102e3e4f70995357a26b99dcc1",
            "188282d5d81245f7a70290bb7100adee",
            "1d501f61d20743288acaa71588efc998",
            "ba26cdac76764dbebb336f199019c873",
            "c7e88564dad9499fa84515e0d5344b8e",
            "e0db174c60ab499eadebfc4c15c49d65",
            "853d7f8b43bb49dab7ceb5428cd48f07",
            "9de6599b63d54291b35c34303978f8fa",
            "096444d5998e4152b825344d95bd6491",
            "d9d33e406b2f4a6f80d68007ad087f23"
          ]
        },
        "outputId": "e51cb88d-baf3-4fb8-85fe-3f9b3ccb8c53",
        "id": "oc72dGqRZwRp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12dd627a357e4aadaa94d446a728cc47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6eea0f6b52149ae90cfac0d9d06db01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c165cf56584e4760b87f845f8f267e55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_checkpoint).to(device)\n",
        "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "# Resize the token embeddings because we've just added 3 new tokens \n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "86825ac4395c43b5b868dd1e58177be9",
            "e1c6f1701cec4d04bb45661f90681ad7",
            "ab177ef17a004bc29785cbcf7a21c694",
            "4a07adb2d6f848c7b85d0bcaa2aaf1a8",
            "d04f6e22e04849c59c16b741ea7a374f",
            "752b40210dea407fbad70017a2c31950",
            "4cb690543c33495397518cdb081622c0",
            "a6f6209277ad4a178ab43c97cbbe2b2a",
            "7910ea1364a449f0816cf9ecae227608",
            "94192cddf19847a0b7fc3c995e3c5b9c",
            "e640c3b60d1b48a6a579c64b91faea79",
            "1d503f8c8c4e47a8a0e85504a40b353d",
            "4444bb6f7a80414e8d6e077a34692bc8",
            "119135e7a95c4fb8907951f766be6f80",
            "9c127d6f936d47a89406070c9fb1c99a",
            "707fd6df8f2b45598c7f8d71cf42f4c1",
            "b0026c32cc2f41eeb587ea97a89ed7e8",
            "0b700844997e48d7bdf8f02f4c024268",
            "76af1fdd5a45496c8132f63107280429",
            "ed16a9cc2adc45d9b43ba7757d15b174",
            "729b18457ca247a896a4305d85c7d6ae",
            "805031bd3ef54063b059e34921c2f126"
          ]
        },
        "outputId": "a18832f6-376a-4b30-991a-c9b68c8e9d32",
        "id": "Yr3ZG4kIZwRp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86825ac4395c43b5b868dd1e58177be9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d503f8c8c4e47a8a0e85504a40b353d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc_lines = tc_all_prompts_labelled\n",
        "pc_lines = pc_all_prompts_labelled\n",
        "max_length = 1024\n",
        "tc_descriptions = [description for description in tc_lines if len(tokenizer.encode(description)) < max_length-2]\n",
        "pc_descriptions = [description for description in pc_lines if len(tokenizer.encode(description)) < max_length-2]\n",
        "pc_max_length = max([len(tokenizer.encode(description)) for description in pc_descriptions])\n",
        "tc_max_length = max([len(tokenizer.encode(description)) for description in tc_descriptions])\n",
        "print(pc_max_length)\n",
        "print(len(pc_descriptions))\n",
        "print(tc_max_length)\n",
        "print(len(tc_descriptions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb700a1-d754-400b-c130-4bec3f5c90b6",
        "id": "9K5q_6cUZwRq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "300\n",
            "823\n",
            "360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptsDataset(Dataset):\n",
        "    def __init__(self, txt_list, tokenizer, max_length):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        for txt in txt_list:\n",
        "            # Encode the descriptions using the GPT-Neo tokenizer\n",
        "            encodings_dict = tokenizer(\"<|startoftext|>\" \n",
        "                                        + txt +    \n",
        "                                        \"<|endoftext|>\",\n",
        "                                        truncation=True,\n",
        "                                        max_length=max_length, \n",
        "                                        padding='max_length')\n",
        "            input_ids = torch.tensor(encodings_dict['input_ids'])    \n",
        "            self.input_ids.append(input_ids)\n",
        "            mask = torch.tensor(encodings_dict['attention_mask'])\n",
        "            self.attn_masks.append(mask)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "\n",
        "tc_dataset = PromptsDataset(tc_descriptions, tokenizer, max_length)\n",
        "pc_dataset = PromptsDataset(pc_descriptions, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "yUJVak-5ZwRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_train_size = int(0.7 * len(pc_dataset))\n",
        "tc_train_size = int(0.7 * len(tc_dataset))\n",
        "\n",
        "pc_train_dataset, pc_trainval_dataset = random_split(pc_dataset, \n",
        "                            [pc_train_size, len(pc_dataset) - pc_train_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "pc_test_size = int(0.5 * len(pc_trainval_dataset))\n",
        "pc_test_dataset, pc_val_dataset = random_split(pc_trainval_dataset, \n",
        "                            [pc_test_size, len(pc_trainval_dataset) - pc_test_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_train_dataset, tc_trainval_dataset = random_split(tc_dataset, \n",
        "                            [tc_train_size, len(tc_dataset) - tc_train_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "tc_test_size = int(0.5 * len(tc_trainval_dataset))\n",
        "tc_test_dataset, tc_val_dataset = random_split(tc_trainval_dataset, \n",
        "                            [tc_test_size, len(tc_trainval_dataset) - tc_test_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "# test_size = int(0.5 * len(trainval_dataset))\n",
        "# val_dataset, test_dataset = random_split(trainval_dataset, [test_size, len(trainval_dataset) - test_size])\n",
        "# train_dataset = dataset"
      ],
      "metadata": {
        "id": "OEHmBxgtZwRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, pc_unlabelled_trainval = random_split(pc_all_prompts,\n",
        "                                         [pc_train_size, len(pc_dataset) - pc_train_size],\n",
        "                                         generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "pc_unlabelled_test, pc_unlabelled_val = random_split(pc_unlabelled_trainval,\n",
        "                                                     [pc_test_size, len(pc_trainval_dataset) - pc_test_size],\n",
        "                                                     generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "_, tc_unlabelled_trainval = random_split(tc_all_prompts, \n",
        "                                         [tc_train_size, len(tc_dataset) - tc_train_size],\n",
        "                                         generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_unlabelled_test, tc_unlabelled_val = random_split(tc_unlabelled_trainval, \n",
        "                                                     [tc_test_size, len(tc_trainval_dataset) - tc_test_size],\n",
        "                                                     generator=torch.Generator().manual_seed(RANDOM_SEED))"
      ],
      "metadata": {
        "id": "n5MZgdh9KSbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tc_train_dataset[0][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "GsC8MQXLK-pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_val_labels[4])"
      ],
      "metadata": {
        "id": "K80Glz5zLB0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_train_labels, pc_trainval_labels = random_split(pc_all_labels, \n",
        "                                              [pc_train_size, len(pc_dataset) - pc_train_size],\n",
        "                                              generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "pc_test_labels, pc_val_labels = random_split(pc_trainval_labels,\n",
        "                                             [pc_test_size, len(pc_trainval_labels) - pc_test_size],\n",
        "                                             generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_train_labels, tc_trainval_labels = random_split(tc_all_labels, \n",
        "                                              [tc_train_size, len(tc_dataset) - tc_train_size],\n",
        "                                              generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_test_labels, tc_val_labels = random_split(tc_trainval_labels,\n",
        "                                             [tc_test_size, len(tc_trainval_labels) - tc_test_size],\n",
        "                                             generator=torch.Generator().manual_seed(RANDOM_SEED))"
      ],
      "metadata": {
        "id": "PbSp1fKc7xkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_val_labels[0])"
      ],
      "metadata": {
        "id": "zTNji17x9J-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(pc_train_dataset[0][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "FI10fVDz86go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tc_train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c17WTC0nXTs_",
        "outputId": "adb60ae2-49f5-4707-e02a-bbc4beab4292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pc_train_dataset))\n",
        "print(len(tc_train_dataset))"
      ],
      "metadata": {
        "id": "c6jc3c_D4umW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tc_pc_concatdataset[251][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "5PwM_mErXMuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_pc_concatdataset = torch.utils.data.ConcatDataset([tc_train_dataset, pc_train_dataset])"
      ],
      "metadata": {
        "id": "UHhqY0_jW_Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.5e-5\n",
        "bs=10\n",
        "ne=4\n",
        "training_args = TrainingArguments(output_dir=f'bloom-tc-medium-lm-lr{lr}-bs{bs}-ne{ne}',\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  num_train_epochs=ne,\n",
        "                                  learning_rate=lr,\n",
        "                                  save_strategy='epoch',\n",
        "                                  evaluation_strategy='epoch',\n",
        "                                #   logging_steps=200,\n",
        "                                #   save_steps =1000,\n",
        "                                  per_device_train_batch_size=1,\n",
        "                                  gradient_accumulation_steps=bs,\n",
        "                                #   per_device_eval_batch_size=2,\n",
        "                                #   warmup_steps=500,\n",
        "                                  weight_decay=0.01,  \n",
        "                                  load_best_model_at_end=True,\n",
        "                                  fp16=True,\n",
        "                                  )\n",
        "                                #   logging_dir='./logs')"
      ],
      "metadata": {
        "id": "lMe7W26tZwRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=training_args,  \n",
        "                  train_dataset=tc_pc_concatdataset,\n",
        "                  eval_dataset=tc_val_dataset, \n",
        "                  # This custom collate function is necessary \n",
        "                  # to built batches of data\n",
        "                  data_collator=lambda data: \n",
        "              {'input_ids': torch.stack([f[0] for f in data]),       \n",
        "               'attention_mask': torch.stack([f[1] for f in data]),\n",
        "               'labels': torch.stack([f[0] for f in data])}\n",
        "                 )"
      ],
      "metadata": {
        "id": "hy2VO_zPZwRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabcf9f4-61e3-4c4a-bf6c-76788afffebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training process!\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "913e235b-b4c5-40cc-a430-a00a00be6eea",
        "id": "Uk5CViMgZwRr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 461\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
            "  Gradient Accumulation steps = 10\n",
            "  Total optimization steps = 184\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  8/184 00:30 < 14:46, 0.20 it/s, Epoch 0.15/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-482882979b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start training process!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m         )\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bloom/modeling_bloom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             loss = loss_fct(\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0mshift_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             )\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 980.00 MiB (GPU 0; 14.76 GiB total capacity; 13.44 GiB already allocated; 199.75 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = f'gpt2-tc-medium-lm-lr{lr}-bs{bs}-ne{ne}/checkpoint-46'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
        "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "# Resize the token embeddings because we've just added 3 new tokens \n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Lr4gEjsC13",
        "outputId": "0236dd88-a8e3-4f75-f755-276681f645ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"pad_token_id\": 50258,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50259\n",
            "}\n",
            "\n",
            "loading weights file gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each = \"\"\"Context:\n",
        "Person 1:  the guy is a machine! but he needs a better stage name. maybe president banana? \n",
        "Person 2:  i do not think the president of zimbabwe would be happy about that \n",
        "Person 1:  he could be the artist formerly known as president banana? i don't really care as long as i can listen to him on the radio! i love two things on my radio : indonesian pop music and electromagnetic storms from jupiter. those are my go to listening pleasures! \n",
        "Person 2:  yeah that is so cool that if you turn your radio to am, you may capture jupiter's storms \n",
        "\n",
        "Facts:\n",
        "according to canadian law, all radios are required to have at least 40 % of the music played be canadian.\n",
        "\n",
        "Generated response: \n",
        "Person 1: that might be banned in canada. the law says that all stations must have 40 % of the music played be canadian!\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "\"\"\"\n",
        "tokenized = tokenizer(each)\n",
        "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
        "if len(input_ids[0]) < 1000:\n",
        "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
        "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmIOa_VMPDJD",
        "outputId": "5f2e0fdf-d7a8-4ae8-b43d-0a3140d97405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "Person 1:  the guy is a machine! but he needs a better stage name. maybe president banana? \n",
            "Person 2:  i do not think the president of zimbabwe would be happy about that \n",
            "Person 1:  he could be the artist formerly known as president banana? i don't really care as long as i can listen to him on the radio! i love two things on my radio : indonesian pop music and electromagnetic storms from jupiter. those are my go to listening pleasures! \n",
            "Person 2:  yeah that is so cool that if you turn your radio to am, you may capture jupiter's storms \n",
            "\n",
            "Facts:\n",
            "according to canadian law, all radios are required to have at least 40 % of the music played be canadian.\n",
            "\n",
            "Generated response: \n",
            "Person 1: that might be banned in canada. the law says that all stations must have 40 % of the music played be canadian!\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n",
            "1. Understandable\n",
            "2. Natural\n",
            "3. Maintains Context\n",
            "4. Interesting\n",
            "5. Uses Knowledge\n",
            "6. Overall Quality\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tc_train_dataset[0][0], skip_special_tokens=True)[-200:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lYwqK4VSdE-7",
        "outputId": "91147a3b-28c8-4f0c-daee-8db3ced709d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:\\n1. 1\\n2. 2\\n3. 2\\n4. 3\\n5. 1\\n6. 4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc_unlabelled_test[0][-200:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oD198sdYcThx",
        "outputId": "168da023-6fd3-4461-fba2-32fa5340e120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e is conditioned on, how well does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc_test_dataset = tc_unlabelled_test\n",
        "for i, each in enumerate(tc_test_dataset):\n",
        "    # print(each)\n",
        "    tokenized = tokenizer(each + \"\\n\")\n",
        "    input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
        "    input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "    if len(input_ids[0]) < 1000:\n",
        "        generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=3, temperature=0.1)\n",
        "        print(f\"\\nnum = {i}\")\n",
        "        print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0].replace(input_text, \"\"))"
      ],
      "metadata": {
        "id": "HYUmEFNS2-Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = \"hey there\"\n",
        "tokenized = tokenizer(str1)\n",
        "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
        "generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
        "print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlv1pLA_ubRQ",
        "outputId": "16834113-5d0e-4431-9cc9-8787b2d3db96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey theres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([test_dataset[0][0].tolist()]).to(device)\n",
        "if len(input_ids[0]) < 1000:\n",
        "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=24, num_beams=5)\n",
        "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "9pmHEgrOy6Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(test_dataset[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btRopY8m1QSa",
        "outputId": "b603d1e1-b070-448c-9b96-578c1380d9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startoftext|> Human Evaluation of Chatbot Outputs:\n",
            "\n",
            "Annotation Instructions: \n",
            "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
            "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
            "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
            "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
            "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
            "Interesting (1 - 3): Is the response dull/interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
            "Overall Quality (1 - 5): Given your answers above, what is your overall impression of this utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  i did see the movie, i thought it was bad as well, i liked the book better, i like reading you can learn many interesting facts, like why the area code of new york is 212. \n",
            "Person 2:  ya i think it was because that was the fastest number that you could dial with a rotary phone? crazy how that stuff carries over until even today!! \n",
            "Person 1:  it is! there s a lot things we need to discover still though, i'm kind of worried the cables carrying phone and internet are underwater, at least some of them. \n",
            "Person 2:  ya it's only about 3 inches thick, i wonder how it is protected? is it just a cable or are there safeguards in place in case like a ship sinks and crushes it, etc \n",
            "\n",
            "Generated response: \n",
            "Agent: i think that is a good idea, i think it would be a great idea to put flamethrowers on the back of cars in south africa\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
            "\n",
            "Answers:\n",
            "1. Understandable: 0\n",
            "2. Natural: 2\n",
            "3. Maintains Context: 1\n",
            "4. Interesting: 2\n",
            "5. Overall Quality: 2<|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each in test_dataset:\n",
        "    input_ids = torch.tensor([each[0].tolist()]).to('cuda')\n",
        "    if len(input_ids[0]) < 1000:\n",
        "        outputs = model.generate(input_ids, do_sample=False, max_new_tokens=24, num_beams=5)\n",
        "        print(str(tokenizer.decode(input_ids[0])))\n",
        "        model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        print(model_response)\n",
        "        print(\"\\n\")\n",
        "    else:\n",
        "        print(len(input_ids[0]))"
      ],
      "metadata": {
        "id": "c1rBCbBzbpiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized['input_ids']"
      ],
      "metadata": {
        "id": "Kk5JXW4ntE2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "# prompt = \"hey there\"\n",
        "# tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "# input_ids = tokenized['input_ids'].to('cuda')\n",
        "\n",
        "outputs = model.generate(torch.tensor([test_dataset[0][0].tolist()]).to('cuda'), do_sample=False, max_new_tokens=100, num_beams=5)\n",
        "print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "# feedback_starts = model_response.find(\"Feedback: \")\n",
        "print(\"Model Response: \" + model_response)\n",
        "# print()"
      ],
      "metadata": {
        "id": "gmkS1KZMrJgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avR-qFFKtCCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}