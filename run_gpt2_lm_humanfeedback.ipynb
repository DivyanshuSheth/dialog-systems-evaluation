{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WOo3yMBdBiMc",
        "3YN57Ed3zfwA",
        "SCb0yf9Fyzya"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9c74091f19c481e967f06f1ef6ce981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82c9be9a1b90487f8ee741af45f5e05f",
              "IPY_MODEL_2f700370ef604df4881336e918ab906e",
              "IPY_MODEL_1825fd705f714186ac49743cd576eb92"
            ],
            "layout": "IPY_MODEL_333eaf8ab0a24f7fa7499f73b4e3fcb9"
          }
        },
        "82c9be9a1b90487f8ee741af45f5e05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd0245a35104950b83f8f8bb91acfed",
            "placeholder": "​",
            "style": "IPY_MODEL_829d20f0d5904440b196b85ea84a4506",
            "value": "Downloading data files: 100%"
          }
        },
        "2f700370ef604df4881336e918ab906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ddd905b6bcf43c384841b53db3c632e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4def9a8ceb2e4e08bb8384fb95614a76",
            "value": 1
          }
        },
        "1825fd705f714186ac49743cd576eb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33fcb927b254937bb072d9d2f8533f9",
            "placeholder": "​",
            "style": "IPY_MODEL_bc11acfa4f6b4e6b8c17a11cd3c05099",
            "value": " 1/1 [00:00&lt;00:00, 12.47it/s]"
          }
        },
        "333eaf8ab0a24f7fa7499f73b4e3fcb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd0245a35104950b83f8f8bb91acfed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829d20f0d5904440b196b85ea84a4506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ddd905b6bcf43c384841b53db3c632e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4def9a8ceb2e4e08bb8384fb95614a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b33fcb927b254937bb072d9d2f8533f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc11acfa4f6b4e6b8c17a11cd3c05099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94c5015e8cc3474998cd6a8a6e5a32d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d9681c98de24b8f804ef7d7cf93e032",
              "IPY_MODEL_613cb3fabcaa462d9f03222922da9ee6",
              "IPY_MODEL_e7f8d642bb8743c2af6503631a4b1a91"
            ],
            "layout": "IPY_MODEL_590e151d9f824e49bfa58a0517d12f4d"
          }
        },
        "8d9681c98de24b8f804ef7d7cf93e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd45c0efda241d5b026aa38cd91da15",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7fa1518cb44fba8d3696d0cfb1dfd5",
            "value": "Extracting data files: 100%"
          }
        },
        "613cb3fabcaa462d9f03222922da9ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e32e1e7a74412ca30329d88a3413d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_134944f66dab46eba01682db155b84c4",
            "value": 1
          }
        },
        "e7f8d642bb8743c2af6503631a4b1a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_171afbec907943c290154c7a0aea6850",
            "placeholder": "​",
            "style": "IPY_MODEL_ead807fce2f842149bd27f20eb75be20",
            "value": " 1/1 [00:00&lt;00:00, 16.56it/s]"
          }
        },
        "590e151d9f824e49bfa58a0517d12f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd45c0efda241d5b026aa38cd91da15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7fa1518cb44fba8d3696d0cfb1dfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7e32e1e7a74412ca30329d88a3413d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134944f66dab46eba01682db155b84c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "171afbec907943c290154c7a0aea6850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead807fce2f842149bd27f20eb75be20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0711fd4d2a041ec8fad03a59b8a38fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa40560c473d4d3dabebe4672d3902e5",
              "IPY_MODEL_ef22e76e69a145e49e61c0c6c22737db",
              "IPY_MODEL_95f4330e861347c595dfcc4feef0f07e"
            ],
            "layout": "IPY_MODEL_2385f11dc42449cda7ce251d86b0535b"
          }
        },
        "aa40560c473d4d3dabebe4672d3902e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_083100aa8a664989a9eca81cd6980b89",
            "placeholder": "​",
            "style": "IPY_MODEL_bec0940282b4417294f258b5e88eafa9",
            "value": ""
          }
        },
        "ef22e76e69a145e49e61c0c6c22737db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912c048483d548059678d235ca3da8f6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e196dad83ba43e5830ffba259dcb573",
            "value": 1
          }
        },
        "95f4330e861347c595dfcc4feef0f07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_809e7db338c4426e9a3ad2cc054d6949",
            "placeholder": "​",
            "style": "IPY_MODEL_7e5c8096d54d4e8e9dc4575501fd5886",
            "value": " 1/? [00:00&lt;00:00,  7.97 tables/s]"
          }
        },
        "2385f11dc42449cda7ce251d86b0535b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083100aa8a664989a9eca81cd6980b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec0940282b4417294f258b5e88eafa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "912c048483d548059678d235ca3da8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7e196dad83ba43e5830ffba259dcb573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "809e7db338c4426e9a3ad2cc054d6949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e5c8096d54d4e8e9dc4575501fd5886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2024de4ba0ba4e71a36eebffc9c4b8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19f3c5847b3847f3836e711f3bd336e9",
              "IPY_MODEL_b93242eb7cf344f29e5fc81a98679e7f",
              "IPY_MODEL_ccda1eba7b244957bcd7f610f08c895d"
            ],
            "layout": "IPY_MODEL_89ba8340f8e84070be3997141f86fd36"
          }
        },
        "19f3c5847b3847f3836e711f3bd336e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e47a176a1fe641f6b2ba16fca66040be",
            "placeholder": "​",
            "style": "IPY_MODEL_672a5cd6da8046e0bcffdeaf5e315cc2",
            "value": "100%"
          }
        },
        "b93242eb7cf344f29e5fc81a98679e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561e553790fa4c92a07c0aa9d7caf9f6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f994b26cb7d84954bc72bddb8d10fc75",
            "value": 1
          }
        },
        "ccda1eba7b244957bcd7f610f08c895d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2524d8e07afe45a08866c33e8e973c31",
            "placeholder": "​",
            "style": "IPY_MODEL_55af1939ebb7494898991b943388581a",
            "value": " 1/1 [00:00&lt;00:00, 20.67it/s]"
          }
        },
        "89ba8340f8e84070be3997141f86fd36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47a176a1fe641f6b2ba16fca66040be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672a5cd6da8046e0bcffdeaf5e315cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "561e553790fa4c92a07c0aa9d7caf9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f994b26cb7d84954bc72bddb8d10fc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2524d8e07afe45a08866c33e8e973c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55af1939ebb7494898991b943388581a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e4ce9ce5084a72a91967c48a2a9c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0cf0bcf6e6743a9aabcc29eed7e99dd",
              "IPY_MODEL_ca4ce730d64b470c92886f1ceda51195",
              "IPY_MODEL_d6244f29aa9a4e58a3c290dc6d146cc1"
            ],
            "layout": "IPY_MODEL_510cc8304ba942d0920d87eed8cc71c7"
          }
        },
        "e0cf0bcf6e6743a9aabcc29eed7e99dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b9bd9a606d40ca8e33ad320432ad9e",
            "placeholder": "​",
            "style": "IPY_MODEL_134367c5b230449ba09957da1ad6b008",
            "value": "#0: 100%"
          }
        },
        "ca4ce730d64b470c92886f1ceda51195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482999039c744f2c8246e25cb34df9f5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5c86887901d42d281d76836358eec5c",
            "value": 1
          }
        },
        "d6244f29aa9a4e58a3c290dc6d146cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_708bab5f490644e2a6ae0e79ba3c6b96",
            "placeholder": "​",
            "style": "IPY_MODEL_e770d8c986f14e2a9228d6a7623e4b90",
            "value": " 1/1 [00:00&lt;00:00,  2.65ba/s]"
          }
        },
        "510cc8304ba942d0920d87eed8cc71c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b9bd9a606d40ca8e33ad320432ad9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134367c5b230449ba09957da1ad6b008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482999039c744f2c8246e25cb34df9f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c86887901d42d281d76836358eec5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "708bab5f490644e2a6ae0e79ba3c6b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e770d8c986f14e2a9228d6a7623e4b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e832a0e93a844ed3b6fbdf0ab78889de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c355a6e90d744032a5217d560b81d210",
              "IPY_MODEL_a36f4987c7b94e2a8366615658069426",
              "IPY_MODEL_77548506eaae4017a5ebc73c801e95ea"
            ],
            "layout": "IPY_MODEL_d30d710756c84c6a971ca539b9285f99"
          }
        },
        "c355a6e90d744032a5217d560b81d210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55cc0b2a61d47c897ab92d3899aa2d2",
            "placeholder": "​",
            "style": "IPY_MODEL_edd55aa67f6743f6b3fb75ee5377981f",
            "value": "#1: 100%"
          }
        },
        "a36f4987c7b94e2a8366615658069426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2cbcadd0b64869ab8d37783c301e5f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba3aad1b833749988f951a7485a5104e",
            "value": 1
          }
        },
        "77548506eaae4017a5ebc73c801e95ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54f933b97ac4917b02441200963feaf",
            "placeholder": "​",
            "style": "IPY_MODEL_dd960ddacd064b45bb0b10898e51cd62",
            "value": " 1/1 [00:00&lt;00:00,  3.24ba/s]"
          }
        },
        "d30d710756c84c6a971ca539b9285f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55cc0b2a61d47c897ab92d3899aa2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd55aa67f6743f6b3fb75ee5377981f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b2cbcadd0b64869ab8d37783c301e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3aad1b833749988f951a7485a5104e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c54f933b97ac4917b02441200963feaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd960ddacd064b45bb0b10898e51cd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5fe24d78a548dcad4eb9c7e01693ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf736c8c91534295baf7eae905e08ea9",
              "IPY_MODEL_3ea750a36678401abdc699b08b07d148",
              "IPY_MODEL_602abc5f3bd94b1d98bbbb48b448e4ef"
            ],
            "layout": "IPY_MODEL_24b0c17229b548ceb0585f5d12b6559d"
          }
        },
        "bf736c8c91534295baf7eae905e08ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5269869bba6e4fb5b1a1c4c1b7c4841e",
            "placeholder": "​",
            "style": "IPY_MODEL_a1620c788a5a4e0ab31391c19da80d3c",
            "value": "#2: 100%"
          }
        },
        "3ea750a36678401abdc699b08b07d148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233ca54da4004003abd8f86f1f6f1521",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1c653402e4b41b3b1ed196028d97ecc",
            "value": 1
          }
        },
        "602abc5f3bd94b1d98bbbb48b448e4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6610221a381c415a88201c3a58f87715",
            "placeholder": "​",
            "style": "IPY_MODEL_6141f737a9b9435cbe298cddd3097903",
            "value": " 1/1 [00:00&lt;00:00,  3.01ba/s]"
          }
        },
        "24b0c17229b548ceb0585f5d12b6559d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5269869bba6e4fb5b1a1c4c1b7c4841e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1620c788a5a4e0ab31391c19da80d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233ca54da4004003abd8f86f1f6f1521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c653402e4b41b3b1ed196028d97ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6610221a381c415a88201c3a58f87715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6141f737a9b9435cbe298cddd3097903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "355f7b40296d4e508c12e201ab2cacb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c83e13cb94d547ebad263ebb0017b94f",
              "IPY_MODEL_d62137bbe77848e5bd5240cd6bcf4d64",
              "IPY_MODEL_cca195c5a0ca42cfb01ef3dc781ff636"
            ],
            "layout": "IPY_MODEL_80766dafedb84a859c09dc7bb965cd3e"
          }
        },
        "c83e13cb94d547ebad263ebb0017b94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7fe58bec7b54ee283d7ef43c99ac228",
            "placeholder": "​",
            "style": "IPY_MODEL_c749bad82a0948c89e7b58d8e23da3e0",
            "value": "#3: 100%"
          }
        },
        "d62137bbe77848e5bd5240cd6bcf4d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c506bd413cf4f82bceaaaf612ea67cd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e248fc9aff64037898e823072639a61",
            "value": 1
          }
        },
        "cca195c5a0ca42cfb01ef3dc781ff636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b0036908034e68b6d972879cf7ab20",
            "placeholder": "​",
            "style": "IPY_MODEL_d6d1a33af9274d9aa4f2350c469e49fa",
            "value": " 1/1 [00:00&lt;00:00,  3.84ba/s]"
          }
        },
        "80766dafedb84a859c09dc7bb965cd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7fe58bec7b54ee283d7ef43c99ac228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c749bad82a0948c89e7b58d8e23da3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c506bd413cf4f82bceaaaf612ea67cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e248fc9aff64037898e823072639a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59b0036908034e68b6d972879cf7ab20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d1a33af9274d9aa4f2350c469e49fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4243a5b835b04bd4be85391ec7771c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea0d590c4630431693421ba02684c96a",
              "IPY_MODEL_b47f486f7ae041d5b59d74bcf5bf662c",
              "IPY_MODEL_c8b6240da69f4da9a73ce86d10d4e7d7"
            ],
            "layout": "IPY_MODEL_109ff6b0181b498f9d63a5c5c2acba5f"
          }
        },
        "ea0d590c4630431693421ba02684c96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a923a640002745cc8376d8de76f0c112",
            "placeholder": "​",
            "style": "IPY_MODEL_00235ff03f204c1698d59ace4661eb8c",
            "value": "Downloading config.json: 100%"
          }
        },
        "b47f486f7ae041d5b59d74bcf5bf662c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847c76a70dbc4e15a909a2dac135cb97",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3153af15c3f44e9bc1e82d302262b69",
            "value": 666
          }
        },
        "c8b6240da69f4da9a73ce86d10d4e7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb1b3d0fe96a4dc58f691fb8e3d465b9",
            "placeholder": "​",
            "style": "IPY_MODEL_946a1aa4f81b4046abec4063aceb60fe",
            "value": " 666/666 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "109ff6b0181b498f9d63a5c5c2acba5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a923a640002745cc8376d8de76f0c112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00235ff03f204c1698d59ace4661eb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847c76a70dbc4e15a909a2dac135cb97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3153af15c3f44e9bc1e82d302262b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb1b3d0fe96a4dc58f691fb8e3d465b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946a1aa4f81b4046abec4063aceb60fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e010a06ffc65464b9fba7b547d7f9961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90ad4aa12adf461abebfad658fe87cd5",
              "IPY_MODEL_732708e5fae84874acab9019e6f4676c",
              "IPY_MODEL_758e895da63840a8902e3cb9669b6c2a"
            ],
            "layout": "IPY_MODEL_7b9428c5e726430f91e017bac2e49288"
          }
        },
        "90ad4aa12adf461abebfad658fe87cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605a0785e0904590a2213e161ef32a71",
            "placeholder": "​",
            "style": "IPY_MODEL_cff418fad5b14765ae27cfbacbd39663",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "732708e5fae84874acab9019e6f4676c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cf8a5dc1deb4e199f40974ba02dac0e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_549829ea1a784e8bbd2565024a3a7a5d",
            "value": 1042301
          }
        },
        "758e895da63840a8902e3cb9669b6c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f464663cd74721a390e50f374edf40",
            "placeholder": "​",
            "style": "IPY_MODEL_4be0311605f947398017f5c07b06dbfe",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 13.2MB/s]"
          }
        },
        "7b9428c5e726430f91e017bac2e49288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605a0785e0904590a2213e161ef32a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff418fad5b14765ae27cfbacbd39663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf8a5dc1deb4e199f40974ba02dac0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549829ea1a784e8bbd2565024a3a7a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45f464663cd74721a390e50f374edf40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be0311605f947398017f5c07b06dbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8036287008c943f498491d605f3a1455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30cdf027eb954626b77d96fb99bb6a10",
              "IPY_MODEL_c34f11f3d1a74e2185ba47ea6f6b7fda",
              "IPY_MODEL_3295ba043ab24aa6ac7f02f8e0747a72"
            ],
            "layout": "IPY_MODEL_6dee7daa313242f4840ae94ce7906abc"
          }
        },
        "30cdf027eb954626b77d96fb99bb6a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe15ec7e91ea423985cd7235d1831231",
            "placeholder": "​",
            "style": "IPY_MODEL_4c047bc8539043c8ab8de1ad72122375",
            "value": "Downloading merges.txt: 100%"
          }
        },
        "c34f11f3d1a74e2185ba47ea6f6b7fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f42ce4c3afd4f4188268bd76c981fda",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bd2a91e467348459f2156bc93af48ae",
            "value": 456318
          }
        },
        "3295ba043ab24aa6ac7f02f8e0747a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_666fc6b1eef047069916e6eac03b6c01",
            "placeholder": "​",
            "style": "IPY_MODEL_57ae4070908f42309d5cb6159d93b403",
            "value": " 446k/446k [00:00&lt;00:00, 8.28MB/s]"
          }
        },
        "6dee7daa313242f4840ae94ce7906abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe15ec7e91ea423985cd7235d1831231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c047bc8539043c8ab8de1ad72122375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f42ce4c3afd4f4188268bd76c981fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd2a91e467348459f2156bc93af48ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "666fc6b1eef047069916e6eac03b6c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ae4070908f42309d5cb6159d93b403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4716b9707c2c4bcdb761b266e2cf4f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e7edbc25124497fa5621f819cef3a9b",
              "IPY_MODEL_8af9aefc572042a2b9d3cd13b3be7c9b",
              "IPY_MODEL_6f5f7827f87847a39a23a3a6e76e4950"
            ],
            "layout": "IPY_MODEL_5c64e18c181946719f6233f52cea77d8"
          }
        },
        "7e7edbc25124497fa5621f819cef3a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5940e0e668d4979b76170884ab9f9d5",
            "placeholder": "​",
            "style": "IPY_MODEL_070eed96a3754741b2aa1a55e06406d8",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "8af9aefc572042a2b9d3cd13b3be7c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bfea5c60eca47a188f5ee4f47427cea",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6340dc9bfd954690963b3afb732bc3c1",
            "value": 1355256
          }
        },
        "6f5f7827f87847a39a23a3a6e76e4950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35723e6b86e3459f8612aa909f9d457e",
            "placeholder": "​",
            "style": "IPY_MODEL_61a8ba182e6d4862a42ff8e315c46df3",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 15.2MB/s]"
          }
        },
        "5c64e18c181946719f6233f52cea77d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5940e0e668d4979b76170884ab9f9d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070eed96a3754741b2aa1a55e06406d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bfea5c60eca47a188f5ee4f47427cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6340dc9bfd954690963b3afb732bc3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35723e6b86e3459f8612aa909f9d457e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a8ba182e6d4862a42ff8e315c46df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14882e3ffbdf4079b0bb212b57fa2ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7445f3a402e5450288d1f2b2f6f55075",
              "IPY_MODEL_10e6230ff978468e97669b7f4d90a528",
              "IPY_MODEL_3c0455a208cb4fb6a4439645c490ed0c"
            ],
            "layout": "IPY_MODEL_7dada12071ee43b1a4f7d8be64263ee4"
          }
        },
        "7445f3a402e5450288d1f2b2f6f55075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3162c072dca4494a4a3dade399babc3",
            "placeholder": "​",
            "style": "IPY_MODEL_acd6b98dcd064c5bb64034addcfc39e8",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "10e6230ff978468e97669b7f4d90a528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5f7970eaa0433e94deadfa69378a71",
            "max": 3247202234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7788893cc6b4e8988b93e00ccdc01ce",
            "value": 3247202234
          }
        },
        "3c0455a208cb4fb6a4439645c490ed0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d221f4bdaa4b89b2f43abc6eb94c56",
            "placeholder": "​",
            "style": "IPY_MODEL_c5ab47084fae4b7eadae856940afd9b3",
            "value": " 3.02G/3.02G [01:00&lt;00:00, 58.3MB/s]"
          }
        },
        "7dada12071ee43b1a4f7d8be64263ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3162c072dca4494a4a3dade399babc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd6b98dcd064c5bb64034addcfc39e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa5f7970eaa0433e94deadfa69378a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7788893cc6b4e8988b93e00ccdc01ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25d221f4bdaa4b89b2f43abc6eb94c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ab47084fae4b7eadae856940afd9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbbc9c6bfbc5466c9adc632efddaa69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d14f2418f88b43a79cb23aff11e07ea8",
              "IPY_MODEL_ab16a12ebc0b4823b169736dc6fad547",
              "IPY_MODEL_26d2f01050a9451593b8cef942d152b2"
            ],
            "layout": "IPY_MODEL_a518f507662f495687f8c25f1bbd323c"
          }
        },
        "d14f2418f88b43a79cb23aff11e07ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc6958e9ec84ddcbb2e407eea40c6ab",
            "placeholder": "​",
            "style": "IPY_MODEL_7296c6eb14db4fcba8650a9a4d32b7ab",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ab16a12ebc0b4823b169736dc6fad547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c835b97d99d457395560c12f0258738",
            "max": 3247202234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e38bbe073ab40b4b403e50b37e85263",
            "value": 3247202234
          }
        },
        "26d2f01050a9451593b8cef942d152b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5af26fbe60342258f50234e98ba8fce",
            "placeholder": "​",
            "style": "IPY_MODEL_ba476b0bb57b493a863b5e94ff0d4024",
            "value": " 3.02G/3.02G [01:04&lt;00:00, 56.3MB/s]"
          }
        },
        "a518f507662f495687f8c25f1bbd323c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc6958e9ec84ddcbb2e407eea40c6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7296c6eb14db4fcba8650a9a4d32b7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c835b97d99d457395560c12f0258738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e38bbe073ab40b4b403e50b37e85263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5af26fbe60342258f50234e98ba8fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba476b0bb57b493a863b5e94ff0d4024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b7c33b5f4d4433ea02f0ff536dcd8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4088ab35b9e949f29e87737f6d93be8e",
              "IPY_MODEL_c6fd3bbb0e484992ba74cc5a2b75c23e",
              "IPY_MODEL_ed966bda924d469e91a04cfc7f4cba6c"
            ],
            "layout": "IPY_MODEL_0c4074906db348f6889354df5c398838"
          }
        },
        "4088ab35b9e949f29e87737f6d93be8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425b801047544094bfdfaab6708ed2bc",
            "placeholder": "​",
            "style": "IPY_MODEL_45abfa4dff5d4367a0567cc2745f099d",
            "value": "Downloading: 100%"
          }
        },
        "c6fd3bbb0e484992ba74cc5a2b75c23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f731a4e31604dd2a3d2b4a8034aacf6",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb5aef16180c4062b312c05620585dc7",
            "value": 1042301
          }
        },
        "ed966bda924d469e91a04cfc7f4cba6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f63ca3f0093479ab8fc7a3fe28d065b",
            "placeholder": "​",
            "style": "IPY_MODEL_43caad81600b4b7d816112a7f4f80112",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 1.14MB/s]"
          }
        },
        "0c4074906db348f6889354df5c398838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425b801047544094bfdfaab6708ed2bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45abfa4dff5d4367a0567cc2745f099d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f731a4e31604dd2a3d2b4a8034aacf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5aef16180c4062b312c05620585dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f63ca3f0093479ab8fc7a3fe28d065b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43caad81600b4b7d816112a7f4f80112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5f8534225cf40959e06a73b70dceb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e5124391c7d4271b96a0b046f8b20d7",
              "IPY_MODEL_6ffa40d768284956a0b4f106d4d7b104",
              "IPY_MODEL_197b8637d8644d79b12f46cc774e9499"
            ],
            "layout": "IPY_MODEL_e4f685c474e24075887fed1ea5c41001"
          }
        },
        "7e5124391c7d4271b96a0b046f8b20d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67217d27424e4f0986034e25ef6ffd36",
            "placeholder": "​",
            "style": "IPY_MODEL_c38003e6c5794c77b9e23c31f1fc12f0",
            "value": "Downloading: 100%"
          }
        },
        "6ffa40d768284956a0b4f106d4d7b104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_252391d6d0ef4d8ab02e77031f294a63",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b64a04d8f384ba39447086e1be2ee99",
            "value": 456318
          }
        },
        "197b8637d8644d79b12f46cc774e9499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee31c3a304ae49579f53e0d8bf0a5967",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc6e863204f43f5b40e1f97dcb53ce4",
            "value": " 456k/456k [00:01&lt;00:00, 442kB/s]"
          }
        },
        "e4f685c474e24075887fed1ea5c41001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67217d27424e4f0986034e25ef6ffd36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38003e6c5794c77b9e23c31f1fc12f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "252391d6d0ef4d8ab02e77031f294a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b64a04d8f384ba39447086e1be2ee99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee31c3a304ae49579f53e0d8bf0a5967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc6e863204f43f5b40e1f97dcb53ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e63c3010624ea7b029e56a2f0aa3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_027f781927a546049b64899cd420158b",
              "IPY_MODEL_c66b1d6d6c8344f3af9620e50105156c",
              "IPY_MODEL_f043275dfb904ce7946904d7eb671d09"
            ],
            "layout": "IPY_MODEL_c9e1763059394146837cee6f273bc4b7"
          }
        },
        "027f781927a546049b64899cd420158b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9762a9c82e4da08317386e817632e8",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb3c49e21fe40d1a21023f5e88cb9e7",
            "value": "Downloading: 100%"
          }
        },
        "c66b1d6d6c8344f3af9620e50105156c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99981822da5465583719d6820723f2f",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44d3495a98af4d2fba500151061dab54",
            "value": 666
          }
        },
        "f043275dfb904ce7946904d7eb671d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca432f35dfa46478044b646730f096e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5f9d5f518240eaaf1535aef381fbdb",
            "value": " 666/666 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "c9e1763059394146837cee6f273bc4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9762a9c82e4da08317386e817632e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb3c49e21fe40d1a21023f5e88cb9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99981822da5465583719d6820723f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d3495a98af4d2fba500151061dab54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fca432f35dfa46478044b646730f096e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5f9d5f518240eaaf1535aef381fbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f23810630a8b4443837af97796ecc45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b614f10e1af461bb0828124d2f8a25a",
              "IPY_MODEL_1bed825117dc411fbf5d4e8416d9cc33",
              "IPY_MODEL_fd6c68f7257c487498fc41987000b78c"
            ],
            "layout": "IPY_MODEL_67384a55ff984d12b8f57ea7a6e93a0b"
          }
        },
        "4b614f10e1af461bb0828124d2f8a25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d65ff9fc5274a42953d9dc81f5433e7",
            "placeholder": "​",
            "style": "IPY_MODEL_ed2a912e2899480dafe19ee410a45298",
            "value": ""
          }
        },
        "1bed825117dc411fbf5d4e8416d9cc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34db7bc35c544ad18abf0ae8004634db",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba0108758df14802a60a237f97328688",
            "value": 0
          }
        },
        "fd6c68f7257c487498fc41987000b78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566d1fa7db0a4a829c4058c4939c1f10",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac5e2de835e4f838210c4d99ac1296d",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "67384a55ff984d12b8f57ea7a6e93a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d65ff9fc5274a42953d9dc81f5433e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2a912e2899480dafe19ee410a45298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34db7bc35c544ad18abf0ae8004634db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ba0108758df14802a60a237f97328688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "566d1fa7db0a4a829c4058c4939c1f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac5e2de835e4f838210c4d99ac1296d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12dd627a357e4aadaa94d446a728cc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48705b0fceab476885eff627428b9518",
              "IPY_MODEL_28ad9831d5184727b0dcc9e737f0d727",
              "IPY_MODEL_f4d1827914524f00a0dc9263f39dc43f"
            ],
            "layout": "IPY_MODEL_e3d5721cc5e549b4b291a0eb1e5b44e9"
          }
        },
        "48705b0fceab476885eff627428b9518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952795bb81d2412baf5d9f59775f0e54",
            "placeholder": "​",
            "style": "IPY_MODEL_147d74777d824fb78d5dd43c8c58bbe6",
            "value": "Downloading: 100%"
          }
        },
        "28ad9831d5184727b0dcc9e737f0d727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c6f5ad09934375ac83422a67a7d572",
            "max": 222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbed481764024ad7bbbd8f6fa7546c1d",
            "value": 222
          }
        },
        "f4d1827914524f00a0dc9263f39dc43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db2c71585e84aec9ae278c8b65f42db",
            "placeholder": "​",
            "style": "IPY_MODEL_9d9b34ebf15c4104a1a67cc615332ec8",
            "value": " 222/222 [00:00&lt;00:00, 6.73kB/s]"
          }
        },
        "e3d5721cc5e549b4b291a0eb1e5b44e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952795bb81d2412baf5d9f59775f0e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147d74777d824fb78d5dd43c8c58bbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c6f5ad09934375ac83422a67a7d572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbed481764024ad7bbbd8f6fa7546c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3db2c71585e84aec9ae278c8b65f42db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d9b34ebf15c4104a1a67cc615332ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6eea0f6b52149ae90cfac0d9d06db01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53501bc048a64e70a673f8f2b7e58718",
              "IPY_MODEL_d247d718598f40e59e61113708058352",
              "IPY_MODEL_8f5bc2d8c08a420a83d18d5fa6779949"
            ],
            "layout": "IPY_MODEL_7716d9761d0b4a76b8c21e4e7085cdbe"
          }
        },
        "53501bc048a64e70a673f8f2b7e58718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c59a42d65144ada405a3c60816ca2d",
            "placeholder": "​",
            "style": "IPY_MODEL_df00517a9d194c9d92105bcd3998dd49",
            "value": "Downloading: 100%"
          }
        },
        "d247d718598f40e59e61113708058352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6595ad303874c3aa9e4282116e1e598",
            "max": 14500438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfe57bdda43e4b83a77eb9790cd00439",
            "value": 14500438
          }
        },
        "8f5bc2d8c08a420a83d18d5fa6779949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61c1a95560d4dc08ea24f4e07e0f4f1",
            "placeholder": "​",
            "style": "IPY_MODEL_3191a63890484b00b7d386090681a8d3",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 33.9MB/s]"
          }
        },
        "7716d9761d0b4a76b8c21e4e7085cdbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c59a42d65144ada405a3c60816ca2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df00517a9d194c9d92105bcd3998dd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6595ad303874c3aa9e4282116e1e598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe57bdda43e4b83a77eb9790cd00439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e61c1a95560d4dc08ea24f4e07e0f4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3191a63890484b00b7d386090681a8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c165cf56584e4760b87f845f8f267e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aad8ea102e3e4f70995357a26b99dcc1",
              "IPY_MODEL_188282d5d81245f7a70290bb7100adee",
              "IPY_MODEL_1d501f61d20743288acaa71588efc998"
            ],
            "layout": "IPY_MODEL_ba26cdac76764dbebb336f199019c873"
          }
        },
        "aad8ea102e3e4f70995357a26b99dcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e88564dad9499fa84515e0d5344b8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e0db174c60ab499eadebfc4c15c49d65",
            "value": "Downloading: 100%"
          }
        },
        "188282d5d81245f7a70290bb7100adee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853d7f8b43bb49dab7ceb5428cd48f07",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9de6599b63d54291b35c34303978f8fa",
            "value": 85
          }
        },
        "1d501f61d20743288acaa71588efc998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096444d5998e4152b825344d95bd6491",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d33e406b2f4a6f80d68007ad087f23",
            "value": " 85.0/85.0 [00:00&lt;00:00, 2.73kB/s]"
          }
        },
        "ba26cdac76764dbebb336f199019c873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e88564dad9499fa84515e0d5344b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0db174c60ab499eadebfc4c15c49d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "853d7f8b43bb49dab7ceb5428cd48f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de6599b63d54291b35c34303978f8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "096444d5998e4152b825344d95bd6491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d33e406b2f4a6f80d68007ad087f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86825ac4395c43b5b868dd1e58177be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1c6f1701cec4d04bb45661f90681ad7",
              "IPY_MODEL_ab177ef17a004bc29785cbcf7a21c694",
              "IPY_MODEL_4a07adb2d6f848c7b85d0bcaa2aaf1a8"
            ],
            "layout": "IPY_MODEL_d04f6e22e04849c59c16b741ea7a374f"
          }
        },
        "e1c6f1701cec4d04bb45661f90681ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752b40210dea407fbad70017a2c31950",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb690543c33495397518cdb081622c0",
            "value": "Downloading: 100%"
          }
        },
        "ab177ef17a004bc29785cbcf7a21c694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f6209277ad4a178ab43c97cbbe2b2a",
            "max": 710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7910ea1364a449f0816cf9ecae227608",
            "value": 710
          }
        },
        "4a07adb2d6f848c7b85d0bcaa2aaf1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94192cddf19847a0b7fc3c995e3c5b9c",
            "placeholder": "​",
            "style": "IPY_MODEL_e640c3b60d1b48a6a579c64b91faea79",
            "value": " 710/710 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "d04f6e22e04849c59c16b741ea7a374f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752b40210dea407fbad70017a2c31950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb690543c33495397518cdb081622c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f6209277ad4a178ab43c97cbbe2b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7910ea1364a449f0816cf9ecae227608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94192cddf19847a0b7fc3c995e3c5b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e640c3b60d1b48a6a579c64b91faea79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d503f8c8c4e47a8a0e85504a40b353d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4444bb6f7a80414e8d6e077a34692bc8",
              "IPY_MODEL_119135e7a95c4fb8907951f766be6f80",
              "IPY_MODEL_9c127d6f936d47a89406070c9fb1c99a"
            ],
            "layout": "IPY_MODEL_707fd6df8f2b45598c7f8d71cf42f4c1"
          }
        },
        "4444bb6f7a80414e8d6e077a34692bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0026c32cc2f41eeb587ea97a89ed7e8",
            "placeholder": "​",
            "style": "IPY_MODEL_0b700844997e48d7bdf8f02f4c024268",
            "value": "Downloading: 100%"
          }
        },
        "119135e7a95c4fb8907951f766be6f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76af1fdd5a45496c8132f63107280429",
            "max": 1118531895,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed16a9cc2adc45d9b43ba7757d15b174",
            "value": 1118531895
          }
        },
        "9c127d6f936d47a89406070c9fb1c99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729b18457ca247a896a4305d85c7d6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_805031bd3ef54063b059e34921c2f126",
            "value": " 1.12G/1.12G [00:28&lt;00:00, 57.2MB/s]"
          }
        },
        "707fd6df8f2b45598c7f8d71cf42f4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0026c32cc2f41eeb587ea97a89ed7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b700844997e48d7bdf8f02f4c024268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76af1fdd5a45496c8132f63107280429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed16a9cc2adc45d9b43ba7757d15b174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "729b18457ca247a896a4305d85c7d6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805031bd3ef54063b059e34921c2f126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6FC-FMDBrBq",
        "outputId": "f8aa1c8d-4f00-4811-9d2f-a3bd4748a671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 68.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 708 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 24.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 22.6 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 431 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 73.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 68.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! rm -r sample_data\n",
        "! pip -q install transformers\n",
        "! pip -q install pytorch-lightning\n",
        "! pip -q install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from pytorch_lightning import seed_everything\n",
        "import pickle as pkl\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "os.chdir(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation\")\n",
        "RANDOM_SEED = 42\n",
        "seed_everything(RANDOM_SEED)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "YTHRiW_GB2VR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "f23810630a8b4443837af97796ecc45a",
            "4b614f10e1af461bb0828124d2f8a25a",
            "1bed825117dc411fbf5d4e8416d9cc33",
            "fd6c68f7257c487498fc41987000b78c",
            "67384a55ff984d12b8f57ea7a6e93a0b",
            "0d65ff9fc5274a42953d9dc81f5433e7",
            "ed2a912e2899480dafe19ee410a45298",
            "34db7bc35c544ad18abf0ae8004634db",
            "ba0108758df14802a60a237f97328688",
            "566d1fa7db0a4a829c4058c4939c1f10",
            "9ac5e2de835e4f838210c4d99ac1296d"
          ]
        },
        "outputId": "31afefb3-5021-45bb-d79c-d808edabf34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f23810630a8b4443837af97796ecc45a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_coral_context(context):\n",
        "    context = context.rstrip(\"[SEP]\")\n",
        "    context = context.replace(\"[CLS]\", \"Speaker 1:\")\n",
        "    speaker_num = 2\n",
        "    while context.find(\"[SEP]\") != -1:\n",
        "        context = context.replace(\"[SEP]\", f\"Speaker {speaker_num}:\", 1)\n",
        "        if speaker_num == 2:\n",
        "            speaker_num = 1\n",
        "        else:\n",
        "            speaker_num = 2\n",
        "    return \"Review this dialog: Context: \" + context"
      ],
      "metadata": {
        "id": "cYKPcBTNrRKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_blenderbot_context(context):\n",
        "    return \"Review this dialog: Context: Speaker 1: \" + context"
      ],
      "metadata": {
        "id": "ciWVVDnDrV5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Dataset**"
      ],
      "metadata": {
        "id": "WOo3yMBdBiMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(model_feedback_annotations_sheet):\n",
        "    processed_datapoints = []\n",
        "    for i in range(len(model_feedback_annotations_sheet)):\n",
        "        dataset_here = model_feedback_annotations_sheet.at[i, \"dataset\"]\n",
        "        model_here = model_feedback_annotations_sheet.at[i, \"model_name\"]\n",
        "        # if dataset_here.startswith(\"Dialo\"):\n",
        "        # print(dataset_here)\n",
        "        if type(model_feedback_annotations_sheet.at[i, 'formatted_context']) == str:\n",
        "            # print(dataset_here)\n",
        "            context_here = model_feedback_annotations_sheet.at[i, \"formatted_context\"]\n",
        "            context_here = process_coral_context(str(context_here).replace(\"nan\", \"\"))\n",
        "\n",
        "        elif model_here == \"Blenderbot-1B\":\n",
        "            context_here = model_feedback_annotations_sheet.at[i, 'context']\n",
        "            context_here = process_blenderbot_context(str(context_here).replace(\"nan\", \"\"))\n",
        "        \n",
        "        else:\n",
        "            if model_here == \"DialoGPT\":\n",
        "                # print(\"yeah\")\n",
        "                context_here = \"[CLS] \" + model_feedback_annotations_sheet.at[i, 'context'].replace(\"<|endoftext|>\", \" [SEP] \") + \" [SEP]\"\n",
        "            else:    \n",
        "                # print(dataset_here)\n",
        "                context_here = model_feedback_annotations_sheet.at[i, 'context']\n",
        "            context_here = process_coral_context(context_here)\n",
        "            \n",
        "        # if dataset_here.startswith(\"Blender\"):\n",
        "        #     context_here = process_blenderbot_context(context_here)\n",
        "        # else:\n",
        "        #     context_here = process_coral_context(context_here)\n",
        "    \n",
        "        model_response_here = model_feedback_annotations_sheet.at[i, 'model_response']\n",
        "        human_feedback_here = model_feedback_annotations_sheet.at[i, 'human_feedback']\n",
        "        if type(model_response_here) == float:\n",
        "            model_response_here = \"\"\n",
        "        datapoint = context_here + \" Response: \" + str(model_response_here.replace(\"nan\", \"\")) + \" Feedback: \" + human_feedback_here\n",
        "        processed_datapoints.append(datapoint)\n",
        "    model_feedback_annotations_sheet[\"processed_datapoint\"] = processed_datapoints\n",
        "    return model_feedback_annotations_sheet"
      ],
      "metadata": {
        "id": "uw9o5wXXZyb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feedback_annotations_filepath = \"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/annotated-feedback-model-responses/iitkgp-mtp-dialog-model-responses-1.csv\"\n",
        "model_feedback_annotations_sheet = pd.read_csv(feedback_annotations_filepath)"
      ],
      "metadata": {
        "id": "DfcQRkxeZm4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model_feedback_annotations_sheet['dataset']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhokPRz6vDdm",
        "outputId": "5f1e428e-b82d-44de-a766-e96a37f28d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'Reddit r/CasualConversations', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog', 'dailydialog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_feedback_annotations_sheet"
      ],
      "metadata": {
        "id": "1Y-if9CFZw4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_large_checkpoint = \"gpt2-large\"\n",
        "gpt2_tokenizer = AutoTokenizer.from_pretrained(gpt2_large_checkpoint,\n",
        "                                               pad_token=\"<|pad|>\",\n",
        "                                               additional_special_tokens=[\"<|startofcontext|>\",\n",
        "                                                                          \"<|endofcontext|>\",\n",
        "                                                                          \"<|startofresponse|>\",\n",
        "                                                                          \"<|endofresponse|>\"]\n",
        "                                               )\n",
        "gpt2_model = AutoModelForCausalLM.from_pretrained(gpt2_large_checkpoint).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "4243a5b835b04bd4be85391ec7771c57",
            "ea0d590c4630431693421ba02684c96a",
            "b47f486f7ae041d5b59d74bcf5bf662c",
            "c8b6240da69f4da9a73ce86d10d4e7d7",
            "109ff6b0181b498f9d63a5c5c2acba5f",
            "a923a640002745cc8376d8de76f0c112",
            "00235ff03f204c1698d59ace4661eb8c",
            "847c76a70dbc4e15a909a2dac135cb97",
            "d3153af15c3f44e9bc1e82d302262b69",
            "cb1b3d0fe96a4dc58f691fb8e3d465b9",
            "946a1aa4f81b4046abec4063aceb60fe",
            "e010a06ffc65464b9fba7b547d7f9961",
            "90ad4aa12adf461abebfad658fe87cd5",
            "732708e5fae84874acab9019e6f4676c",
            "758e895da63840a8902e3cb9669b6c2a",
            "7b9428c5e726430f91e017bac2e49288",
            "605a0785e0904590a2213e161ef32a71",
            "cff418fad5b14765ae27cfbacbd39663",
            "1cf8a5dc1deb4e199f40974ba02dac0e",
            "549829ea1a784e8bbd2565024a3a7a5d",
            "45f464663cd74721a390e50f374edf40",
            "4be0311605f947398017f5c07b06dbfe",
            "8036287008c943f498491d605f3a1455",
            "30cdf027eb954626b77d96fb99bb6a10",
            "c34f11f3d1a74e2185ba47ea6f6b7fda",
            "3295ba043ab24aa6ac7f02f8e0747a72",
            "6dee7daa313242f4840ae94ce7906abc",
            "fe15ec7e91ea423985cd7235d1831231",
            "4c047bc8539043c8ab8de1ad72122375",
            "7f42ce4c3afd4f4188268bd76c981fda",
            "6bd2a91e467348459f2156bc93af48ae",
            "666fc6b1eef047069916e6eac03b6c01",
            "57ae4070908f42309d5cb6159d93b403",
            "4716b9707c2c4bcdb761b266e2cf4f5c",
            "7e7edbc25124497fa5621f819cef3a9b",
            "8af9aefc572042a2b9d3cd13b3be7c9b",
            "6f5f7827f87847a39a23a3a6e76e4950",
            "5c64e18c181946719f6233f52cea77d8",
            "b5940e0e668d4979b76170884ab9f9d5",
            "070eed96a3754741b2aa1a55e06406d8",
            "5bfea5c60eca47a188f5ee4f47427cea",
            "6340dc9bfd954690963b3afb732bc3c1",
            "35723e6b86e3459f8612aa909f9d457e",
            "61a8ba182e6d4862a42ff8e315c46df3",
            "14882e3ffbdf4079b0bb212b57fa2ff6",
            "7445f3a402e5450288d1f2b2f6f55075",
            "10e6230ff978468e97669b7f4d90a528",
            "3c0455a208cb4fb6a4439645c490ed0c",
            "7dada12071ee43b1a4f7d8be64263ee4",
            "b3162c072dca4494a4a3dade399babc3",
            "acd6b98dcd064c5bb64034addcfc39e8",
            "aa5f7970eaa0433e94deadfa69378a71",
            "e7788893cc6b4e8988b93e00ccdc01ce",
            "25d221f4bdaa4b89b2f43abc6eb94c56",
            "c5ab47084fae4b7eadae856940afd9b3"
          ]
        },
        "id": "7a3JwB7YjBsA",
        "outputId": "7fcc0b31-7e1e-49d1-efe4-6ee8d038d1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4243a5b835b04bd4be85391ec7771c57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e010a06ffc65464b9fba7b547d7f9961"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8036287008c943f498491d605f3a1455"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4716b9707c2c4bcdb761b266e2cf4f5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/3.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14882e3ffbdf4079b0bb212b57fa2ff6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 47\n",
        "# list(model_feedback_annotations_sheet['dataset'])"
      ],
      "metadata": {
        "id": "QHMnwDgluwT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_feedback_annotations_sheet_processed = process_data(model_feedback_annotations_sheet)"
      ],
      "metadata": {
        "id": "n9GwG5hM2vDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_feedback_annotations_sheet_processed"
      ],
      "metadata": {
        "id": "yNzSCPlLrVbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scratch**"
      ],
      "metadata": {
        "id": "3YN57Ed3zfwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_feedback_annotations_sheet_processed.to_csv(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/annotated-feedback-model-responses/annotated-feedback-processed.csv\",\n",
        "                                                  index=False)"
      ],
      "metadata": {
        "id": "G_Cgn2QN21gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"csv\", data_files={\"train\": [\"annotated-feedback-processed.csv\"]})"
      ],
      "metadata": {
        "id": "DJ7WjMeEliY4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "c9c74091f19c481e967f06f1ef6ce981",
            "82c9be9a1b90487f8ee741af45f5e05f",
            "2f700370ef604df4881336e918ab906e",
            "1825fd705f714186ac49743cd576eb92",
            "333eaf8ab0a24f7fa7499f73b4e3fcb9",
            "0cd0245a35104950b83f8f8bb91acfed",
            "829d20f0d5904440b196b85ea84a4506",
            "7ddd905b6bcf43c384841b53db3c632e",
            "4def9a8ceb2e4e08bb8384fb95614a76",
            "b33fcb927b254937bb072d9d2f8533f9",
            "bc11acfa4f6b4e6b8c17a11cd3c05099",
            "94c5015e8cc3474998cd6a8a6e5a32d1",
            "8d9681c98de24b8f804ef7d7cf93e032",
            "613cb3fabcaa462d9f03222922da9ee6",
            "e7f8d642bb8743c2af6503631a4b1a91",
            "590e151d9f824e49bfa58a0517d12f4d",
            "ffd45c0efda241d5b026aa38cd91da15",
            "8e7fa1518cb44fba8d3696d0cfb1dfd5",
            "d7e32e1e7a74412ca30329d88a3413d9",
            "134944f66dab46eba01682db155b84c4",
            "171afbec907943c290154c7a0aea6850",
            "ead807fce2f842149bd27f20eb75be20",
            "e0711fd4d2a041ec8fad03a59b8a38fb",
            "aa40560c473d4d3dabebe4672d3902e5",
            "ef22e76e69a145e49e61c0c6c22737db",
            "95f4330e861347c595dfcc4feef0f07e",
            "2385f11dc42449cda7ce251d86b0535b",
            "083100aa8a664989a9eca81cd6980b89",
            "bec0940282b4417294f258b5e88eafa9",
            "912c048483d548059678d235ca3da8f6",
            "7e196dad83ba43e5830ffba259dcb573",
            "809e7db338c4426e9a3ad2cc054d6949",
            "7e5c8096d54d4e8e9dc4575501fd5886",
            "2024de4ba0ba4e71a36eebffc9c4b8b1",
            "19f3c5847b3847f3836e711f3bd336e9",
            "b93242eb7cf344f29e5fc81a98679e7f",
            "ccda1eba7b244957bcd7f610f08c895d",
            "89ba8340f8e84070be3997141f86fd36",
            "e47a176a1fe641f6b2ba16fca66040be",
            "672a5cd6da8046e0bcffdeaf5e315cc2",
            "561e553790fa4c92a07c0aa9d7caf9f6",
            "f994b26cb7d84954bc72bddb8d10fc75",
            "2524d8e07afe45a08866c33e8e973c31",
            "55af1939ebb7494898991b943388581a"
          ]
        },
        "outputId": "fb432ec7-33e6-4179-b7cb-f1565c529c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-0dc349f645b7170f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-0dc349f645b7170f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9c74091f19c481e967f06f1ef6ce981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94c5015e8cc3474998cd6a8a6e5a32d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0711fd4d2a041ec8fad03a59b8a38fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-0dc349f645b7170f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2024de4ba0ba4e71a36eebffc9c4b8b1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JRg4FvPqfeH",
        "outputId": "b0ddf06e-85de-493d-e510-0cd01a279903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['model_name', 'Unnamed: 1', 'dataset', 'context', 'formatted_context', 'model_response', 'human_feedback', 'Unnamed: 7', 'questions', 'filename', 'processed_datapoint'],\n",
              "        num_rows: 37\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return gpt2_tokenizer(examples[\"processed_datapoint\"])\n",
        "dataset = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"model_name\",\n",
        "                                                                                   \"Unnamed: 1\",\n",
        "                                                                                   \"dataset\",\n",
        "                                                                                   \"context\",\n",
        "                                                                                   \"formatted_context\",\n",
        "                                                                                   \"model_response\",\n",
        "                                                                                   \"human_feedback\",\n",
        "                                                                                   \"Unnamed: 7\",\n",
        "                                                                                   \"questions\",\n",
        "                                                                                   \"filename\",\n",
        "                                                                                    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "89e4ce9ce5084a72a91967c48a2a9c53",
            "e0cf0bcf6e6743a9aabcc29eed7e99dd",
            "ca4ce730d64b470c92886f1ceda51195",
            "d6244f29aa9a4e58a3c290dc6d146cc1",
            "510cc8304ba942d0920d87eed8cc71c7",
            "a0b9bd9a606d40ca8e33ad320432ad9e",
            "134367c5b230449ba09957da1ad6b008",
            "482999039c744f2c8246e25cb34df9f5",
            "d5c86887901d42d281d76836358eec5c",
            "708bab5f490644e2a6ae0e79ba3c6b96",
            "e770d8c986f14e2a9228d6a7623e4b90",
            "e832a0e93a844ed3b6fbdf0ab78889de",
            "c355a6e90d744032a5217d560b81d210",
            "a36f4987c7b94e2a8366615658069426",
            "77548506eaae4017a5ebc73c801e95ea",
            "d30d710756c84c6a971ca539b9285f99",
            "c55cc0b2a61d47c897ab92d3899aa2d2",
            "edd55aa67f6743f6b3fb75ee5377981f",
            "5b2cbcadd0b64869ab8d37783c301e5f",
            "ba3aad1b833749988f951a7485a5104e",
            "c54f933b97ac4917b02441200963feaf",
            "dd960ddacd064b45bb0b10898e51cd62",
            "ba5fe24d78a548dcad4eb9c7e01693ac",
            "bf736c8c91534295baf7eae905e08ea9",
            "3ea750a36678401abdc699b08b07d148",
            "602abc5f3bd94b1d98bbbb48b448e4ef",
            "24b0c17229b548ceb0585f5d12b6559d",
            "5269869bba6e4fb5b1a1c4c1b7c4841e",
            "a1620c788a5a4e0ab31391c19da80d3c",
            "233ca54da4004003abd8f86f1f6f1521",
            "c1c653402e4b41b3b1ed196028d97ecc",
            "6610221a381c415a88201c3a58f87715",
            "6141f737a9b9435cbe298cddd3097903",
            "355f7b40296d4e508c12e201ab2cacb5",
            "c83e13cb94d547ebad263ebb0017b94f",
            "d62137bbe77848e5bd5240cd6bcf4d64",
            "cca195c5a0ca42cfb01ef3dc781ff636",
            "80766dafedb84a859c09dc7bb965cd3e",
            "b7fe58bec7b54ee283d7ef43c99ac228",
            "c749bad82a0948c89e7b58d8e23da3e0",
            "8c506bd413cf4f82bceaaaf612ea67cd",
            "4e248fc9aff64037898e823072639a61",
            "59b0036908034e68b6d972879cf7ab20",
            "d6d1a33af9274d9aa4f2350c469e49fa"
          ]
        },
        "id": "sWbWlY96pQ1-",
        "outputId": "c9fe090a-f412-4793-d673-d6f18c997059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89e4ce9ce5084a72a91967c48a2a9c53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e832a0e93a844ed3b6fbdf0ab78889de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba5fe24d78a548dcad4eb9c7e01693ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "355f7b40296d4e508c12e201ab2cacb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"gpt2-large\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    # push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "eZM92m-5rbf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.pad_token=\"<|pad|>\""
      ],
      "metadata": {
        "id": "knPsnUGLtea7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_model.resize_token_embeddings(len(gpt2_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvxQYoCPvCXI",
        "outputId": "480bc2c7-386a-4137-8438-4ce55b114020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50262, 1280)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=gpt2_model,\n",
        "    tokenizer=gpt2_tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        ")"
      ],
      "metadata": {
        "id": "TbBkzZsyrik0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "flrlmP8gr-O2",
        "outputId": "4aac17ae-96b7-4061-90d1-2b2fb6382649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: processed_datapoint. If processed_datapoint are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 37\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         )\n\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 2516\u001b[0;31m                     \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2517\u001b[0m                     \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvZbus3dr-M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3YI77fDsC2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3L60Mt1lsCzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aqy4Hs5MsCw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset['train']['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTZcdq6kpQzG",
        "outputId": "f2b5f3c5-fdf8-4515-e468-4986dd13d780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer(\"Hey there how are you right now?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRl3dLtbpQxI",
        "outputId": "55f1fc2a-19fe-4823-b773-72b388190904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [10814, 612, 703, 389, 345, 826, 783, 30], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQrHSoempQvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "humFE9xypQtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install transformers"
      ],
      "metadata": {
        "id": "1g6YSXbOw9Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpuYkNlWw_5r",
        "outputId": "e9b6fd24-83ad-464b-c32b-a30b7d532342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 23 17:42:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Working->**"
      ],
      "metadata": {
        "id": "SCb0yf9Fyzya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPTNeoForCausalLM, GPTNeoModel, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import random\n",
        "from torch import cuda\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "I9OXrp-HtqC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to a fixed value to get reproducible results \n",
        "# torch.manual_seed(42)\n",
        "# Download the pre-trained GPT-Neo model's tokenizer\n",
        "# Add the custom tokens denoting the beginning and the end \n",
        "# of the sequence and a special token for padding\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\",    \n",
        "                            bos_token=\"<|startoftext|>\",\n",
        "                            eos_token=\"<|endoftext|>\",\n",
        "                            pad_token=\"<|pad|>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "1b7c33b5f4d4433ea02f0ff536dcd8db",
            "4088ab35b9e949f29e87737f6d93be8e",
            "c6fd3bbb0e484992ba74cc5a2b75c23e",
            "ed966bda924d469e91a04cfc7f4cba6c",
            "0c4074906db348f6889354df5c398838",
            "425b801047544094bfdfaab6708ed2bc",
            "45abfa4dff5d4367a0567cc2745f099d",
            "8f731a4e31604dd2a3d2b4a8034aacf6",
            "bb5aef16180c4062b312c05620585dc7",
            "8f63ca3f0093479ab8fc7a3fe28d065b",
            "43caad81600b4b7d816112a7f4f80112",
            "a5f8534225cf40959e06a73b70dceb4b",
            "7e5124391c7d4271b96a0b046f8b20d7",
            "6ffa40d768284956a0b4f106d4d7b104",
            "197b8637d8644d79b12f46cc774e9499",
            "e4f685c474e24075887fed1ea5c41001",
            "67217d27424e4f0986034e25ef6ffd36",
            "c38003e6c5794c77b9e23c31f1fc12f0",
            "252391d6d0ef4d8ab02e77031f294a63",
            "2b64a04d8f384ba39447086e1be2ee99",
            "ee31c3a304ae49579f53e0d8bf0a5967",
            "8fc6e863204f43f5b40e1f97dcb53ce4",
            "73e63c3010624ea7b029e56a2f0aa3c6",
            "027f781927a546049b64899cd420158b",
            "c66b1d6d6c8344f3af9620e50105156c",
            "f043275dfb904ce7946904d7eb671d09",
            "c9e1763059394146837cee6f273bc4b7",
            "ba9762a9c82e4da08317386e817632e8",
            "fcb3c49e21fe40d1a21023f5e88cb9e7",
            "c99981822da5465583719d6820723f2f",
            "44d3495a98af4d2fba500151061dab54",
            "fca432f35dfa46478044b646730f096e",
            "0a5f9d5f518240eaaf1535aef381fbdb"
          ]
        },
        "id": "7T-Ymp0zvizh",
        "outputId": "44e0ca18-2566-45ba-c385-01ae0cabb530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b7c33b5f4d4433ea02f0ff536dcd8db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5f8534225cf40959e06a73b70dceb4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73e63c3010624ea7b029e56a2f0aa3c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\").to(device)\n",
        "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "# Resize the token embeddings because we've just added 3 new tokens \n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "cKAAUcfkvpp3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "dbbc9c6bfbc5466c9adc632efddaa69d",
            "d14f2418f88b43a79cb23aff11e07ea8",
            "ab16a12ebc0b4823b169736dc6fad547",
            "26d2f01050a9451593b8cef942d152b2",
            "a518f507662f495687f8c25f1bbd323c",
            "8dc6958e9ec84ddcbb2e407eea40c6ab",
            "7296c6eb14db4fcba8650a9a4d32b7ab",
            "2c835b97d99d457395560c12f0258738",
            "5e38bbe073ab40b4b403e50b37e85263",
            "b5af26fbe60342258f50234e98ba8fce",
            "ba476b0bb57b493a863b5e94ff0d4024"
          ]
        },
        "outputId": "abfddee0-b5b9-438d-b671-0fa1b9b77bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/3.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbbc9c6bfbc5466c9adc632efddaa69d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50259, 1280)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "annotations = pd.read_csv(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/annotated-feedback-model-responses/annotated-feedback-processed.csv\")\n",
        "for i in range(len(annotations)):\n",
        "    lines.append(annotations.at[i, 'processed_datapoint'])"
      ],
      "metadata": {
        "id": "bKLav0NMxZqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "descriptions = [description for description in lines if len(tokenizer.encode(description)) < max_length-2]\n",
        "max_length = max([len(tokenizer.encode(description)) for description in descriptions])\n",
        "max_length"
      ],
      "metadata": {
        "id": "ivyLz0eLxn1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetflixDataset(Dataset):\n",
        "    def __init__(self, txt_list, tokenizer, max_length):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        for txt in txt_list:\n",
        "            # Encode the descriptions using the GPT-Neo tokenizer\n",
        "            encodings_dict = tokenizer(\"<|startoftext|>\" \n",
        "                                        + txt +    \n",
        "                                        \"<|endoftext|>\",\n",
        "                                        truncation=True,\n",
        "                                        max_length=max_length, \n",
        "                                        padding='max_length')\n",
        "            input_ids = torch.tensor(encodings_dict['input_ids'])    \n",
        "            self.input_ids.append(input_ids)\n",
        "            mask = torch.tensor(encodings_dict['attention_mask'])\n",
        "            self.attn_masks.append(mask)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "dataset = NetflixDataset(descriptions, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "81PFZh46x4kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(1 * len(dataset))\n",
        "train_dataset, val_dataset = random_split(dataset, \n",
        "                            [train_size, len(dataset) - train_size])\n",
        "# train_dataset = dataset\n",
        "train_size = len(train_dataset)"
      ],
      "metadata": {
        "id": "dw9IlkQEx6Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.5e-5\n",
        "bs=10\n",
        "ne=3\n",
        "training_args = TrainingArguments(output_dir=f'gpt2-large-lm-lr{lr}-bs{bs}-ne{ne}',\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  num_train_epochs=3,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  save_strategy='epoch',\n",
        "                                #   logging_steps=200,\n",
        "                                #   save_steps =1000,\n",
        "                                  per_device_train_batch_size=1,\n",
        "                                  gradient_accumulation_steps=10,\n",
        "                                #   per_device_eval_batch_size=2,\n",
        "                                #   warmup_steps=500,\n",
        "                                  weight_decay=0.01,  \n",
        "                                  load_best_model_at_end=True,\n",
        "                                  )\n",
        "                                #   logging_dir='./logs')"
      ],
      "metadata": {
        "id": "P9kAcp8tx9Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=training_args,  \n",
        "                  train_dataset=train_dataset,\n",
        "                #   eval_dataset=val_dataset, \n",
        "                  # This custom collate function is necessary \n",
        "                  # to built batches of data\n",
        "                  data_collator=lambda data: \n",
        "              {'input_ids': torch.stack([f[0] for f in data]),       \n",
        "               'attention_mask': torch.stack([f[1] for f in data]),\n",
        "               'labels': torch.stack([f[0] for f in data])}\n",
        "                 )"
      ],
      "metadata": {
        "id": "8uWGvwg2tqAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training process!\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "BExBFSw2zChZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "2a333b7a-dc33-49ab-98e0-02ff72f23f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 70\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
            "  Gradient Accumulation steps = 10\n",
            "  Total optimization steps = 21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 03:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-7\n",
            "Configuration saved in gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-7/config.json\n",
            "Model weights saved in gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-7/pytorch_model.bin\n",
            "Saving model checkpoint to gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-14\n",
            "Configuration saved in gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-14/config.json\n",
            "Model weights saved in gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-14/pytorch_model.bin\n",
            "Saving model checkpoint to gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-21\n",
            "Configuration saved in gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-21/config.json\n",
            "Model weights saved in gpt2-large-lm-lr5e-06-bs10-ne3/checkpoint-21/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=21, training_loss=1.6736891610281808, metrics={'train_runtime': 227.0799, 'train_samples_per_second': 0.925, 'train_steps_per_second': 0.092, 'total_flos': 191010387456000.0, 'train_loss': 1.6736891610281808, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "DKNM_u76-xWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines"
      ],
      "metadata": {
        "id": "koLK3GEwgvTB",
        "outputId": "a70b639e-b3e0-44c9-bc36-5adb80ba8f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Review this dialog: Context: Speaker 1: hey man, you wanna buy some weed? Speaker 2: some what?  Response: i like to look at all my wedding, and i\\'d like a little tired. Feedback: The response is incorrect because it is completely unrelated to the context. A better response would have been \"Weed - marijuana. Would you like some?\"',\n",
              " 'Review this dialog: Context: Speaker 1: we\\'ve managed to reduce our energy consumption in our factory by about 15 per cent in the last two years. Speaker 2: that\\'s excellent. how have you managed that?  Response: i don\\'t know, so that\\'s right? Feedback: The response is incorrect because it is not coherent. \"so that\\'s right?\" following \"i don\\'t know\" does not make sense in the given context. A better response would be \"mainly because we\\'ve invested in a heat recovery system.\"',\n",
              " 'Review this dialog: Context: Speaker 1: we\\'ve managed to reduce our energy consumption in our factory by about 15 per cent in the last two years. Speaker 2: that\\'s excellent. how have you managed that? Speaker 1: mainly because we\\'ve invested in a heat recovery system.  Response: what\\'s that? i think about you\\'ll enjoy the new apartment on that position. Feedback: The response is incorrect because it has grammar errors and is unrelated to the context. \"I think about you\\'ll...\" is grammatically incorrect. \"the new apartment on that position\" is unrelated to the given context. A better response would be \"What\\'s that? Tell me more about it.\"',\n",
              " 'Review this dialog: Context: Speaker 1: believe it or not, tea is the most popular beverage in the world after water. Speaker 2: well, people from asia to europe all enjoy tea. Speaker 1: right. and china is the homeland of tea.  Response: ok, honey on the aluminum, the course i think i\\'m going to be sure you can manage. Feedback: The response is incorrect because it is incoherent and unrelated to the context. A better response would be \"That\\'s interesting. What else do you know about tea?\"',\n",
              " 'Review this dialog: Context: Speaker 1: so how did i do on my driving test? Speaker 2: do you want the truth? Speaker 1: of course, i do.  Response: have you ever been a week with them? Feedback: The response is incorrect because it is completely unrelated to the context. A better response would be, \"Well, you really didn\\'t do all that well.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Do you know there are several catagories of Chinese tea ? Speaker 2: Yes , I believe there are green teas , black teas and scented teas . Any Others ?  Response: There is also a catagory of sweet and sour dishes Feedback: The response is incorrect because it is not related to the context. The context is about categories of tea, while the response involves categories of dishes. A better response would be, \"Well , have you ever heard of Oulong tea and compressed tea ?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Oh , yeah . Oulong tea is good for one\\'s health . isn\\'t it ? You surely know a lot about Chinese tea .  Response: I\\'m a tea expert. I know a lot about tea. I\\'m a tea expert. I know a lot about Chinese tea. Feedback: The response is incorrect because it repeats sentences. The sentence \"I\\'m a tea expert\" is repeated twice. A better response would be, \"I\\'m a tea expert and I know a lot about tea. Especially Chinese tea.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Why don\\'t we go for one now ? Speaker 2: Great . We can chat while enjoying a cup there .  Response: Great. I\\'ll bring the wine. I\\'ll be waiting for you. I\\'ll be waiting for you. I\\'ll be waiting for you. Feedback: The response is incorrect because it repeats sentences. The sentence \"I\\'ll be waiting for you\" is repeated thrice. A better response would be, \"Great. I\\'ll bring the wine. I\\'ll be waiting for you.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Mr . Johnson ’ s office . Cindy speaking . Response: Do you like Mr. Johnson? He was an American businessman, actor, and philanthropist Feedback: The response is incorrect because it tells someone at Mr. Johnson\\'s office about Mr. Johnson himself, something they would be expected to know. It also addresses Mr. Johnson in the past tense (\"he was...\"), which is inappropriate, given the information and context at hand. A better response would be, \"Is Mr. Johnson available today?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Yes , sir ? Response: I\\'m a ma\\'am, but thank you for the compliment. It means a lot to me. Feedback: This response is incorrect because being addressed as \\'sir\\' is not a complement, and it cannot mean a lot as said in the response. A better response would be, \"What can I help you with?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Jack , let ’ s go ! Response: Jack is such a great name for a dog. It\\'s a cross between a bulldog and a poodle. Feedback: The response is incorrect because it interprets Jack as a dog\\'s name without supporting context for the same. Additionally, a name, Jack, cannot be a cross between a bulldog and a poodle, as the response says. A better response would be, \"I\\'m ready. Let\\'s go!\"',\n",
              " 'Review this dialog: Context: Speaker 1: Excuse me , Miss . Response: Hi, how are you today? I am fine, thank you for asking. How are you? Feedback: The response is incorrect because it asks a question and answers it itself. The question \"How are you?\" is repeated twice. \"Thank you for asking\" is inappropriate, as the author never asks. A better response would be, \"Hi, how can I help?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Good morning , Kate . Long time no see . Response:  Hi, how are you today? I\\'m doing well, thank you. How are you? Feedback: The response is incorrect because it asks a question and answers it itself. The question \"How are you?\" is repeated twice. A better response would be, \"Good morning! How are you doing?\"',\n",
              " 'Review this dialog: Context: Speaker 1: I wonder if you could help me , I\\'m looking for a room . Response: Sure, what do you need help with? I can help you find a place to live. Feedback: The response is incorrect because it asks what help the author needs, in spite of the author having said they need a room. A better response would be, \"Sure, I can help you with that. What kind of room would you like?\"',\n",
              " 'Review this dialog: Context: Speaker 1: IBA , Jane speaking . How can I help you ?  Response: I\\'m not sure what to do. I don\\'t know if I\\'m ready to go back to school. Feedback: The response is incorrect because it it not relevant to the context. A better response would be, \"I\\'d like to know more about IBA.\"',\n",
              " 'Review this dialog: Context: Speaker 1: What can I do for you , sir ? Response: I am a ma\\'am, but thank you for the kind words. I am trying to figure out what to do. Feedback: The response is incorrect because calling a woman \\'sir\\' is not kind, as said in the response. A better response could be, \"I am trying to figure out what to do.\"',\n",
              " 'Review this dialog: Context: Speaker 1: May I help you , sir ?  Response: I\\'m a ma\\'am, but I appreciate the gesture.  What do you do for a living? Feedback: The response is incorrect because calling a woman \\'sir\\' is not kind, as said in the response. A better response could be, \"I am trying to figure out what to do.\"',\n",
              " 'Review this dialog: Context: Speaker 1: no , no , you helped me with my computer last week . I want to repay the favor . Response: Oh, I\\'m sorry to hear that. I hope you can get it fixed soon.  Feedback: The response is incorrect because it does not understand the context well. The author was already helped with his computer last week and wants to do a favor to the addressee in return. A better response would be, \"Oh, thank you for the kind gesture! I\\'m glad I helped you with your computer.\"',\n",
              " 'Review this dialog: Context: Speaker 1: I ’ Ve been told you might have a vacant room . Response:  That would be nice, but I don\\'t know if I can afford it right now.  Feedback: The response is incorrect because it does not understand the context well. The author wants to inquire about the availability of a vacant room with the addressee, while the response assumes a vacant room is being offered to them. A better response would be, \"I do! What do you need it for?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Hello . May I speak to Jerry , please ? Sorry , but he is out for lunch right now . Response: Oh, I see. Well, I hope you have a good lunch. I\\'ll be here waiting for you. Feedback: The response is incorrect because it does not understand the context well enough. It is Jerry who is out for lunch, and not the author. The response wishes the author a good lunch instead. A better response would be, \"Do you know when he will be back?\"',\n",
              " \"Review this dialog: Context: Speaker 1: Welcome to IBA . Can I help you ?  Yes , please . I'm here for an International Settlement . Our company has to effect payment , and it needs to be done today . Here's the advice slip for the payment . Response: I'm sorry to hear that. I hope everything works out for you and your company.  Feedback: The response is incorrect because it does not understand the context well. There is nothing to be sorry about, as the conversation is about making a payment to IBA by the end of the day.\",\n",
              " 'Review this dialog: Context: Speaker 1: are you busy tomorrow morning? Speaker 2: i\\'m free. what\\'s up?  Response: you\\'re a thief please. Feedback: The response is incorrect because it is unrelated to the context, accusatory and rude. A better response would be, \"Would you like to go on a walk together?\"',\n",
              " 'Review this dialog: Context: Speaker 1: do you have maps of downtown area? Speaker 2: yes, here you are.  Response: yes. this is possible, betty and in the future. li is quite nice, a better, just there isn\\'t my house. Feedback: The response is incorrect because it is completely unrelated to the context. A better response would be, \"Thank you.\"',\n",
              " 'Review this dialog: Context: Speaker 1: hi there, i want to reserve a hotel room. Speaker 2: no problem at all. could i have your full name, please? Speaker 1: sure, john sandals. Speaker 2: hi, mr. sandals. i\\'m michelle, at your service. when do you need the room? Speaker 1: my plans are to be there april 14th to the 17th. Speaker 2: we have new room rates, sir. will that be acceptable to you? Speaker 1: well, it depends on the price, of course. what is it? Speaker 2: it\\'s $ 308 a night. Speaker 1: i have no problem with that. Speaker 2: great! would you prefer smoking or nonsmoking?  Response: can you give me a call extra charge up, 000 or non account? Feedback: The response is incorrect because it is completely unrelated to the context. A better response would be, \"Definitely non-smoking. I can\\'t handle the smell.\"',\n",
              " 'Review this dialog: Context: Speaker 1: could i have my bill, please? Speaker 2: certainly, sir. Speaker 1: i\\'m afraid there\\'s been a mistake.  Response: here you are.. it\\'s correct. Feedback: The response is incorrect because it is impolite and not very clear. A better response would be, \"I\\'m sorry, sir. What seems to be the trouble?\"',\n",
              " 'Review this dialog: Context: Speaker 1: good evening, madam. can i help you? Speaker 2: yes. i bought this sheet here yesterday.  Response: what about the account?. Feedback: The response is incorrect because it is completely unrelated to the context. A better response would be, \"Yes, is there anything wrong with it?\"',\n",
              " 'Review this dialog: Context: Speaker 1: hey, you look great! how\\'s everything? Speaker 2: yeah, you know what? i\\'ve been going to the club regularly. the training really pays off. now i am in a good shape and i know more about how to keep fit.  Response: a real talent? i just started my job performance. Feedback: The response is incorrect because it is completely unrelated to the context. A better response would be, \"Really? Tell me about it. I haven\\'t gone to the club for a long time. I\\'ve been too busy with work.\"',\n",
              " 'Review this dialog: Context: Speaker 1: do you have sport shirts for ladies? Speaker 2: there are different types. which one do you like best?  Response: i want to try on this one. it\\'s not very popular. in fact, those are not very heavy. Feedback: The response is incorrect because it is not coherent. The addressee shouldn\\'t want to try on a shirt if it is not very popular. Some shirts not being heavy, as stated in the last line, seems out of place and irrelevant to the context. A better response would be, \"I think the red one fits me well. Can I try it on?\"',\n",
              " 'Review this dialog: Context: Speaker 1: i\\'m a little nervous. Speaker 2: don\\'t worry. you\\'ll be fine. first of all, put on your seat belt. adjust the mirrors. Speaker 1: you don\\'t think i\\'ll need the seat belt, do you?  Response: i guess i\\'ll get hurt. Feedback: The response is incorrect because it is insensitive, foreboding and unrelated to the question being asked. A better response would be, \"Of course not. But it\\'s a good habit to put it on every time you drive.\"',\n",
              " 'Review this dialog: Context: Speaker 1: good evening, ma\\'am. table for one? Speaker 2: yes, please. Speaker 1: will this table be all right?  Response: this way, please. i\\'ll be right back. from september, a table, please.. Feedback: The response is incorrect because it is incoherent, and does not answer the question being asked. A better response would be, \"Yes, this will be fine, thanks.\"',\n",
              " 'Review this dialog: Context: Speaker 1: hi, who has the remote control? Speaker 2: i do. why, do you want me to change the channel? Speaker 1: yes, please. i can\\'t stand watching the channel any more.  Response: oh, so?. here is it...? Feedback: The response is incorrect because it is grammatically wrong and does not make sense. A better response would be, \"Oh, is that so? Here you go, I\\'m changing the channel.\"',\n",
              " 'Review this dialog: Context: Speaker 1: excuse me, are you mrs. green from england? Speaker 2: yes, i am.  Response: is there a problem? you\\'re really good - very short..??? Feedback: The response is incorrect because it is incoherent, unrelated to the context, and grammatically incorrect. A better response would be, \"I\\'m pleased to meet you, Mrs. Green.\"',\n",
              " 'Review this dialog: Context: Speaker 1: shall we visit the summer palace tomorrow? Speaker 2: good. i don\\'t want to leave beijing without visiting it. Speaker 1: how far is it from our hotel?  Response: this one will be ok. Feedback: The response is incorrect because it is unrelated to the context, which revolves around visiting the Summer Palace in Beijing. A better response would be, \"It\\'s not too far away.\"',\n",
              " 'Review this dialog: Context: Speaker 1: i need a taxi, please. Speaker 2: we have various transportation services. would you prefer a private vehicle?  Response: i\\'m sorry. i have the rest. it\\'s not.\\'s the. Feedback: The response is incorrect because it is grammatically wrong, incoherent, and unrelated to the context. A better response would be, \"No, thanks. A taxi is just fine.\"',\n",
              " 'Review this dialog: Context: Speaker 1: it\\'s your turn now, helen. Speaker 2: ok. i\\'m coming. Speaker 1: this is your song. i picked it for you.  Response: i\\'ll have the computer after.,\\'to,. Feedback: The response is incorrect because it is grammatically wrong, incoherent, and unrelated to the context. A better response would be, \"Thank you. You are so considerate.\"',\n",
              " 'Review this dialog: Context: Speaker 1: excuse me, could you help me pick out a lotion? Speaker 2: sure, what is the problem?  Response: what is the rate? what did you say? that\\'s the matter?????? Feedback: The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I got poison oak while hiking, and I need something to help me with the itching.\"',\n",
              " 'Review this dialog: Context: Speaker 1: abby park hotel. can i help you? Speaker 2: yes, i would like to book a room for my wife and myself. Speaker 1: certainly sir. could i have your arrival and departure dates?  Response: i\\'m afraid i can\\'t get it.\\'s not your room i\\'m glad? i want Feedback: The response is incorrect because it is grammatically wrong, incoherent, and unrelated to the context. A better response would be, \"We will be arriving on Tuesday next week and staying for two days.\"',\n",
              " 'Review this dialog: Context: Speaker 1: dc or marvel  Response: DC, but I\\'m not sure if Marvel has a DC equivalent. Feedback: The response is wrong because it is unclear what Marvel having a DC equivalent means, DC and Marvel both being film production companies. A better response would be, \"DC! I like their superheroes better. What about you?\"',\n",
              " 'Review this dialog: Context: Speaker 1: why waste time, say lot word when few word do trick?  Response: I think you mean\\'lot word \\'. Feedback: The response is incorrect because it has spacing issues and does not understand the author\\'s point about saying few words instead of a lot of words, thus helping save time. The author illustrates this point by using few words to convey his point, but being grammatically incorrect at the same time. A better response would be, \"Oh, but wouldn\\'t it lead to sentences sounding awkward because of their grammatical incorrectness?\"',\n",
              " 'Review this dialog: Context: Speaker 1: I was teasing :) it\\'s been a while since you originally posted, how did your day end up going?   Response: I\\'m still here. Feedback: The response is wrong because it does not answer the question \"How did your day end up going?\" asked by the author. A better response would be, \"I had a wonderful day! How was your day?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Thanks. I figure that I’ve saved the cost of a new car, twice over  Response: You can get a used car for that much. Feedback: The response is incorrect because, while not factually incorrect, it provides redundant information, possibly because the context is not understood well. With savings equal to twice the cost of a new car, a used car can obviously be bought. A better response would be, \"That\\'s amazing! What are you going to do with your savings?\"',\n",
              " 'Review this dialog: Context: Speaker 1: It is the most overrated band in the world  Response: I think you mean overrated. Feedback: The response is wrong because there is nothing in the context to correct with the word \\'overrated\\'. A better response would be, \"Oh, really? Tell me about it. What makes you think so?\"',\n",
              " 'Review this dialog: Context: Speaker 1: And he\\'s a manchild for...what exactly?  Response: He\\'s a manchild for being a manchild. Feedback: The response is incorrect because it is not coherent and provides a recursive reason. A better response would be, \"I\\'m not sure. Can you tell me more about him?\"',\n",
              " 'Review this dialog: Context: Speaker 1: No, I haven\\'t, but I know it\\'s a classic  Response: I think it\\'s a classic, but I don\\'t think it\\'s a classic. Feedback: The response is wrong because it is self-contradictory, in that it says it isn\\'t a classic after saying it is a classic. A better response would be, \"Interesting, tell me more about it.\"',\n",
              " 'Review this dialog: Context: Speaker 1: I\\'m almost certain you\\'ll be taller if you try eating mushrooms  Response: I\\'m almost certain you\\'ll be taller if you try eating mushrooms Feedback: The response is incorrect because it inappropriately repeats the context as-is. A better response would be, \"I love mushrooms! They have so many health benefits.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Really? Awesome, what are you playing right now?   Response: I\\'m playing a lot of games, but I\\'m not really into them. I\\'m playing a lot of games, but I\\'m not really into them. Feedback: The response is wrong because it repeats sentences. A better response would be, \"I\\'m not playing anything at the moment, but I love talking about games. What are you playing right now?\"',\n",
              " 'Review this dialog: Context: Speaker 1: As a kid, what movie(s) did you repeatedly watch? Speaker 2: The Lion King!\\n\\nI could never get bored of that movie.  Response: I\\'m sorry, but I don\\'t think you\\'re allowed to say that. Feedback: The response is incorrect because there is nothing inappropriate in the context, which talks about The Lion King movie, that shouldn\\'t be said. A better response would be, \"Yeah, The Lion King was an amazing movie!  It\\'s one of my favorites as well.\"',\n",
              " 'Review this dialog: Context: Speaker 1: What\\'s that one food you hate but everyone seems to like it? Speaker 2: Fucking olives, man.  Response: I\\'m not a fan of olives, but I do love olives. Feedback: The response is wrong because it is self-contradictory. The response says it both loves olives and doesn\\'t like them (is not a fan of them) at the same time, which is not possible. A better response would be, \"Oh, I like olives. What don\\'t you like about them?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Talk to me Speaker 2: How do you feel about the color orange  Response: I\\'m a fan Feedback: The response is incorrect because it is slightly abrupt and unclear. A better response would be, \"I love the color orange. Especially the shades you see in sunsets.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Do you ever randomly catch a whiff of a specific smell and immediately think \"hey, that\\'s the way it smelled in the spring of 2001 when I was playing Pokemon at my grandma\\'s house\" Speaker 2: I only played pokemon at my grandma\\'s in the spring of 1997, sorry.  Response: I played pokemon at my grandma\\'s in the spring of 1997, sorry. Feedback: The response is wrong because it repeats the last statement in the context about playing pokemon in the spring of 1997. A better response would be, \"I\\'m not sure I do, but that\\'s interesting to hear. Do you still play pokemon?\"',\n",
              " 'Review this dialog: Context: Speaker 1: I\\'M GONNA DO IT Speaker 2: YES U ARE  Response: I\\'M GON Feedback: The response is incorrect because it ends abruptly and is incomplete. A better response would be, \"What did you want me to do, again?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Oof that post history.. well at least we know youre ugly on the inside too Speaker 2: Now that\\'s an eye opener. Jesus  Response: I\\'m not Jesus, but I\\'m pretty sure Jesus is pretty ugly on the inside. Feedback: The response is wrong because it talks about religious matters (Jesus) inappropriately. A better response would be, \"I\\'m sorry I offended you.\"',\n",
              " 'Review this dialog: Context: Speaker 1: 88! Speaker 2: r/unexpectedfactorial  Response:  Feedback: The response is incorrect because it is empty. A better response would be, \"I\\'m not sure what that means.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Happy Diwali Speaker 2: Same to you!!  Response: Happy Diwali Feedback: The response is wrong because \"Happy Diwali\" has already been said in a previous message by the same person. A better response would be, \"Diwali is a festival of lights! How are you going to celebrate?\"',\n",
              " 'Review this dialog: Context: Speaker 1: I ’ Ve lost my purse .  Response:  Oh no! I hope you find it soon. Did you check your purse\\'s pockets? Feedback: The response is incorrect because it asks whether the purse pockets have been checked, which is not possible to do when the purse has been lost, as stated in the context. A better response would be, \"Oh no! I hope you find it soon. When is the last time you remember seeing it?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Did you bring your certificate for nursing ?  Response:  Yes, I have been studying for it for a while now. I am ready to take the exam. Feedback: The response is wrong because it is irrelevant to the context. The question asked is whether a certificate has been brought, while the response is about a different topic, studying for an exam. A better response would be, \"I think I have it here somewhere. Let me check.\"',\n",
              " 'Review this dialog: Context: Speaker 1: It says here that you graduated from Beijing Normal University with a major in English Language and Literature . Response:  That is correct. I studied English literature at the University of Pennsylvania. Feedback: The response is incorrect because it contradicts the part about Beijing Normal University in the context after agreeing to it by saying it is correct. A better response would be, \"That is correct. I studied English literature at Beijing Normal University.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Hello . I sent out my laundry yesterday.Aren \\' t they ready ? Response:  I\\'m sure they will be.  What are you going to do with your clothes now? Feedback: The response is wrong because it asks what the author is going to do with their clothes after receiving them from the laundry, which is a weird question to ask, as the answer is obvious. A better response would be, \"I\\'m sure they will be.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Hello , welcome to Lincoln Bank . What can we do for you today ?  Response:  I am going to go to the bank and get some money to pay off my student loans. Feedback: The response is incorrect because it talks about going to the bank while already present at the bank, as indicated by the context that welcomes the addressee at Lincoln Bank. A better response would be, \"Hi, I\\'d like to open a bank account, could you help me?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Excuse me , do you have the latest issue of Newsworld ?  Response:  No, I don\\'t. I\\'m not a big fan of the New York Times. Feedback: The response is wrong because it misunderstands Newsworld as the New York Times. A better response would be, \"No, I don\\'t. Do you like reading it?\"',\n",
              " 'Review this dialog: Context: Speaker 1: I want to send some money to Australia . Could you handle it for me ?  Response:  Australia is a great place to visit, but I don\\'t think I\\'d want to live there. Feedback: The response is incorrect because it does not answer the question asked, and deviates from the context a bit. A better response would be, \"I\\'m afraid I do not have a bank account.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Good afternoon . Is this the Roley Hotel ?  Response:  Yes, it is.  I love the Royal Opera House.  Have you ever been? Feedback: The response is wrong because it misunderstands the Roley Hotel as the Royal Opera House. A better response would be, \"Good afternoon, yes it is the Roley Hotel. How can I help you today?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Peter , it\\'s time to get up .  Response:  Peter is a great name for a dog.  I have a dog named Peter.  Do you have any pets? Feedback: The response is incorrect because it inappropriately refers to Peter as a dog\\'s name, while it is a person\\'s name. A better response would be, \"Oh, is it already? What time is it?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Here is the draft contract , Mr . Brown . Let\\'s discuss the clauses to see if we agree on all of them . Then I will make out an original of the contract . After that , what\\'s left is to fill out the contract and sign our names . Speaker 2: That\\'s OK .  Response:  Feedback: The response is incorrect because it is blank. A better response would be, \"Great, I\\'ll let you know once an original copy of the contract is ready.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Certainty.Do you want double breasted suit or single breasted suit ? Speaker 2: I prefer single breasted suit .  Response: Yes, I\\'ll take it. Feedback: The response is wrong because it does not fit the context well. With the responder having asked whether a double breasted or single breasted suit is preferred earlier, the response does not make sense. A better response would be, \"Alright, noted!\"',\n",
              " 'Review this dialog: Context: Speaker 1: Yes , you are right . After all , the quality of your air conditioners is good . The only problem is price . Speaker 2: I should not be surprised , many customers have the same opinion . Speaker 1: Do you have any suggestion in mind ? Speaker 2: Our salesman told your secretary that the price could be negotiable .  Response: I\\'m afraid that\\'s too high a price. Feedback: The response is incorrect because it does not fit the context well, and says the price is too high while no price has been mentioned. A better response would be, \"Oh, did he? What would your best offer be?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Do you think you are introverted or extroverted ? Speaker 2: I\\'m quite outgoing i think . I enjoy mixing and doing things with others .  Response: Do you think you are introverted or extroverted Feedback: The response is incorrect because it repeats the question already asked by the responder in the context. A better response would be, \"That\\'s nice. I\\'m quite extroverted as well. What is your favorite activity to do outdoors?\"',\n",
              " 'Review this dialog: Context: Speaker 1: Margaret , I\\'d like to follow up with the arrangements for our company retreat , to take place next month . We need to book the venue , make arrangements for speakers and door prizes , and set up all the activities and accommodations . Also , very important , we need to determine which of our staff will be eligible and will be available to go . We\\'ve got to get a head count in order to make reservations . Speaker 2: What\\'s the criteria for staff to attend ? Are we only including our management team in this affair ? Or will we be extending invitations to lower level employees to attend ?  Response: I\\'m afraid that we can\\'t go any further Feedback: The response is wrong because it does not make sense in the context, which discusses arrangements to be made for the company retreat. There is no reason to stop proceedings, and the response doesn\\'t provide one either. A better response would be, \"I\\'m not sure. What do you think we should do?\"',\n",
              " 'Review this dialog: Context: Speaker 1: I think Yoga might be suitable for me . Speaker 2: Why ?  Response: Because you are a beginner. Feedback: The response is incorrect because it talks about the addressee being a beginner, instead of the responder, as it should be based on the first statement in the context (\\'suitable for \"me\"\\'). A better response would be, \"Because I am a beginner.\"',\n",
              " 'Review this dialog: Context: Speaker 1: Overwork-amongst other things . You can\\'t work 24 hours a day . You \\' Ve got to slow down . Speaker 2: But I can\\'t just slow down .\",  Response: You can\\'t just work 24 hours a day? Feedback: The response is wrong because the responder already advises the addressee to not work 24 hours a day, making the response inappropriate and incoherent with the context. A better response would be, \"You must take care of your health!\"']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\",    \n",
        "                            bos_token=\"<|startoftext|>\",\n",
        "                            eos_token=\"<|endoftext|>\",\n",
        "                            pad_token=\"<|pad|>\")\n",
        "checkpoint = \"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/gpt2-large-lm-lr2e-5-bs10-ne-3/checkpoint-7\"\n",
        "model = GPT2LMHeadModel.from_pretrained(checkpoint).to(device)\n",
        "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "# Resize the token embeddings because we've just added 3 new tokens \n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "XxqDUZK5_meq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"\"\"Review this dialog: Context: Oh , thank you . Could I interest you in our store credit card ? Response: Yes, I'd like to purchase some groceries. Feedback: \"\"\"\n",
        "# tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "# input_ids = tokenized['input_ids'].to('cuda')\n",
        "# # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "# # generate up to 30 tokens\n",
        "# outputs = model.generate(input_ids, do_sample=False, max_length=200)\n",
        "# tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "# # ['Today I believe we can finally get to the point where we can make a difference in the lives of the people of the United States of America.\\n']"
      ],
      "metadata": {
        "id": "tvM24aJczRgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/annotated-feedback-model-responses/iitkgp-mtp-dialog-model-responses-2.csv\")\n",
        "# test_data"
      ],
      "metadata": {
        "id": "hOcKNjWzy6Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(test_data)):\n",
        "#     if test_data.at[i, 'model_name'] == \"CORAL ESIM-gen\":\n",
        "#         print(process_coral_context(test_data.at[i, 'context']))"
      ],
      "metadata": {
        "id": "m7Lqg17tCaa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_results(model, tokenizer, test_data, dialog_model_name, learning_rate, batch_size, num_epochs):\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    print(f\"Feedback results for {dialog_model_name}'s responses, with\\nModel Learning_rate = {learning_rate}, Batch_size = {batch_size}, Num_epochs = {num_epochs}:\\n\")\n",
        "    for i in range(len(test_data)):\n",
        "        if test_data.at[i, 'model_name'] == dialog_model_name:\n",
        "            if dialog_model_name.startswith(\"Blender\"):\n",
        "                prompt = process_blenderbot_context(test_data.at[i, 'context']) + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "            elif dialog_model_name.startswith(\"CORAL\"):\n",
        "                prompt = process_coral_context(test_data.at[i, 'context']) + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "            tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "            input_ids = tokenized['input_ids'].to('cuda')\n",
        "\n",
        "            outputs = model.generate(input_ids, do_sample=False, max_length=200, num_beams=5)\n",
        "            print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "            model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "            feedback_starts = model_response.find(\"Feedback: \")\n",
        "            print(\"Model Response: \" + model_response[feedback_starts + 11:])\n",
        "            print()"
      ],
      "metadata": {
        "id": "ud1TiF6FOspd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## checkpoint-21 (3 epochs)\n",
        "generate_results(model, tokenizer, test_data, \"Blenderbot-1B\", \"5e-6\", \"10\", \"3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUzNm8mFd892",
        "outputId": "a6ebc429-1d9a-4508-e706-05c92966526f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback results for Blenderbot-1B's responses, with\n",
            "Model Learning_rate = 5e-6, Batch_size = 10, Num_epochs = 3:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I love being a dog.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: Well, I love to travel. I've been all over the world. What about you?\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I know, right?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: Response: Neither did I, but I'm glad I did. It was a lot of fun.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not sure what I'm going to do with it.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's cool. What kind of music do you like to listen to while you're in the movie?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: The response is incorrect because it is unrelated to the context. A better response would be, \"I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it does not match the context. A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks for asking.\" A better response would be, \"I'm doing well, thanks\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh my gosh, that is so creepy! Did you say anything to him?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Yes, what do you know about IBA?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it does not match the context. A better response would be, \"How are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: The train is leaving. Hurry up! Which car are we in? It's a Toyota Corolla. It's the best car I've ever owned.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: The response is incorrect because it is unrelated to the context. A better response would be, \"That's great! I hope you get the job.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: The response, \"I have never heard of Tsingtao beer,\" is incorrect because it is grammatically incorrect. A better response would be, \"I have never heard of Tsingtao beer.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: No response.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Hi, how are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## checkpoint-21 (3 epochs)\n",
        "generate_results(model, tokenizer, test_data, \"Blenderbot-1B\", \"5e-6\", \"10\", \"3\")"
      ],
      "metadata": {
        "id": "IwWQsLr6eHyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVzLx0vXeJwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGrkF-nMeHvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## checkpoint-7 (1 epoch)\n",
        "generate_results(model, tokenizer, test_data, \"Blenderbot-1B\", \"2e-5\", \"10\", \"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMFLYD2-W6Lm",
        "outputId": "1fb6a63a-845a-472c-b7da-4b18f6b398cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback results for Blenderbot-1B's responses, with\n",
            "Model Learning_rate = 1e-5, Batch_size = 10, Num_epochs = 1:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: Response: Yes, I love being a dog. It's a lot of work, but it's worth it. Response: Yes, I love being a dog. It's a lot of work, but it's worth it. Response: Yes, I love being a dog. It's a lot of work, but it's worth it. Response: Yes, I love being a dog. It's a lot of work, but it's worth it. Response: Yes, I love being a dog. It's a lot of work, but it's worth it. Response: Yes, I love being a dog. It's a lot of work, but it's worth it. Response: Yes, I love being a dog. It's a lot of work\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love to travel. I've been all over the world. What about you? Response:  Well, I love\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: This response is not appropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this dialog. This response is inappropriate for this\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: Thank you for your feedback. We appreciate your feedback and will be in touch soon.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: That's pretty cool. What kind of music do you like to listen to while you're in the movie?\n",
            "\n",
            "Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie?\n",
            "\n",
            "Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie?\n",
            "\n",
            "Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie?\n",
            "\n",
            "Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie?\n",
            "\n",
            "Response:  That's pretty cool. What kind of music do you like\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: Thank you for your feedback. We would like to respond to this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback:  Thank you for your feedback. We would like to respond to this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback:  Thank you for your feedback. We would like to respond to this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: Response: Hi, how are you today? I'm doing well, thanks for asking. How are you? Response: Hi, how are you today? I'm doing well, thanks for asking. How are you? Response: Hi, how are you today? I'm doing well, thanks for asking. How are you? Response: Hi, how are you today? I'm doing well, thanks for asking. How are you? Response: Hi, how are you today? I'm doing well, thanks for asking. How are you? Response: Hi, how are you today? I'm doing well, thanks for asking. How are you? Response: Hi, how are you today? I'm doing well, thanks for asking. How are you\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: Thank you for your feedback. We appreciate your feedback and will be in touch soon.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:  I'm not sure what you mean by that, but thank you for the compliment. Response:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: Thank you for your interest in IBA. I would like to help you learn more about IBA. I have been studying it for a few years now. I would like to help you learn more about IBA. I have been studying it for a few years now. I would like to help you learn more about IBA. I have been studying it for a few years now. I would like to help you learn more about IBA. I have been studying it for a few years now. I would like to help you learn more about IBA. I have been studying it for a few years now. I would like to help you learn more about IBA. I have been studying it for a few years now. I would like to help\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: Response:  Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response: Response:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: Response:  I don't mind at all. I wait tables, so I know how you feel. Response:  I don't mind at all. I wait tables, so I know how you feel. Response:  I don't mind at all. I wait tables, so I know how you feel. Response:  I don't mind at all. I wait tables, so I know how you feel. Response:  I don't mind at all. I wait tables, so I know how you feel. Response:  I don't mind at all. I wait tables, so I know how you feel. Response:  I don't mind at all. I wait tables, so I know how you feel. Response: \n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: The train is leaving. Hurry up! Which car are we in? It's a Toyota Corolla. It's the best car I've ever owned. Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Response:  It's a Toyota Corolla.  It's the\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play? Response:  I'm sorry to hear that. What kind of instruments do you play\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for?\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: Response:  I have never heard of Tsingtao beer.  What is it?  Do you like it? Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:  I have never heard of Tsingtao beer. Response:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response:  Thank you for your feedback. We look forward to hearing from you. Response: \n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: Response:  Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Response:  Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Response:  Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Response:  Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response:  Response: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## checkpoint-14 (2 epochs)\n",
        "generate_results(model, tokenizer, test_data, \"Blenderbot-1B\", \"1e-5\", \"10\", \"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC3h7tmAWrW5",
        "outputId": "7b222a80-92db-4a0c-c78c-cb730c4df2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback results for Blenderbot-1B's responses, with\n",
            "Model Learning_rate = 1e-5, Batch_size = 10, Num_epochs = 1:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Yes, I love being a dog.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"What about you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I know, right?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's great! I never learned that!\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Thank you for taking the test. I'll be sure to pass it.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's pretty cool. What kind of music do you like to listen to while you're in the movie?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it does not match the context. A better response would be, \"I'm doing well, thanks for asking.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: The response is incorrect because the context is incorrect. The response is \"Oh my gosh, that is so creepy! Did you say anything to him?\" The response is \"Oh my gosh, that is so creepy! Did you say anything to him?\" The response is \"Oh my gosh, that is so creepy! Did you say anything to him?\" The response is \"Oh my gosh, that is so creepy! Did you say anything to him?\" The response is \"Oh my gosh, that is so creepy! Did you say anything to him?\" The response is \"Oh my gosh, that\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Sure, what do you know about IBA?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I am fine, thank you for asking.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"It's a Toyota Corolla. It's the best car I've ever owned.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's great! I hope you get the job. What kind of job are you applying for?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I have never heard of Tsingtao beer.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh, I love that show!\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Hi, how are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: The response is incorrect because it implies that Peter Parker is a fictional character created by J.K. Rowling. A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## checkpoint-21 (3 epochs)\n",
        "generate_results(model, tokenizer, test_data, \"Blenderbot-1B\", \"1e-5\", \"10\", \"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps7Y-QIlP-Pf",
        "outputId": "b325738b-c53e-4362-8737-0000242c5eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback results for Blenderbot-1B's responses, with\n",
            "Model Learning_rate = 1e-5, Batch_size = 10, Num_epochs = 1:\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Yes, I love being a dog.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: The response is incorrect because it is unrelated to the context. A better response would be, \"What about you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I know, right?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's great!\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: The response is incorrect because it is unrelated to the context. A better response would be, \"Congratulations! That's a big accomplishment. What are you going to do with it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: The response is incorrect because it is unrelated to the context. A better response would be, \"That's pretty cool. What kind of music do you like to listen to while you're in the movie?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm doing well, thanks for asking.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh my gosh, that is so creepy! Did you say anything to him?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Sure, what do you know about IBA?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"How are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"It's a Toyota Corolla. It's the best car I've ever owned.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's great! I hope you get the job. What kind of job are you applying for?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: The response is incorrect because it is unrelated to the context. A better response would be, \"I have never heard of Tsingtao beer.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh, I love that show!\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Hi, how are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Peter, enough with your computer games. Go do your homework now.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 1 epoch, lr=2e-5, bs=10\n",
        "### CORAL ESIM-gen\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"CORAL ESIM-gen\":\n",
        "        # print('yay')\n",
        "        # try:\n",
        "            prompt = process_coral_context(test_data.at[i, 'context']) + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "            tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "            input_ids = tokenized['input_ids'].to('cuda')\n",
        "            # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "            # generate up to 30 tokens\n",
        "            outputs = model.generate(input_ids, do_sample=False, max_length=200, num_beams=5)\n",
        "            print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "            print(\"Model Response: \" + tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].replace(prompt, \"\"))\n",
        "            print()\n",
        "        # except:\n",
        "        #     continue"
      ],
      "metadata": {
        "id": "GRSXm05mOpjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1 epoch, lr=2e-5, bs=1\n",
        "### CORAL ESIM-gen\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"CORAL ESIM-gen\":\n",
        "        # print('yay')\n",
        "        # try:\n",
        "            prompt = process_coral_context(test_data.at[i, 'context']) + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "            tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "            input_ids = tokenized['input_ids'].to('cuda')\n",
        "            # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "            # generate up to 30 tokens\n",
        "            outputs = model.generate(input_ids, do_sample=False, max_length=200, num_beams=5)\n",
        "            print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "            print(\"Model Response: \" + tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].replace(prompt, \"\"))\n",
        "            print()\n",
        "        # except:\n",
        "        #     continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFJXF-o-TS_I",
        "outputId": "5ba0e4e7-d7a2-4028-9580-1d2d0cd8fd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: i really need to start eating healthier. Speaker 2: i have to start eating better too.  Response: how long is it? how did you know????'s?? Feedback: \n",
            "Model Response:  The response is incorrect because it is grammatically incorrect. A better response would be, \"How long is it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: good afternoon! can i help you? Speaker 2: could you show me where the chinesc - style clothing is located? i want to buy a silk coat. Speaker 1: this way, please. here they are. they're all handmade.  Response: that's right. i'm so happy to see you tomorrow..?. Feedback: \n",
            "Model Response: \n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: next, please. hello, may i help you, sir? Speaker 2: yes, i want to send a registered airmail letter to france.  Response: i just went out. that's why i was my out. Feedback: \n",
            "Model Response:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm sorry, but I don't have a registered mail address.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: why'd you pull me over? Speaker 2: are you aware that you drove through a red light?  Response: thank you. i don't think it's very nice.,.''.. Feedback: \n",
            "Model Response:  Response: thank you. i don't think it's very nice.,.''..\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: room service, is there anything i can do for you? Speaker 2: yes, i am afraid there are not enough outlets.  Response: thanks a lot. let's go. Feedback: \n",
            "Model Response: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 1 epoch, lr=2e-5\n",
        "### BLENDERBOT\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"Blenderbot-1B\":\n",
        "            prompt = process_blenderbot_context(test_data.at[i, 'context']) + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "            tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "            input_ids = tokenized['input_ids'].to('cuda')\n",
        "\n",
        "            outputs = model.generate(input_ids, do_sample=False, max_length=200, num_beams=5)\n",
        "            print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "            model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "            feedback_starts = model_response.find(\"Feedback: \")\n",
        "            print(\"Model Response: \" + model_response[feedback_starts + 11:])\n",
        "            print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PNjS6NpFT7p",
        "outputId": "b5c2a3aa-12da-4735-dd0a-bedd1d02f409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Yes, I love being a dog.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: The response is incorrect because it does not answer the question. A better response would be, \"I love to travel.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I know, right?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's great!\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Congratulations! That's a big accomplishment. What are you going to do with it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's pretty cool. What kind of music do you like to listen to while you're in the movie?\" A better response would be, \"That's pretty cool. What kind of music do you like to listen to while you're in the movie?\" A better response would be, \"That's pretty cool. What kind of music do you like to listen to while you're in the movie?\" A better response would be, \"That's pretty cool. What kind of music do you like to listen to while you're in the movie?\" A better response would be, \"That's pretty cool. What kind of music do you like to\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it does not match the context. A better response would be, \"I'm doing well, thanks for asking.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh my gosh, that is so creepy! Did you say anything to him?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Sure, what do you know about IBA?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"How are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\" A better response would be, \"I don't mind at all.\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"It's a Toyota Corolla.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh no, I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"That's great! I hope you get the job.\" A better response would be, \"That's great! I hope you get the job.\" A better response would be, \"That's great! I hope you get the job.\" A better response would be, \"That's great! I hope you get the job.\" A better response would be, \"That's great! I hope you get the job.\" A better response would be, \"That's great! I hope you get the job.\" A better response would be, \"That's great! I hope you get the job\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: The response is incorrect because it does not answer the question. A better response would be, \"I have never heard of Tsingtao beer.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh, I love that show!\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Hi, how are you?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: The response is incorrect because it is grammatically incorrect. A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K. Rowling.\" A better response would be, \"Peter Parker is a fictional character created by J.K.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4GfGJuiFgrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TR8lQUW4Fgo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 2 epoch, lr=0.5e-5\n",
        "### BLENDERBOT\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"Blenderbot-1B\":\n",
        "        prompt = \"Review this dialog: Context: Speaker 1: \" + test_data.at[i, 'context'] + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "        tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        input_ids = tokenized['input_ids'].to('cuda')\n",
        "        # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "        # generate up to 30 tokens\n",
        "        outputs = model.generate(input_ids, do_sample=False, max_length=200)\n",
        "        print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "        print(\"Model Response: \" + tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23fIsYUVOYe6",
        "outputId": "13aaa0ba-417f-417e-a9bc-d60401b9b2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I love being a dog.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback:  The response is incorrect because it is not a question. A better response would be, \"Tell me about yourself.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I know, right?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback:  The response is incorrect because it is not a response to the question. A better response would be, \"That's great! I never learned how to play the piano.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"Congratulations! That's a big accomplishment. What are you going to do with it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback:  The response is incorrect because it is not a question. A better response would be, \"I like to listen to music while I'm in the movie.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback:  The response is incorrect because it is not a response to the question. A better response would be, \"Oh, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback:  Response: I'm doing well, thanks for asking. How are you? Feedback: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm doing well, thanks for asking.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback:  The response is incorrect because it is not a response to the question. A better response would be, \"I'm sorry, I don't know what that means.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm glad you asked. I'm\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm fine, thank you for asking.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"It's a Toyota Corolla. It's the best car I've ever owned.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm looking for a job in the field of computer science. What kind of job are you applying for?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback:  The response is incorrect because it is not relevant to the context. A better response would be, \"I have never heard of Tsingtao beer.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I love that show, too.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm looking for a flight to Beijing. What's the best way to get there?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"Peter, enough with your computer games. Go do your homework now.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 1 epoch, lr=2e-5\n",
        "### BLENDERBOT\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"Blenderbot-1B\":\n",
        "        try:\n",
        "            prompt = \"Review this dialog: Context: Speaker 1: \" + test_data.at[i, 'context'] + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "            tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "            input_ids = tokenized['input_ids'].to('cuda')\n",
        "            # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "            # generate up to 30 tokens\n",
        "            outputs = model.generate(input_ids, do_sample=False, max_length=200)\n",
        "            print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "            print(\"Model Response: \" + tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n",
        "            print()\n",
        "        except:\n",
        "            continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKzc6id8OoPA",
        "outputId": "8a92cae6-9d75-4c1a-8fb9-238bc9c21513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: For what? Are you taking up painting? No. I can't paint. I'm asking for my niece. She is really into it. Response: <no-response> Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: For what? Are you taking up painting? No. I can't paint. I'm asking for my niece. She is really into it. Response: <no-response> Feedback:  Response: I'm sorry, I'm not sure what you mean. I'm not sure if I can paint. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything. I'm not sure if I can do anything\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Oh, thank you. Could I interest you in our store credit card? Response: Yes, I'd like to purchase some groceries. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Oh, thank you. Could I interest you in our store credit card? Response: Yes, I'd like to purchase some groceries. Feedback:  Response: Thank you for your interest in our store credit card. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We are happy to help you. We\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Good morning, may I speak with Professor Clark, please? You are speaking with Professor Clark. Response: Yes, I am. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Good morning, may I speak with Professor Clark, please? You are speaking with Professor Clark. Response: Yes, I am. Feedback:  Response: Thank you for your interest in my course. I am pleased to inform you that the course is now available for registration. I look forward to hearing from you soon.  Response: Thank you for your interest in my course. I am pleased to inform you that the course is now available for registration. I look forward to hearing from you soon.  Response: Thank you for your interest in my course. I am pleased to inform you that the course is now available for registration. I look forward to hearing from you soon.  Response: Thank you for your interest in my course. I am pleased to inform you that the course is now available for registration. I look forward to hearing from you soon.  Response: Thank you for your interest in my course. I am pleased to inform you that\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Honey, I need to have a talk with you. Dad, I have to do my homework. Response: You're not going to do your homework? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Honey, I need to have a talk with you. Dad, I have to do my homework. Response: You're not going to do your homework? Feedback:  Response: I'm not going to do my homework. Feedback: The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm not going to do my homework.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: What's wrong with you, young man? Doctor, I have a bad cough and a headache. Response: Oh, I'm sorry to hear that. What's the matter? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: What's wrong with you, young man? Doctor, I have a bad cough and a headache. Response: Oh, I'm sorry to hear that. What's the matter? Feedback:  Response: I'm sorry to hear that. What's the matter?\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Don't worry, we'll soon fix them. Good, I hope you'll make sure that it won't happen again. Response: <no-response> Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Don't worry, we'll soon fix them. Good, I hope you'll make sure that it won't happen again. Response: <no-response> Feedback:  Response: I'm sorry, I don't know what to say. I'm sorry, I don't know what to say. Feedback: The response is incorrect because it is not a response. A better response would be, \"I'm sorry, I don't know what to say.\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Of course. It sounds great. I'll take it. Response: Alright, I'll take it. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Of course. It sounds great. I'll take it. Response: Alright, I'll take it. Feedback:  Response: I'll take it. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 1 epoch, lr=2e-5\n",
        "### BLENDERBOT\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"Blenderbot-1B\":\n",
        "        prompt = \"Review this dialog: Context: Speaker 1: \" + test_data.at[i, 'context'] + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "        tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        input_ids = tokenized['input_ids'].to('cuda')\n",
        "        # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "        # generate up to 30 tokens\n",
        "        outputs = model.generate(input_ids, do_sample=False, max_length=200)\n",
        "        print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "        print(\"Model Response: \" + tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycKhyUI3MApI",
        "outputId": "34f086a8-050d-4de2-f248-589247885663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I love being a dog.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback:  The response is incorrect because it is not a question. A better response would be, \"I love to travel. What about you?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I know, right? I was so mad at myself.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback:  The response is incorrect because it is not coherent. A better response would be, \"I'm glad I did. It was a lot of fun.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback:  The response is incorrect because it is unrelated to the context. A better response would be, \"I'm going to take it as a challenge.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback:  The response is incorrect because it is unrelated to the context. A better response would be, \"I'm not sure. What kind of music do you like to listen to while you're in the movie?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback:  The response is incorrect because it is not a response to the question. A better response would be, \"Oh, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm doing well, thanks for asking.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback:  The response is incorrect because it is unrelated to the context. A better response would be, \"Oh, I'm sorry, I didn't know what that meant.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback:  The response is incorrect because it is not a compliment. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm glad you like it. What do you think of it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm doing well, thank you for asking.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm sorry, but I don't know. What do you think?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback:  The response is incorrect because it is not coherent. A better response would be, \"I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"I'm looking for a job. What kind of job are you applying for?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback:  The response is incorrect because it is unrelated to the context. A better response would be, \"I have never heard of Tsingtao beer.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"Oh, I love that show! It's one of my favorites.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"Hi, I'm a fan of your airline. What do you think of them?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback:  The response is incorrect because it is grammatically incorrect. A better response would be, \"Peter, I'm sorry to hear that. I'm sure you'll be doing a lot better in school.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 2 epochs, lr=2e-5\n",
        "### BLENDERBOT\n",
        "for i in range(len(test_data)):\n",
        "    if test_data.at[i, 'model_name'] == \"Blenderbot-1B\":\n",
        "        prompt = \"Review this dialog: Context: Speaker 1: \" + test_data.at[i, 'context'] + \" Response: \" + test_data.at[i, 'model_response'] + \" Feedback: \"\n",
        "        tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        input_ids = tokenized['input_ids'].to('cuda')\n",
        "        # attn_mask = tokenized['attention_mask'].to('cuda')\n",
        "\n",
        "        # generate up to 30 tokens\n",
        "        outputs = model.generate(input_ids, do_sample=False, max_length=200)\n",
        "        print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "        print(\"Model Response: \" + tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf0p0GFQ6WjA",
        "outputId": "f9961e33-4747-4538-fb9a-bf67e1c5d8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I love being a dog.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Well, I love to travel. I've been all over the world.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I know, right? I was so mad at myself.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"That's great! I never learned about it.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Congratulations! That's a big accomplishment. What are you going to do with it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I like to listen to a lot of different kinds of music.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh no, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I'm doing well, thanks for asking.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh, I'm sure you know what that means. What's the story behind it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Sure, what do you know about IBA?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Hi, how are you doing?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"It's a Toyota Corolla. What car are you in?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh no, I'm sorry to hear that. What kind of instruments do you play?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"That's great! I hope you get the job. What kind of job are you applying for?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I have never heard of Tsingtao beer. What is it?\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh, I love that show! It's one of my favorites.\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Sure, what do you want to know about them?\"\n",
            "\n",
            "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
            "Model Response: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Peter, enough with your computer games. Go do your homework now.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Prompt: Review this dialog: Context: Speaker 1: And fun to be aound. Hahha Response: Yes, I love being a dog.  It's a lot of work, but it's worth it. Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I love being a dog.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Tell me 3 interesting facts about yourself. Response:  Well, I love to travel. I've been all over the world. What about you? Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Well, I love to travel. I've been all over the world.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: DAMN YOU PIZZA Response:  I know, right?  I was so mad at myself.  I should have known better. Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I know, right? I was so mad at myself.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: That's great! I never learned :/ Response:  Neither did I, but I'm glad I did. It was a lot of fun. Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"That's great! I never learned about it.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: I just passed my General Chemistry exam! :) Response:  Congratulations!  That's a big accomplishment.  What are you going to do with it? Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Congratulations! That's a big accomplishment. What are you going to do with it?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: I've been in a movie, a tv show, and a music video. Response:  That's pretty cool. What kind of music do you like to listen to while you're in the movie? Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I like to listen to a lot of different kinds of music.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Just found out my fourth consecutive crush is gay. Again. Response:  Oh no, I'm sorry to hear that. Have you tried talking to them about it? Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh no, I'm sorry to hear that. Have you tried talking to them about it?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: 😀😊☺🍔🍟 Response:  Hi, how are you today? I'm doing well, thanks for asking. How are you? Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I'm doing well, thanks for asking.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: I was wearing a \"Hakuna Matata\" Lion King shirt yesterday and an African man walked up to me and pointed at it asking \"Do you know what that means?\" Response:  Oh my gosh, that is so creepy! Did you say anything to him? I would have been so scared! Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh, I'm sure you know what that means. What's the story behind it?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: if you could be anything.. Response:  I'm not sure what you mean by that, but thank you for the compliment. Feedback: \n",
        "Model Response:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I'm not sure what you mean by that, but thank you for the compliment.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Welcome to IBA. Can I help you?  Response:  Sure, what do you know about IBA?  I have been studying it for a few years now. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Sure, what do you know about IBA?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Hello, this is Lucy. May I speak to Mr. Smith?  Response:  Hi Lucy, how are you today? I am fine, thank you for asking. How are you? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Hi, how are you doing?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Waiter, we have been waiting for 20 minutes. Would you mind hurrying? Response:  I don't mind at all. I wait tables, so I know how you feel. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I don't mind at all. I wait tables, so I know how you feel.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: The train is leaving. Hurry up! Which car are we in?  Response:  It's a Toyota Corolla.  It's the best car I've ever owned. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"It's a Toyota Corolla. What car are you in?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: The consignments of chemical instruments have just reached us. We have to lodge a claim against you for inferior quality I am afraid. Response:  Oh no, I'm sorry to hear that. What kind of instruments do you play? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh no, I'm sorry to hear that. What kind of instruments do you play?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Good morning.sir.My name is Liu Peng from Tsinghai University. I am here for the interview relating to my visa application. Response:  That's great! I hope you get the job. What kind of job are you applying for? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"That's great! I hope you get the job. What kind of job are you applying for?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: May I recommend you Tsingtao beer?  Response:  I have never heard of Tsingo beer.  What is it?  Do you like it? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"I have never heard of Tsingtao beer. What is it?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Marry Lin's Office, this is Linda.  Response:  Oh, I love that show!  It's one of my favorites.  Have you seen it? Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Oh, I love that show! It's one of my favorites.\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Hello, China Southern Airlines. Can I help you?  Response:  Sure, what do you want to know about them? They are an American multinational airline based in Honolulu, Hawaii. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Sure, what do you want to know about them?\"\n",
        "\n",
        "Prompt: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback: \n",
        "Model Response: Review this dialog: Context: Speaker 1: Peter, enough with your computer games. Go do your homework now.  Response:  Peter Parker is a fictional character created by J.K. Rowling. Feedback:  The response is incorrect because it is grammatically wrong and unrelated to the context. A better response would be, \"Peter, enough with your computer games. Go do your homework now.\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aacIgElA-9gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Likert Prompts Training**"
      ],
      "metadata": {
        "id": "6EWCZyQmVy2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\"\"\""
      ],
      "metadata": {
        "id": "Et0uv1m1kmYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/tc_all_prompts.pkl\", \"rb\") as f1:\n",
        "    tc_all_prompts = pkl.load(f1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/tc_all_labels.pkl\", \"rb\") as f1:\n",
        "    tc_all_labels = pkl.load(f1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/pc_all_prompts.pkl\", \"rb\") as f1:\n",
        "    pc_all_prompts = pkl.load(f1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/pc_all_labels.pkl\", \"rb\") as f1:\n",
        "    pc_all_labels = pkl.load(f1)\n",
        "\n",
        "pc_all_prompts_labelled = [-1] * len(pc_all_prompts)\n",
        "tc_all_prompts_labelled = [-1] * len(tc_all_prompts)\n",
        "for i, each in enumerate(pc_all_prompts):\n",
        "    prompt_here = pc_all_prompts[i]\n",
        "    label_1 = round(np.mean(np.array(pc_all_labels[i][0])))\n",
        "    label_2 = round(np.mean(np.array(pc_all_labels[i][1])))\n",
        "    label_3 = round(np.mean(np.array(pc_all_labels[i][2])))\n",
        "    label_4 = round(np.mean(np.array(pc_all_labels[i][3])))\n",
        "    label_5 = round(np.mean(np.array(pc_all_labels[i][4])))\n",
        "    label_6 = round(np.mean(np.array(pc_all_labels[i][5])))\n",
        "    # all_prompts[i] = prefix + each + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Overall Quality: {str(label_5)}\"\n",
        "    # pc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Uses Knowledge: {str(label_5)}\\n6. Overall Quality: {str(label_6)}\"\n",
        "    pc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. {str(label_1)}\\n2. {str(label_2)}\\n3. {str(label_3)}\\n4. {str(label_4)}\\n5. {str(label_5)}\\n6. {str(label_6)}\"\n",
        "\n",
        "for i, each in enumerate(tc_all_prompts):\n",
        "    prompt_here = tc_all_prompts[i]\n",
        "    label_1 = round(np.mean(np.array(tc_all_labels[i][0])))\n",
        "    label_2 = round(np.mean(np.array(tc_all_labels[i][1])))\n",
        "    label_3 = round(np.mean(np.array(tc_all_labels[i][2])))\n",
        "    label_4 = round(np.mean(np.array(tc_all_labels[i][3])))\n",
        "    label_5 = round(np.mean(np.array(tc_all_labels[i][4])))\n",
        "    label_6 = round(np.mean(np.array(tc_all_labels[i][5])))\n",
        "    # all_prompts[i] = prefix + each + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Overall Quality: {str(label_5)}\"\n",
        "    # tc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Uses Knowledge: {str(label_5)}\\n6. Overall Quality: {str(label_6)}\"\n",
        "    tc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. {str(label_1)}\\n2. {str(label_2)}\\n3. {str(label_3)}\\n4. {str(label_4)}\\n5. {str(label_5)}\\n6. {str(label_6)}\""
      ],
      "metadata": {
        "id": "EEpo1Yk4V2-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts_labelled[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yfLe0zl2hln",
        "outputId": "b04b96c5-053f-4f6b-d6fe-6b063b430c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "Person 1: lead singer for a band , music teacher\n",
            "Person 2: wow nice are you really good ?\n",
            "Person 1: millions of plays on soundcloud\n",
            "Person 2: really would you share or are you shy\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i also have a dog walking business.\n",
            "Person 1's statement: i've three dogs.\n",
            "Person 1's statement: my father was a door to door salesman.\n",
            "Person 1's statement: i am in an open polyamorous relationship.\n",
            "Person 1's statement: i like to watch the olympics.\n",
            "\n",
            "Generated response: \n",
            "Person 1: ha ha i'm so shy\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n",
            "1. 1\n",
            "2. 3\n",
            "3. 3\n",
            "4. 1\n",
            "5. 0\n",
            "6. 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPTNeoForCausalLM, GPTNeoModel, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import random\n",
        "from torch import cuda\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "skcyesH4ZwRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to a fixed value to get reproducible results \n",
        "# torch.manual_seed(42)\n",
        "# Download the pre-trained GPT-Neo model's tokenizer\n",
        "# Add the custom tokens denoting the beginning and the end \n",
        "# of the sequence and a special token for padding\n",
        "\n",
        "# model_checkpoint = \"gpt2-medium\"\n",
        "# model_checkpoint = \"gpt2-large\"\n",
        "model_checkpoint = \"bigscience/bloom-560m\"\n",
        "# model_checkpoint = \"bigscience/bloom-1b1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint,\n",
        "#                             bos_token=\"<|startoftext|>\",\n",
        "#                             eos_token=\"<|endoftext|>\",\n",
        "#                             pad_token=\"<|pad|>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "12dd627a357e4aadaa94d446a728cc47",
            "48705b0fceab476885eff627428b9518",
            "28ad9831d5184727b0dcc9e737f0d727",
            "f4d1827914524f00a0dc9263f39dc43f",
            "e3d5721cc5e549b4b291a0eb1e5b44e9",
            "952795bb81d2412baf5d9f59775f0e54",
            "147d74777d824fb78d5dd43c8c58bbe6",
            "51c6f5ad09934375ac83422a67a7d572",
            "bbed481764024ad7bbbd8f6fa7546c1d",
            "3db2c71585e84aec9ae278c8b65f42db",
            "9d9b34ebf15c4104a1a67cc615332ec8",
            "e6eea0f6b52149ae90cfac0d9d06db01",
            "53501bc048a64e70a673f8f2b7e58718",
            "d247d718598f40e59e61113708058352",
            "8f5bc2d8c08a420a83d18d5fa6779949",
            "7716d9761d0b4a76b8c21e4e7085cdbe",
            "88c59a42d65144ada405a3c60816ca2d",
            "df00517a9d194c9d92105bcd3998dd49",
            "b6595ad303874c3aa9e4282116e1e598",
            "bfe57bdda43e4b83a77eb9790cd00439",
            "e61c1a95560d4dc08ea24f4e07e0f4f1",
            "3191a63890484b00b7d386090681a8d3",
            "c165cf56584e4760b87f845f8f267e55",
            "aad8ea102e3e4f70995357a26b99dcc1",
            "188282d5d81245f7a70290bb7100adee",
            "1d501f61d20743288acaa71588efc998",
            "ba26cdac76764dbebb336f199019c873",
            "c7e88564dad9499fa84515e0d5344b8e",
            "e0db174c60ab499eadebfc4c15c49d65",
            "853d7f8b43bb49dab7ceb5428cd48f07",
            "9de6599b63d54291b35c34303978f8fa",
            "096444d5998e4152b825344d95bd6491",
            "d9d33e406b2f4a6f80d68007ad087f23"
          ]
        },
        "outputId": "e51cb88d-baf3-4fb8-85fe-3f9b3ccb8c53",
        "id": "oc72dGqRZwRp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12dd627a357e4aadaa94d446a728cc47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6eea0f6b52149ae90cfac0d9d06db01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c165cf56584e4760b87f845f8f267e55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_checkpoint).to(device)\n",
        "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "# Resize the token embeddings because we've just added 3 new tokens \n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "86825ac4395c43b5b868dd1e58177be9",
            "e1c6f1701cec4d04bb45661f90681ad7",
            "ab177ef17a004bc29785cbcf7a21c694",
            "4a07adb2d6f848c7b85d0bcaa2aaf1a8",
            "d04f6e22e04849c59c16b741ea7a374f",
            "752b40210dea407fbad70017a2c31950",
            "4cb690543c33495397518cdb081622c0",
            "a6f6209277ad4a178ab43c97cbbe2b2a",
            "7910ea1364a449f0816cf9ecae227608",
            "94192cddf19847a0b7fc3c995e3c5b9c",
            "e640c3b60d1b48a6a579c64b91faea79",
            "1d503f8c8c4e47a8a0e85504a40b353d",
            "4444bb6f7a80414e8d6e077a34692bc8",
            "119135e7a95c4fb8907951f766be6f80",
            "9c127d6f936d47a89406070c9fb1c99a",
            "707fd6df8f2b45598c7f8d71cf42f4c1",
            "b0026c32cc2f41eeb587ea97a89ed7e8",
            "0b700844997e48d7bdf8f02f4c024268",
            "76af1fdd5a45496c8132f63107280429",
            "ed16a9cc2adc45d9b43ba7757d15b174",
            "729b18457ca247a896a4305d85c7d6ae",
            "805031bd3ef54063b059e34921c2f126"
          ]
        },
        "outputId": "a18832f6-376a-4b30-991a-c9b68c8e9d32",
        "id": "Yr3ZG4kIZwRp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86825ac4395c43b5b868dd1e58177be9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d503f8c8c4e47a8a0e85504a40b353d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc_lines = tc_all_prompts_labelled\n",
        "pc_lines = pc_all_prompts_labelled\n",
        "max_length = 1024\n",
        "tc_descriptions = [description for description in tc_lines if len(tokenizer.encode(description)) < max_length-2]\n",
        "pc_descriptions = [description for description in pc_lines if len(tokenizer.encode(description)) < max_length-2]\n",
        "pc_max_length = max([len(tokenizer.encode(description)) for description in pc_descriptions])\n",
        "tc_max_length = max([len(tokenizer.encode(description)) for description in tc_descriptions])\n",
        "print(pc_max_length)\n",
        "print(len(pc_descriptions))\n",
        "print(tc_max_length)\n",
        "print(len(tc_descriptions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb700a1-d754-400b-c130-4bec3f5c90b6",
        "id": "9K5q_6cUZwRq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "300\n",
            "823\n",
            "360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptsDataset(Dataset):\n",
        "    def __init__(self, txt_list, tokenizer, max_length):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        for txt in txt_list:\n",
        "            # Encode the descriptions using the GPT-Neo tokenizer\n",
        "            encodings_dict = tokenizer(\"<|startoftext|>\" \n",
        "                                        + txt +    \n",
        "                                        \"<|endoftext|>\",\n",
        "                                        truncation=True,\n",
        "                                        max_length=max_length, \n",
        "                                        padding='max_length')\n",
        "            input_ids = torch.tensor(encodings_dict['input_ids'])    \n",
        "            self.input_ids.append(input_ids)\n",
        "            mask = torch.tensor(encodings_dict['attention_mask'])\n",
        "            self.attn_masks.append(mask)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "\n",
        "tc_dataset = PromptsDataset(tc_descriptions, tokenizer, max_length)\n",
        "pc_dataset = PromptsDataset(pc_descriptions, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "yUJVak-5ZwRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_train_size = int(0.7 * len(pc_dataset))\n",
        "tc_train_size = int(0.7 * len(tc_dataset))\n",
        "\n",
        "pc_train_dataset, pc_trainval_dataset = random_split(pc_dataset, \n",
        "                            [pc_train_size, len(pc_dataset) - pc_train_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "pc_test_size = int(0.5 * len(pc_trainval_dataset))\n",
        "pc_test_dataset, pc_val_dataset = random_split(pc_trainval_dataset, \n",
        "                            [pc_test_size, len(pc_trainval_dataset) - pc_test_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_train_dataset, tc_trainval_dataset = random_split(tc_dataset, \n",
        "                            [tc_train_size, len(tc_dataset) - tc_train_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "tc_test_size = int(0.5 * len(tc_trainval_dataset))\n",
        "tc_test_dataset, tc_val_dataset = random_split(tc_trainval_dataset, \n",
        "                            [tc_test_size, len(tc_trainval_dataset) - tc_test_size],\n",
        "                            generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "# test_size = int(0.5 * len(trainval_dataset))\n",
        "# val_dataset, test_dataset = random_split(trainval_dataset, [test_size, len(trainval_dataset) - test_size])\n",
        "# train_dataset = dataset"
      ],
      "metadata": {
        "id": "OEHmBxgtZwRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, pc_unlabelled_trainval = random_split(pc_all_prompts,\n",
        "                                         [pc_train_size, len(pc_dataset) - pc_train_size],\n",
        "                                         generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "pc_unlabelled_test, pc_unlabelled_val = random_split(pc_unlabelled_trainval,\n",
        "                                                     [pc_test_size, len(pc_trainval_dataset) - pc_test_size],\n",
        "                                                     generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "_, tc_unlabelled_trainval = random_split(tc_all_prompts, \n",
        "                                         [tc_train_size, len(tc_dataset) - tc_train_size],\n",
        "                                         generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_unlabelled_test, tc_unlabelled_val = random_split(tc_unlabelled_trainval, \n",
        "                                                     [tc_test_size, len(tc_trainval_dataset) - tc_test_size],\n",
        "                                                     generator=torch.Generator().manual_seed(RANDOM_SEED))"
      ],
      "metadata": {
        "id": "n5MZgdh9KSbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tc_train_dataset[0][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "GsC8MQXLK-pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_val_labels[4])"
      ],
      "metadata": {
        "id": "K80Glz5zLB0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_train_labels, pc_trainval_labels = random_split(pc_all_labels, \n",
        "                                              [pc_train_size, len(pc_dataset) - pc_train_size],\n",
        "                                              generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "pc_test_labels, pc_val_labels = random_split(pc_trainval_labels,\n",
        "                                             [pc_test_size, len(pc_trainval_labels) - pc_test_size],\n",
        "                                             generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_train_labels, tc_trainval_labels = random_split(tc_all_labels, \n",
        "                                              [tc_train_size, len(tc_dataset) - tc_train_size],\n",
        "                                              generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "tc_test_labels, tc_val_labels = random_split(tc_trainval_labels,\n",
        "                                             [tc_test_size, len(tc_trainval_labels) - tc_test_size],\n",
        "                                             generator=torch.Generator().manual_seed(RANDOM_SEED))"
      ],
      "metadata": {
        "id": "PbSp1fKc7xkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_val_labels[0])"
      ],
      "metadata": {
        "id": "zTNji17x9J-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(pc_train_dataset[0][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "FI10fVDz86go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tc_train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c17WTC0nXTs_",
        "outputId": "adb60ae2-49f5-4707-e02a-bbc4beab4292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pc_train_dataset))\n",
        "print(len(tc_train_dataset))"
      ],
      "metadata": {
        "id": "c6jc3c_D4umW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tc_pc_concatdataset[251][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "5PwM_mErXMuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_pc_concatdataset = torch.utils.data.ConcatDataset([tc_train_dataset, pc_train_dataset])"
      ],
      "metadata": {
        "id": "UHhqY0_jW_Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.5e-5\n",
        "bs=10\n",
        "ne=4\n",
        "training_args = TrainingArguments(output_dir=f'bloom-tc-medium-lm-lr{lr}-bs{bs}-ne{ne}',\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  num_train_epochs=ne,\n",
        "                                  learning_rate=lr,\n",
        "                                  save_strategy='epoch',\n",
        "                                  evaluation_strategy='epoch',\n",
        "                                #   logging_steps=200,\n",
        "                                #   save_steps =1000,\n",
        "                                  per_device_train_batch_size=1,\n",
        "                                  gradient_accumulation_steps=bs,\n",
        "                                #   per_device_eval_batch_size=2,\n",
        "                                #   warmup_steps=500,\n",
        "                                  weight_decay=0.01,  \n",
        "                                  load_best_model_at_end=True,\n",
        "                                  fp16=True,\n",
        "                                  )\n",
        "                                #   logging_dir='./logs')"
      ],
      "metadata": {
        "id": "lMe7W26tZwRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=training_args,  \n",
        "                  train_dataset=tc_pc_concatdataset,\n",
        "                  eval_dataset=tc_val_dataset, \n",
        "                  # This custom collate function is necessary \n",
        "                  # to built batches of data\n",
        "                  data_collator=lambda data: \n",
        "              {'input_ids': torch.stack([f[0] for f in data]),       \n",
        "               'attention_mask': torch.stack([f[1] for f in data]),\n",
        "               'labels': torch.stack([f[0] for f in data])}\n",
        "                 )"
      ],
      "metadata": {
        "id": "hy2VO_zPZwRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabcf9f4-61e3-4c4a-bf6c-76788afffebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training process!\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "913e235b-b4c5-40cc-a430-a00a00be6eea",
        "id": "Uk5CViMgZwRr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 461\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
            "  Gradient Accumulation steps = 10\n",
            "  Total optimization steps = 184\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  8/184 00:30 < 14:46, 0.20 it/s, Epoch 0.15/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-482882979b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start training process!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m         )\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bloom/modeling_bloom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             loss = loss_fct(\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0mshift_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             )\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 980.00 MiB (GPU 0; 14.76 GiB total capacity; 13.44 GiB already allocated; 199.75 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = f'gpt2-tc-medium-lm-lr{lr}-bs{bs}-ne{ne}/checkpoint-46'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
        "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "# Resize the token embeddings because we've just added 3 new tokens \n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Lr4gEjsC13",
        "outputId": "0236dd88-a8e3-4f75-f755-276681f645ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"pad_token_id\": 50258,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50259\n",
            "}\n",
            "\n",
            "loading weights file gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each = \"\"\"Context:\n",
        "Person 1:  the guy is a machine! but he needs a better stage name. maybe president banana? \n",
        "Person 2:  i do not think the president of zimbabwe would be happy about that \n",
        "Person 1:  he could be the artist formerly known as president banana? i don't really care as long as i can listen to him on the radio! i love two things on my radio : indonesian pop music and electromagnetic storms from jupiter. those are my go to listening pleasures! \n",
        "Person 2:  yeah that is so cool that if you turn your radio to am, you may capture jupiter's storms \n",
        "\n",
        "Facts:\n",
        "according to canadian law, all radios are required to have at least 40 % of the music played be canadian.\n",
        "\n",
        "Generated response: \n",
        "Person 1: that might be banned in canada. the law says that all stations must have 40 % of the music played be canadian!\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "\"\"\"\n",
        "tokenized = tokenizer(each)\n",
        "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
        "if len(input_ids[0]) < 1000:\n",
        "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
        "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmIOa_VMPDJD",
        "outputId": "5f2e0fdf-d7a8-4ae8-b43d-0a3140d97405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "Person 1:  the guy is a machine! but he needs a better stage name. maybe president banana? \n",
            "Person 2:  i do not think the president of zimbabwe would be happy about that \n",
            "Person 1:  he could be the artist formerly known as president banana? i don't really care as long as i can listen to him on the radio! i love two things on my radio : indonesian pop music and electromagnetic storms from jupiter. those are my go to listening pleasures! \n",
            "Person 2:  yeah that is so cool that if you turn your radio to am, you may capture jupiter's storms \n",
            "\n",
            "Facts:\n",
            "according to canadian law, all radios are required to have at least 40 % of the music played be canadian.\n",
            "\n",
            "Generated response: \n",
            "Person 1: that might be banned in canada. the law says that all stations must have 40 % of the music played be canadian!\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n",
            "1. Understandable\n",
            "2. Natural\n",
            "3. Maintains Context\n",
            "4. Interesting\n",
            "5. Uses Knowledge\n",
            "6. Overall Quality\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tc_train_dataset[0][0], skip_special_tokens=True)[-200:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lYwqK4VSdE-7",
        "outputId": "91147a3b-28c8-4f0c-daee-8db3ced709d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:\\n1. 1\\n2. 2\\n3. 2\\n4. 3\\n5. 1\\n6. 4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc_unlabelled_test[0][-200:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oD198sdYcThx",
        "outputId": "168da023-6fd3-4461-fba2-32fa5340e120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e is conditioned on, how well does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DDoEAyqinUW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_test_dataset = tc_unlabelled_test\n",
        "for i, each in enumerate(tc_test_dataset):\n",
        "    # print(each)\n",
        "    tokenized = tokenizer(each + \"\\n\")\n",
        "    input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
        "    input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "    if len(input_ids[0]) < 1000:\n",
        "        generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=3, temperature=0.1)\n",
        "        print(f\"\\nnum = {i}\")\n",
        "        print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0].replace(input_text, \"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "HYUmEFNS2-Me",
        "outputId": "9e71c98b-af82-4073-cd65-0ccfdd1203d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "num = 0\n",
            "1.\n",
            "2.\n",
            "3.\n",
            "\n",
            "num = 1\n",
            "1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.\n",
            "\n",
            "num = 2\n",
            "1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.\n",
            "\n",
            "num = 3\n",
            "1.\n",
            "2.\n",
            "3.\n",
            "\n",
            "num = 4\n",
            "1.\n",
            "2.\n",
            "3.\n",
            "4.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-836ee2138fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mgeneration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nnum = {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1393\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             )\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m             )\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m         )\n\u001b[1;32m   1078\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m                 )\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         )\n\u001b[1;32m    414\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer_past\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = \"hey there\"\n",
        "tokenized = tokenizer(str1)\n",
        "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
        "generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
        "print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlv1pLA_ubRQ",
        "outputId": "16834113-5d0e-4431-9cc9-8787b2d3db96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey theres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([test_dataset[0][0].tolist()]).to(device)\n",
        "if len(input_ids[0]) < 1000:\n",
        "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=24, num_beams=5)\n",
        "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "9pmHEgrOy6Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(test_dataset[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btRopY8m1QSa",
        "outputId": "b603d1e1-b070-448c-9b96-578c1380d9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startoftext|> Human Evaluation of Chatbot Outputs:\n",
            "\n",
            "Annotation Instructions: \n",
            "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
            "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
            "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
            "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
            "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
            "Interesting (1 - 3): Is the response dull/interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
            "Overall Quality (1 - 5): Given your answers above, what is your overall impression of this utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  i did see the movie, i thought it was bad as well, i liked the book better, i like reading you can learn many interesting facts, like why the area code of new york is 212. \n",
            "Person 2:  ya i think it was because that was the fastest number that you could dial with a rotary phone? crazy how that stuff carries over until even today!! \n",
            "Person 1:  it is! there s a lot things we need to discover still though, i'm kind of worried the cables carrying phone and internet are underwater, at least some of them. \n",
            "Person 2:  ya it's only about 3 inches thick, i wonder how it is protected? is it just a cable or are there safeguards in place in case like a ship sinks and crushes it, etc \n",
            "\n",
            "Generated response: \n",
            "Agent: i think that is a good idea, i think it would be a great idea to put flamethrowers on the back of cars in south africa\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
            "\n",
            "Answers:\n",
            "1. Understandable: 0\n",
            "2. Natural: 2\n",
            "3. Maintains Context: 1\n",
            "4. Interesting: 2\n",
            "5. Overall Quality: 2<|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each in test_dataset:\n",
        "    input_ids = torch.tensor([each[0].tolist()]).to('cuda')\n",
        "    if len(input_ids[0]) < 1000:\n",
        "        outputs = model.generate(input_ids, do_sample=False, max_new_tokens=24, num_beams=5)\n",
        "        print(str(tokenizer.decode(input_ids[0])))\n",
        "        model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        print(model_response)\n",
        "        print(\"\\n\")\n",
        "    else:\n",
        "        print(len(input_ids[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1rBCbBzbpiu",
        "outputId": "e5442de0-ee16-49c2-fae9-5cb749aad528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n",
            "1018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk5JXW4ntE2j",
        "outputId": "4812c11e-30cd-4695-8107-bc39c217a270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20342,   612]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkM7EbqptJtm",
        "outputId": "3900d138-3391-43c5-bd78-5b153abb19b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[50257, 20490, 34959,  ..., 50258, 50258, 50258]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "# prompt = \"hey there\"\n",
        "# tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "# input_ids = tokenized['input_ids'].to('cuda')\n",
        "\n",
        "outputs = model.generate(torch.tensor([test_dataset[0][0].tolist()]).to('cuda'), do_sample=False, max_new_tokens=100, num_beams=5)\n",
        "print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
        "model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "# feedback_starts = model_response.find(\"Feedback: \")\n",
        "print(\"Model Response: \" + model_response)\n",
        "# print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "gmkS1KZMrJgB",
        "outputId": "5121c455-4531-4ff0-f7d5-016254913dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f5160127d283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input_ids = tokenized['input_ids'].to('cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prompt: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avR-qFFKtCCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}