{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U7w8uY9x9kC7",
        "ZC1HoI679mty",
        "81BF9V0hmbO6",
        "b3-Yj5ZtmoM1",
        "kW6Cc2ybRgME"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! rm -r sample_data\n",
        "! pip -q install transformers\n",
        "! pip -q install pytorch-lightning\n",
        "! pip -q install datasets\n",
        "! pip -q install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZulggTpT0Py",
        "outputId": "90ae7e63-e206-4a9a-edaa-db9ce8d73005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 34.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 102.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 85.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 708 kB 12.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 66.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 431 kB 37.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 99.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 163 kB 69.6 MB/s \n",
            "\u001b[?25h  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from pytorch_lightning import seed_everything\n",
        "os.chdir(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation\")\n",
        "import openai\n",
        "RANDOM_SEED = 42\n",
        "seed_everything(RANDOM_SEED)\n",
        "# openai.api_key = \"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\" #1\n",
        "# openai.api_key = \"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\" #mum's phone\n",
        "# openai.api_key = \"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\" #colab1\n",
        "openai.api_key = \"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\" #colab2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz_LAuGeT171",
        "outputId": "e0e62c32-a5aa-4ab6-e4ba-250b7407d59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Five-Point Scale**"
      ],
      "metadata": {
        "id": "Z4-FAVPhWzDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q \"http://shikib.com/tc_usr_data.json\" -O \"five_point_dialog_eval_tc_usr_data.json\"\n",
        "! wget -q \"http://shikib.com/pc_usr_data.json\" -O \"five_point_dialog_eval_pc_usr_data.json\""
      ],
      "metadata": {
        "id": "cHorayWrW1gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_tc_usr_data.json\", \"r\") as f1:\n",
        "    tc_usr_data = json.load(f1)\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_pc_usr_data.json\", \"r\") as f1:\n",
        "    pc_usr_data = json.load(f1)"
      ],
      "metadata": {
        "id": "Lx6yW9pxW1eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(pc_usr_data[0])"
      ],
      "metadata": {
        "id": "GnoF_yob0puZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_usr_data[0]['context'].split('\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz3r6b8RW1cE",
        "outputId": "c04dd4a1-eadd-46f6-f329-ff7efd6c0470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \", \" sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \", '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in tc_usr_data:\n",
        "    if len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        count += 1\n",
        "print(len(tc_usr_data))\n",
        "print(count)"
      ],
      "metadata": {
        "id": "uWUAdZ1r7roZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b7902e-e21b-446f-d592-168e4d7bbe09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each = tc_usr_data[0]\n",
        "print([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghv0x_bbDER0",
        "outputId": "31e3d965-4801-4439-d327-a4a5201d4dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"so , i 'm reading the latest film from studio ghibli is out the tale of princess kaguya . dunno if you 're familiar with them , but studio ghibli has made a lot of great animated films , like spirited away , and princess mononoke \", \" i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \", ' yeah , sadly , disney ( which owns the american rights to the films ) does n\\'t tend to promote them very much . i think they \\'re worried they \\'ll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they \\'re worth checking out . ', \" i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \", \" sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_tc_usr_data.json\", \"r\") as f1:\n",
        "    tc_usr_data = json.load(f1)\n",
        "with open(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation/five_point_dialog_eval_pc_usr_data.json\", \"r\") as f1:\n",
        "    pc_usr_data = json.load(f1)\n",
        "# tc_pc_combined_context4 = []\n",
        "tc_context4 = []\n",
        "pc_context4 = []\n",
        "for each in tc_usr_data:\n",
        "    if not len([p for p in each[\"context\"].split(\"\\n\") if p != \"\"]) < 4:\n",
        "        copy = each\n",
        "        copy[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"][-4:])\n",
        "        # print(each)\n",
        "        tc_context4.append(copy)\n",
        "    else:\n",
        "        tc_context4.append(each)\n",
        "for each in pc_usr_data:\n",
        "    if not len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        copy = each\n",
        "        copy[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"][-4:])\n",
        "        pc_context4.append(copy)\n",
        "    else:\n",
        "        pc_context4.append(each)\n",
        "\n",
        "for each in tc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        # print(each)\n",
        "for each in pc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        # print(each)"
      ],
      "metadata": {
        "id": "p9WTmbv88bCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in tc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        # each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        print(\"sda\")\n",
        "for each in pc_context4:\n",
        "    if \"\" in each['context'].split('\\n'):\n",
        "        # each[\"context\"] = \"\\n\".join([p for p in each[\"context\"].split(\"\\n\") if p != \"\"])\n",
        "        print(\"sda\")"
      ],
      "metadata": {
        "id": "Dybc-eAtSD7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_context4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_context4, f1)\n",
        "with open(\"pc_context4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_context4, f1)"
      ],
      "metadata": {
        "id": "Ztyr4shVRcmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in tc_context4:\n",
        "    if each == None:\n",
        "        print('dsa')\n",
        "for each in pc_context4:\n",
        "    if each == None:\n",
        "        print('dsa')"
      ],
      "metadata": {
        "id": "tP0rLsbi-olW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in tc_context4:\n",
        "    print(len(each['context'].split(\"\\n\")))"
      ],
      "metadata": {
        "id": "bOfu5eaJ--tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in pc_context4:\n",
        "    print(len(each['context'].split(\"\\n\")))"
      ],
      "metadata": {
        "id": "qAfCSgtDFp5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_context4[4]['context'].split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzrR9_nr_L88",
        "outputId": "26b69671-a4e8-4a07-fa5d-c5465d7ecd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' i ve done it traveling , you ve got to really know the team and all of the players names . it was so much harder . ',\n",
              " ' do you have a favorite nfl team . like i said , i lived in dc for a while so kind of follow them . now in northern ohio , the browns are a difficult team to support . ',\n",
              " ' i feel you there , living in florida here . dolphins are hard to root for and feel proud . ',\n",
              " ' it could be worse , i read about this team that lost 220 - 0 . it would be hard to watch to the end . ']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_context4[6]['context'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4rd9kMf9C0x",
        "outputId": "18c1e333-21e2-4d2e-fb20-4cc9f11efc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey . where are you from ? i'm from a farm in wisconsin\n",
            "i love ice cream what is your favorite ? mine is chocolate\n",
            "mine is mint chocolate chip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in tc_pc_combined_context4:\n",
        "    if len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        count += 1\n",
        "print(len(tc_pc_combined_context4))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxyOoU6n9ET-",
        "outputId": "97d2ef5d-cb25-4b13-d8a3-e9208ce3b1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n",
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for each in pc_usr_data:\n",
        "    if len(each[\"context\"].split(\"\\n\")) < 4:\n",
        "        count += 1\n",
        "print(len(pc_usr_data))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XMLQ5Xy8T6T",
        "outputId": "ced06de1-8211-4594-d7da-c3260366d2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapoints_count = 0\n",
        "for each in tc_context4:\n",
        "    # print(len(each['responses']))\n",
        "    datapoints_count += len(each['responses'])\n",
        "print(datapoints_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZDw44_mD7qG",
        "outputId": "8fda95bd-980b-4461-e0fb-9f6c2d57d8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tc_context4[6][\"responses\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjwj50gfIYCR",
        "outputId": "3764fc2e-7112-430c-9b70-201e0b815c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapoints_count = 0\n",
        "for each in pc_context4:\n",
        "    # print(len(each['responses']))\n",
        "    datapoints_count += len(each['responses'])\n",
        "print(datapoints_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCQ93K_3IVE1",
        "outputId": "91e57dcb-1d10-475c-d1cc-e3e2c80a34f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pc_context4[5][\"responses\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Ur1jXoIb7T",
        "outputId": "f8f539d6-cd17-40fd-e291-02b9be33b23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tc_all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KWPre3wIiq6",
        "outputId": "0e2b643d-05ff-400d-be29-c3eab73c9bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_context4[0][\"fact\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUbJPqLpJZ3y",
        "outputId": "344718a6-a961-46a9-dbe3-549df1c24796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from left , emma baker , daniel saperstein and taylor mulitz of flasher will perform this summer 's final fort reno concert . ( jared soares for the washington post ) monday , july 30 25th birthday celebration at national postal museum : celebrate 25 years of this institution devoted to the long history of the u.s . postal service with daytime festivities that include cupcakes , birthday postcards , a photo booth and a special scavenger hunt with prizes . 11 a.m. to 2 p.m. free . tuesday , july 31 \" the color purple \" at kennedy center : the tony award - winning musical revival , based on the pulitzer prize - winning alice walker novel of the same name , features jazz , ragtime , gospel and blues with a story about an african american woman named celie surviving poverty in the south during the 1930s . through aug . 26 . $ 69-$149 . ask a harry potter scholar at southeast neighborhood library : come to this talk from tolanda henderson , a librarian from george washington university , who has used the j.k . rowling book series as a text in academia . commune with other muggles who prove that it 's not just kids and young adults who obsess about the boy who lived . 7 p.m. free . wednesday , aug . 1 rico nasty at the fillmore silver spring : two summers ago , rico nasty was a teenage loudmouth from the maryland suburbs , generating buzz on youtube for spitting surly , rainbow - tinted rhymes . now , after signing a deal with atlantic records , the 21-year - old singer is on her way to becoming one of the brightest voices in rap music .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pc_context4"
      ],
      "metadata": {
        "id": "nDvfN-FnJbt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_context4[0][\"fact\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El0ZFZFdI-F1",
        "outputId": "908559ce-65f2-4778-bff2-f7fa36ea298e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your persona: i also have a dog walking business.\n",
            "your persona: i've three dogs.\n",
            "your persona: my father was a door to door salesman.\n",
            "your persona: i am in an open polyamorous relationship.\n",
            "your persona: i like to watch the olympics.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "tc_all_prompts = []\n",
        "tc_all_labels = []\n",
        "pc_all_prompts = []\n",
        "pc_all_labels = []\n",
        "for each in tc_context4:\n",
        "    prompt_here = f\"\"\"\\n\\n\\nContext:\\n\"\"\"\n",
        "    for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "        if i % 2 == 0:\n",
        "            prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "        else:\n",
        "            prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    next_person = (1 if len([p for p in each['context'].split(\"\\n\") if p != \"\"]) % 2 == 0 else 2)\n",
        "    prompt_here += f\"\\nFacts:\\n{each['fact']}\"\n",
        "    for i in range(len(each[\"responses\"])):\n",
        "        prompt_1 = prompt_here + f\"\"\"\\nGenerated response: \\nPerson {next_person}: {each['responses'][i]['response'].strip()}\\n\\nQuestions about the generated response:\\n1. Understandable (0 - 1): Is the response understandable given the previous context?\\n2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\\n3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\\n4. Interesting (1 - 3): Is the response dull or interesting?\\n5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:\"\"\"\n",
        "        tc_all_prompts.append(prompt_1)\n",
        "        labels_here = [each[\"responses\"][i][\"Understandable\"], each[\"responses\"][i][\"Natural\"], each[\"responses\"][i][\"Maintains Context\"], each[\"responses\"][i][\"Engaging\"], each[\"responses\"][i][\"Uses Knowledge\"], each[\"responses\"][i][\"Overall\"]]\n",
        "        tc_all_labels.append(labels_here)\n",
        "\n",
        "for each in pc_context4:\n",
        "    prompt_here = f\"\"\"\\n\\n\\nContext:\\n\"\"\"\n",
        "    for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "        if i % 2 == 0:\n",
        "            prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "        else:\n",
        "            prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    next_person = (1 if len([p for p in each['context'].split(\"\\n\") if p != \"\"]) % 2 == 0 else 2)\n",
        "    prompt_here += f\"\\nFacts:\\n{each['fact']}\".replace(\"your persona:\", f\"Person {next_person}'s statement:\")\n",
        "    for i in range(len(each[\"responses\"])):\n",
        "        prompt_1 = prompt_here + f\"\"\"\\nGenerated response: \\nPerson {next_person}: {each['responses'][i]['response'].strip()}\\n\\nQuestions about the generated response:\\n1. Understandable (0 - 1): Is the response understandable given the previous context?\\n2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\\n3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\\n4. Interesting (1 - 3): Is the response dull or interesting?\\n5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:\"\"\"\n",
        "        pc_all_prompts.append(prompt_1)\n",
        "        labels_here = [each[\"responses\"][i][\"Understandable\"], each[\"responses\"][i][\"Natural\"], each[\"responses\"][i][\"Maintains Context\"], each[\"responses\"][i][\"Engaging\"], each[\"responses\"][i][\"Uses Knowledge\"], each[\"responses\"][i][\"Overall\"]]\n",
        "        pc_all_labels.append(labels_here)\n",
        "# print(prompt_here)\n"
      ],
      "metadata": {
        "id": "0zI5pi2xW1Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_all_prompts[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ciIQDOaL_AC",
        "outputId": "77ca7bf2-bde9-4fc1-e0b8-295b0898cdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
            "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
            "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
            "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
            "\n",
            "Facts:\n",
            "the raiders sacked goff only once , on a play during which bruce irvin forced a fumble . other than that , the oakland defense could put almost no pressure on goff . the absence of mack , the former nfl defensive player of the year , was glaring . in the first half sunday night , mack had a sack , a forced fumble , a fumble recovery , an interception and a touchdown on defense . he and the bears could not sustain that , and they succumbed to the second - half exploits of packers quarterback aaron rodgers . but mack reinforced what a game - changing , difference - making player he is . he left little doubt that he is worth the six - year , $ 141 million contract given to him by the bears , making him the league 's highest - paid defensive player . [ the nfl teams that have serious reasons to worry , versus the ones that do n't ] mack , while still with the raiders , had been holding out , seeking such a deal . the raiders did n't want to give it to him . they have a $ 125 million quarterback in carr . they have a $ 100 million coach in gruden . they drew the line at handing out another mammoth deal , not wanting to further strain their budget or push the boundaries of the salary cap . they regarded the king 's ransom of draft picks put forth by the bears , including a pair of first - rounders , as an offer they could n't refuse . in truth , they could have refused it .\n",
            "\n",
            "Generated response: \n",
            "Person 1: i like the eagles . i think they are doing well this season .\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0zKudlFcUD5",
        "outputId": "fe9bb8fd-c8a5-4167-b375-8298e1f2d410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1: lead singer for a band , music teacher\n",
            "Person 2: wow nice are you really good ?\n",
            "Person 1: millions of plays on soundcloud\n",
            "Person 2: really would you share or are you shy\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i also have a dog walking business.\n",
            "Person 1's statement: i've three dogs.\n",
            "Person 1's statement: my father was a door to door salesman.\n",
            "Person 1's statement: i am in an open polyamorous relationship.\n",
            "Person 1's statement: i like to watch the olympics.\n",
            "\n",
            "Generated response: \n",
            "Person 1: i am not . i am a student .\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "print(pc_all_prompts[i] + pc_all_prompts[i + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KynY5Jq5XuJd",
        "outputId": "f4f2930f-15b6-45c7-dd04-e282620ad807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1: lead singer for a band , music teacher\n",
            "Person 2: wow nice are you really good ?\n",
            "Person 1: millions of plays on soundcloud\n",
            "Person 2: really would you share or are you shy\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i also have a dog walking business.\n",
            "Person 1's statement: i've three dogs.\n",
            "Person 1's statement: my father was a door to door salesman.\n",
            "Person 1's statement: i am in an open polyamorous relationship.\n",
            "Person 1's statement: i like to watch the olympics.\n",
            "\n",
            "Generated response: \n",
            "Person 1: ha ha i'm so shy\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1: lead singer for a band , music teacher\n",
            "Person 2: wow nice are you really good ?\n",
            "Person 1: millions of plays on soundcloud\n",
            "Person 2: really would you share or are you shy\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i also have a dog walking business.\n",
            "Person 1's statement: i've three dogs.\n",
            "Person 1's statement: my father was a door to door salesman.\n",
            "Person 1's statement: i am in an open polyamorous relationship.\n",
            "Person 1's statement: i like to watch the olympics.\n",
            "\n",
            "Generated response: \n",
            "Person 1: i know what you mean spend most nights cuddling my dog and star watching\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_likert_feedback(gpt3_feedback_format_texts, prefix=\"\"):\n",
        "    feedbacks = []\n",
        "    for each in gpt3_feedback_format_texts:\n",
        "        instance_prompt = prefix + each.rstrip()\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-002\",\n",
        "            prompt=instance_prompt,\n",
        "            temperature=0.1,\n",
        "            max_tokens=1000,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "        )\n",
        "        # print(each + response['choices'][0]['text'])\n",
        "        feedbacks.append(response['choices'][0]['text'])\n",
        "    return feedbacks"
      ],
      "metadata": {
        "id": "cGj0grMTfN7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prefix + all_prompts[0])"
      ],
      "metadata": {
        "id": "GvJLpAKBqcU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Two-Shot**"
      ],
      "metadata": {
        "id": "uMzgi-u79KsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_prompts[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oei1EHfC8XTb",
        "outputId": "44c68416-5bf4-4392-b7fe-c0a07a3ac7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  yeah the diamondbacks had a chance and then they did have a bad 2nd half of the season . i am a brewers fan and our gm made some amazing moves in the offseason and it paid off big . \n",
            "Person 2:  nice ! ( except for ryan braun ) i like the brewers and was pulling for them against the dodgers ( who i hate more than braun ) ! \n",
            "Person 1:  yeah i was so disappointed with the whole braun thing , i was like just admit you messed up , and get on with it . the lying and blaming others is just the worst ! thanks though , game 7 just sucked ! i do like the dbacks though , craig counsel your old hero ! ! \n",
            "Person 2:  yep - craig is the man , glad he 's having success with the brewers . even your bench coach ( murphy ) has arizona ties ( asu ) . i really like your corner infielders shaw / aguilar \n",
            "\n",
            "Generated response: \n",
            "Agent: that 's awesome ! the indians also have an uniforms because they can actually play for the field . the guy who is still invited to play baseball at the oracle arena !\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rivsDqafVmJ",
        "outputId": "fe97e837-8792-419f-efa3-0c93b7a73b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1: lead singer for a band , music teacher\n",
            "Person 2: wow nice are you really good ?\n",
            "Person 1: millions of plays on soundcloud\n",
            "Person 2: really would you share or are you shy\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i also have a dog walking business.\n",
            "Person 1's statement: i've three dogs.\n",
            "Person 1's statement: my father was a door to door salesman.\n",
            "Person 1's statement: i am in an open polyamorous relationship.\n",
            "Person 1's statement: i like to watch the olympics.\n",
            "\n",
            "Generated response: \n",
            "Person 1: ha ha i'm so shy\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pc_prefix_twoshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1: lead singer for a band , music teacher\n",
        "Person 2: wow nice are you really good ?\n",
        "Person 1: millions of plays on soundcloud\n",
        "Person 2: really would you share or are you shy\n",
        "\n",
        "Facts:\n",
        "Person 1's statement: i also have a dog walking business.\n",
        "Person 1's statement: i've three dogs.\n",
        "Person 1's statement: my father was a door to door salesman.\n",
        "Person 1's statement: i am in an open polyamorous relationship.\n",
        "Person 1's statement: i like to watch the olympics.\n",
        "\n",
        "Generated response: \n",
        "Person 1: i know what you mean spend most nights cuddling my dog and star watching\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 1\n",
        "2. 3\n",
        "3. 1\n",
        "4. 3\n",
        "5. 1\n",
        "6. 2\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1: as long as i have my french fries !\n",
        "Person 2: well everyone can cheat once in a while\n",
        "Person 1: of course . now all of this has made me hungry .\n",
        "Person 2: you can go for some grub\n",
        "\n",
        "Facts:\n",
        "Person 1's statement: i like to take walks.\n",
        "Person 1's statement: i don't drink soda.\n",
        "Person 1's statement: i've a boyfriend.\n",
        "Person 1's statement: i like to eat hamburgers and french fries.\n",
        "\n",
        "Generated response: \n",
        "Person 1: maybe i'll take go for a walk and get a burger after .\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 1\n",
        "2. 3\n",
        "3. 3\n",
        "4. 1\n",
        "5. 5\"\"\""
      ],
      "metadata": {
        "id": "-28aUn4Jee_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_prefix_twoshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
        "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
        "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
        "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
        "\n",
        "Facts:\n",
        "from left , emma baker , daniel saperstein and taylor mulitz of flasher will perform this summer 's final fort reno concert . ( jared soares for the washington post ) monday , july 30 25th birthday celebration at national postal museum : celebrate 25 years of this institution devoted to the long history of the u.s . postal service with daytime festivities that include cupcakes , birthday postcards , a photo booth and a special scavenger hunt with prizes . 11 a.m. to 2 p.m. free . tuesday , july 31 \" the color purple \" at kennedy center : the tony award - winning musical revival , based on the pulitzer prize - winning alice walker novel of the same name , features jazz , ragtime , gospel and blues with a story about an african american woman named celie surviving poverty in the south during the 1930s . through aug . 26 . $ 69-$149 . ask a harry potter scholar at southeast neighborhood library : come to this talk from tolanda henderson , a librarian from george washington university , who has used the j.k . rowling book series as a text in academia . commune with other muggles who prove that it 's not just kids and young adults who obsess about the boy who lived . 7 p.m. free . wednesday , aug . 1 rico nasty at the fillmore silver spring : two summers ago , rico nasty was a teenage loudmouth from the maryland suburbs , generating buzz on youtube for spitting surly , rainbow - tinted rhymes . now , after signing a deal with atlantic records , the 21-year - old singer is on her way to becoming one of the brightest voices in rap music .\n",
        "\n",
        "Generated response: \n",
        "Person 1: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 1\n",
        "2. 3\n",
        "3. 3\n",
        "4. 3\n",
        "5. 1\n",
        "6. 5\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
        "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
        "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
        "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
        "\n",
        "Facts:\n",
        "the raiders sacked goff only once , on a play during which bruce irvin forced a fumble . other than that , the oakland defense could put almost no pressure on goff . the absence of mack , the former nfl defensive player of the year , was glaring . in the first half sunday night , mack had a sack , a forced fumble , a fumble recovery , an interception and a touchdown on defense . he and the bears could not sustain that , and they succumbed to the second - half exploits of packers quarterback aaron rodgers . but mack reinforced what a game - changing , difference - making player he is . he left little doubt that he is worth the six - year , $ 141 million contract given to him by the bears , making him the league 's highest - paid defensive player . [ the nfl teams that have serious reasons to worry , versus the ones that do n't ] mack , while still with the raiders , had been holding out , seeking such a deal . the raiders did n't want to give it to him . they have a $ 125 million quarterback in carr . they have a $ 100 million coach in gruden . they drew the line at handing out another mammoth deal , not wanting to further strain their budget or push the boundaries of the salary cap . they regarded the king 's ransom of draft picks put forth by the bears , including a pair of first - rounders , as an offer they could n't refuse . in truth , they could have refused it .\n",
        "\n",
        "Generated response: \n",
        "Person 1: i like a little bit . i have a lot of friends . i do nt have a team that great fans are a fan . i would like to know why they would do that .\n",
        "\n",
        "Questions about the generated response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
        "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
        "\n",
        "Answers:\n",
        "1. 0\n",
        "2. 1\n",
        "3. 1\n",
        "4. 1\n",
        "5. 0\n",
        "6. 1\"\"\""
      ],
      "metadata": {
        "id": "5COp05fWj8fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_all_prompts[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn9lhRFxlBtI",
        "outputId": "1d7de6f0-278e-4727-b764-62e91c940082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
            "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
            "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
            "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
            "\n",
            "Facts:\n",
            "the raiders sacked goff only once , on a play during which bruce irvin forced a fumble . other than that , the oakland defense could put almost no pressure on goff . the absence of mack , the former nfl defensive player of the year , was glaring . in the first half sunday night , mack had a sack , a forced fumble , a fumble recovery , an interception and a touchdown on defense . he and the bears could not sustain that , and they succumbed to the second - half exploits of packers quarterback aaron rodgers . but mack reinforced what a game - changing , difference - making player he is . he left little doubt that he is worth the six - year , $ 141 million contract given to him by the bears , making him the league 's highest - paid defensive player . [ the nfl teams that have serious reasons to worry , versus the ones that do n't ] mack , while still with the raiders , had been holding out , seeking such a deal . the raiders did n't want to give it to him . they have a $ 125 million quarterback in carr . they have a $ 100 million coach in gruden . they drew the line at handing out another mammoth deal , not wanting to further strain their budget or push the boundaries of the salary cap . they regarded the king 's ransom of draft picks put forth by the bears , including a pair of first - rounders , as an offer they could n't refuse . in truth , they could have refused it .\n",
            "\n",
            "Generated response: \n",
            "Person 1: i like a little bit . i have a lot of friends . i do nt have a team that great fans are a fan . i would like to know why they would do that .\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tc_all_prompts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCH6Aoy5kBaO",
        "outputId": "33394cb1-c20d-4317-f414-de686d5c30d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
            "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
            "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
            "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
            "\n",
            "Facts:\n",
            "from left , emma baker , daniel saperstein and taylor mulitz of flasher will perform this summer 's final fort reno concert . ( jared soares for the washington post ) monday , july 30 25th birthday celebration at national postal museum : celebrate 25 years of this institution devoted to the long history of the u.s . postal service with daytime festivities that include cupcakes , birthday postcards , a photo booth and a special scavenger hunt with prizes . 11 a.m. to 2 p.m. free . tuesday , july 31 \" the color purple \" at kennedy center : the tony award - winning musical revival , based on the pulitzer prize - winning alice walker novel of the same name , features jazz , ragtime , gospel and blues with a story about an african american woman named celie surviving poverty in the south during the 1930s . through aug . 26 . $ 69-$149 . ask a harry potter scholar at southeast neighborhood library : come to this talk from tolanda henderson , a librarian from george washington university , who has used the j.k . rowling book series as a text in academia . commune with other muggles who prove that it 's not just kids and young adults who obsess about the boy who lived . 7 p.m. free . wednesday , aug . 1 rico nasty at the fillmore silver spring : two summers ago , rico nasty was a teenage loudmouth from the maryland suburbs , generating buzz on youtube for spitting surly , rainbow - tinted rhymes . now , after signing a deal with atlantic records , the 21-year - old singer is on her way to becoming one of the brightest voices in rap music .\n",
            "\n",
            "Generated response: \n",
            "Person 1: i think it 's interesting that peter gabriel has been in the us , he is a great performer .\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pc_all_prompts[10:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbfdagR8h0yT",
        "outputId": "af53da0e-d3b8-432a-c0b4-5141693a9430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tc_context4[0][\"responses\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQcw_lr1l7wk",
        "outputId": "02f1f05f-3038-4ee9-f7fd-3ba1709ea60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result_part1 = get_likert_feedback(pc_all_prompts[10:100], pc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "yuXISB9LhL22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result_part1 = get_likert_feedback(tc_all_prompts[12:112], tc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "XM6pbelhl5YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pc_result_part1.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_result_part1, f1)"
      ],
      "metadata": {
        "id": "Llf4qNeNosaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_result_part1.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part1, f1)"
      ],
      "metadata": {
        "id": "KTu1VyVjYN4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result_part2 = get_likert_feedback(pc_all_prompts[100:190], pc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "kGXWP3sXiTC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result_part2 = get_likert_feedback(tc_all_prompts[112:170], tc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "LnEKyu72mq9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pc_result_part2.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_result_part2, f1)"
      ],
      "metadata": {
        "id": "vsowbibzZAIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_result_part2.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part2, f1)"
      ],
      "metadata": {
        "id": "tSOtleZsmuZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result_part3 = get_likert_feedback(pc_all_prompts[190:300], pc_prefix_twoshot)"
      ],
      "metadata": {
        "id": "f9fYv4ekjaV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pc_result_part3.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_result_part3, f1)"
      ],
      "metadata": {
        "id": "ZOXyLxRLZFE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result_part31 = get_likert_feedback(tc_all_prompts[170:200], tc_prefix_twoshot)\n",
        "time.sleep(60)\n",
        "tc_result_part32 = get_likert_feedback(tc_all_prompts[200:230], tc_prefix_twoshot)\n",
        "tc_result_part3 = tc_result_part31 + tc_result_part32\n",
        "with open(\"tc_result_part3.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part3, f1)\n",
        "time.sleep(60)\n",
        "tc_result_part41 = get_likert_feedback(tc_all_prompts[230:260], tc_prefix_twoshot)\n",
        "time.sleep(60)\n",
        "tc_result_part42 = get_likert_feedback(tc_all_prompts[260:290], tc_prefix_twoshot)\n",
        "tc_result_part4 = tc_result_part41 + tc_result_part42\n",
        "with open(\"tc_result_part4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part4, f1)"
      ],
      "metadata": {
        "id": "AcWJcUdCnvr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(60)\n",
        "tc_result_part51 = get_likert_feedback(tc_all_prompts[290:320], tc_prefix_twoshot)\n",
        "time.sleep(60)\n",
        "tc_result_part52 = get_likert_feedback(tc_all_prompts[320:], tc_prefix_twoshot)\n",
        "tc_result_part5 = tc_result_part51 + tc_result_part52\n",
        "with open(\"tc_result_part5.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_result_part5, f1)"
      ],
      "metadata": {
        "id": "EJ3Nd8PGostz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_result = pc_result_part1 + pc_result_part2 + pc_result_part3"
      ],
      "metadata": {
        "id": "12eesM-oYupL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_result = tc_result_part1 + tc_result_part2 + tc_result_part3 + tc_result_part4 + tc_result_part5"
      ],
      "metadata": {
        "id": "0XvdkXYwozU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_prefix_twoshot + pc_all_prompts[9])"
      ],
      "metadata": {
        "id": "cNq505IKg7hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc_all_prompts[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55g1cZmVgm_k",
        "outputId": "9a3d6ae4-00f6-4f38-f14e-4fc0cbdd260d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Context:\n",
            "Person 1: as long as i have my french fries !\n",
            "Person 2: well everyone can cheat once in a while\n",
            "Person 1: of course . now all of this has made me hungry .\n",
            "Person 2: you can go for some grub\n",
            "\n",
            "Facts:\n",
            "Person 1's statement: i like to take walks.\n",
            "Person 1's statement: i don't drink soda.\n",
            "Person 1's statement: i've a boyfriend.\n",
            "Person 1's statement: i like to eat hamburgers and french fries.\n",
            "\n",
            "Generated response: \n",
            "Person 1: maybe i'll take go for a walk and get a burger after .\n",
            "\n",
            "Questions about the generated response:\n",
            "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
            "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
            "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
            "4. Interesting (1 - 3): Is the response dull or interesting?\n",
            "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
            "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
            "\n",
            "Answers:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_threeshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull or interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Uses Knowledge (0 - 1): Given the fact that the response is conditioned on, how well does the response use that fact? A score of 0 (no) means the response does not mention or refer to the fact at all. Ascore of 1 (yes) means the response uses the fact well.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of the generated response/utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
        "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
        "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
        "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 3\n",
        "3. Maintains Context: 3\n",
        "4. Interesting: 3\n",
        "5. Overall Quality: 5\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  yeah the diamondbacks had a chance and then they did have a bad 2nd half of the season . i am a brewers fan and our gm made some amazing moves in the offseason and it paid off big . \n",
        "Person 2:  nice ! ( except for ryan braun ) i like the brewers and was pulling for them against the dodgers ( who i hate more than braun ) ! \n",
        "Person 1:  yeah i was so disappointed with the whole braun thing , i was like just admit you messed up , and get on with it . the lying and blaming others is just the worst ! thanks though , game 7 just sucked ! i do like the dbacks though , craig counsel your old hero ! ! \n",
        "Person 2:  yep - craig is the man , glad he 's having success with the brewers . even your bench coach ( murphy ) has arizona ties ( asu ) . i really like your corner infielders shaw / aguilar \n",
        "\n",
        "Generated response: \n",
        "Agent: that 's awesome ! the indians also have an uniforms because they can actually play for the field . the guy who is still invited to play baseball at the oracle arena !\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 0\n",
        "2. Natural: 1\n",
        "3. Maintains Context: 1\n",
        "4. Interesting: 2\n",
        "5. Overall Quality: 2\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
        "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
        "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
        "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i think he 's a great player . i think he 's a great player .\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 2\n",
        "3. Maintains Context: 2\n",
        "4. Interesting: 2\n",
        "5. Overall Quality: 2\"\"\"\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "KX906uH38UwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_twoshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull/interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of this utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
        "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
        "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
        "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 3\n",
        "3. Maintains Context: 3\n",
        "4. Interesting: 3\n",
        "5. Overall Quality: 5\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
        "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
        "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
        "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i think he 's a great player . i think he 's a great player .\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 2\n",
        "3. Maintains Context: 2\n",
        "4. Interesting: 2\n",
        "5. Overall Quality: 2\"\"\"\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "EA3LyTUEhmTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_oneshot = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull/interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of this utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
        "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
        "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
        "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 3\n",
        "3. Maintains Context: 3\n",
        "4. Interesting: 3\n",
        "5. Overall Quality: 5\"\"\"\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "osvT8m8s6z0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_likert_feedback(all_prompts[36:72], prefix_threeshot)"
      ],
      "metadata": {
        "id": "TLw9TNNptfvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_a1a2a3(all_labels, result):\n",
        "    annotator_1 = []\n",
        "    annotator_2 = []\n",
        "    annotator_3 = []\n",
        "    for each in all_labels:\n",
        "        a1_here = []\n",
        "        a2_here = []\n",
        "        a3_here = []\n",
        "        for e in each:\n",
        "            a1_here.append(e[0])\n",
        "            a2_here.append(e[1])\n",
        "            a3_here.append(e[2])\n",
        "        annotator_1.append(a1_here)\n",
        "        annotator_2.append(a2_here)\n",
        "        annotator_3.append(a3_here)\n",
        "    return annotator_1, annotator_2, annotator_3"
      ],
      "metadata": {
        "id": "s3htltMn96cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_all_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WyicKvrcKtg",
        "outputId": "eb6a1d32-4238-4a55-fbd9-debc9e234ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1], [3, 3, 3], [3, 3, 3], [1, 2, 1], [0, 0, 0], [3, 4, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flG_brh4cIRl",
        "outputId": "fd6a0a2b-939e-48c4-89ac-35bd6960e56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 3, 3, 1, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1, a2, a3 = get_a1a2a3(pc_all_labels[10:300], pc_result)"
      ],
      "metadata": {
        "id": "PD9kiDRnAeQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1, a2, a3 = get_a1a2a3(tc_all_labels[12:360], tc_result)"
      ],
      "metadata": {
        "id": "MoVfIcDqvwqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_result_predictions(result):\n",
        "    all_preds = []\n",
        "    for each in result:\n",
        "        splits = each.split(\"\\n\")[1:]\n",
        "        predictions = [int(p[-1]) for p in splits]\n",
        "        all_preds.append(predictions)\n",
        "    return all_preds"
      ],
      "metadata": {
        "id": "QKkTxTuuCZy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = get_result_predictions(pc_result)"
      ],
      "metadata": {
        "id": "KTz31i8PDGRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = get_result_predictions(tc_result)"
      ],
      "metadata": {
        "id": "u0GERGZYv2yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1_q1 = [each[0] for each in a1]\n",
        "a1_q2 = [each[1] for each in a1]\n",
        "a1_q3 = [each[2] for each in a1]\n",
        "a1_q4 = [each[3] for each in a1]\n",
        "a1_q5 = [each[4] for each in a1]\n",
        "a1_q6 = [each[5] for each in a1]\n",
        "\n",
        "a2_q1 = [each[0] for each in a2]\n",
        "a2_q2 = [each[1] for each in a2]\n",
        "a2_q3 = [each[2] for each in a2]\n",
        "a2_q4 = [each[3] for each in a2]\n",
        "a2_q5 = [each[4] for each in a2]\n",
        "a2_q6 = [each[5] for each in a2]\n",
        "\n",
        "a3_q1 = [each[0] for each in a3]\n",
        "a3_q2 = [each[1] for each in a3]\n",
        "a3_q3 = [each[2] for each in a3]\n",
        "a3_q4 = [each[3] for each in a3]\n",
        "a3_q5 = [each[4] for each in a3]\n",
        "a3_q6 = [each[5] for each in a3]\n",
        "\n",
        "preds_q1 = [each[0] for each in all_preds]\n",
        "preds_q2 = [each[1] for each in all_preds]\n",
        "preds_q3 = [each[2] for each in all_preds]\n",
        "preds_q4 = [each[3] for each in all_preds]\n",
        "preds_q5 = [each[4] for each in all_preds]\n",
        "preds_q6 = [each[4] for each in all_preds]\n",
        "\n",
        "avg_q1 = [(p + q + r) / 3 for p, q, r in zip(a1_q1, a2_q1, a3_q1)]\n",
        "avg_q2 = [(p + q + r) / 3 for p, q, r in zip(a1_q2, a2_q2, a3_q2)]\n",
        "avg_q3 = [(p + q + r) / 3 for p, q, r in zip(a1_q3, a2_q3, a3_q3)]\n",
        "avg_q4 = [(p + q + r) / 3 for p, q, r in zip(a1_q4, a2_q4, a3_q4)]\n",
        "avg_q5 = [(p + q + r) / 3 for p, q, r in zip(a1_q5, a2_q5, a3_q5)]\n",
        "avg_q6 = [(p + q + r) / 3 for p, q, r in zip(a1_q6, a2_q6, a3_q6)]"
      ],
      "metadata": {
        "id": "D9QXSP0iDoqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_q1"
      ],
      "metadata": {
        "id": "ZVt5DkZUbKE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b, c in zip(a1_q1, a2_q1, a3_q1):\n",
        "    print(a, b, c)"
      ],
      "metadata": {
        "id": "gp7AutIVac-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in all_prompts[36:72]:\n",
        "    print(each)"
      ],
      "metadata": {
        "id": "IX-CZ6m2JbM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot TC\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685a9a8f-34cf-46df-cad7-027c87c89bc0",
        "id": "U9Oe3LTGwaps"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  0.27439242143985465\n",
            "p =  1.9879625220522456e-07\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.334544070993657\n",
            "p =  1.5152099326200143e-10\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.31702533060441584\n",
            "p =  1.4529195844553958e-09\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.38310134474756563\n",
            "p =  1.3077732149719403e-13\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.5207202296292283\n",
            "p =  1.4081152879378415e-25\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.44192629542108725\n",
            "p =  4.5344950005935225e-18\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot TC\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208b638b-676a-49ba-8881-0f3918093ffc",
        "id": "vMvgbIMSwaps"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  0.26636125681997547\n",
            "p =  4.597017877523339e-07\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.32436415028537324\n",
            "p =  5.7358477955303e-10\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.31058464198509994\n",
            "p =  3.2179272216892623e-09\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.3515321357715196\n",
            "p =  1.4701022970810943e-11\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.5276249389291235\n",
            "p =  2.4724414945777766e-26\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.44240844151950665\n",
            "p =  4.1328351059246755e-18\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot PC\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = spearmanr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy3hCTRIbVgo",
        "outputId": "1f90d2eb-d53c-42de-99ef-39385bed14a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  0.001987256992043949\n",
            "p =  0.9731198554098119\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.3796573439048053\n",
            "p =  2.238772236339354e-11\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.42120532910187497\n",
            "p =  6.711196774591265e-14\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.2564979136932833\n",
            "p =  9.717737938515492e-06\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.47661744686295093\n",
            "p =  7.469723156893223e-18\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.5236070064165446\n",
            "p =  8.122723895575865e-22\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New two-shot PC\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, avg_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, avg_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, avg_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, avg_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Q6:\")\n",
        "rho, p = pearsonr(preds_q5, avg_q6)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0qUgmQMeFbx",
        "outputId": "8a2e8efc-95ce-40ef-e23f-5e648ab40b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1:\n",
            "Rho =  -0.010621345273839438\n",
            "p =  0.8570749352156075\n",
            "\n",
            "\n",
            "Q2:\n",
            "Rho =  0.38470138000725124\n",
            "p =  1.1538979684068542e-11\n",
            "\n",
            "\n",
            "Q3:\n",
            "Rho =  0.43842256638155735\n",
            "p =  4.726455044586849e-15\n",
            "\n",
            "\n",
            "Q4:\n",
            "Rho =  0.20937012546191983\n",
            "p =  0.0003307866781860974\n",
            "\n",
            "\n",
            "Q5:\n",
            "Rho =  0.46790083832213636\n",
            "p =  3.497698902104082e-17\n",
            "\n",
            "\n",
            "Q6:\n",
            "Rho =  0.5128384528035694\n",
            "p =  7.461495239602863e-21\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Three-shot\n",
        "print(\"A1:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a1_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a1_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a1_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a1_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a1_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a2_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a2_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a2_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a2_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a2_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a3_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a3_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a3_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a3_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a3_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmqciwNJ9NpA",
        "outputId": "b22d914f-c766-42e1-f0f8-993405556b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1:\n",
            "Q1:\n",
            "Rho =  0.3597531123369121\n",
            "p =  0.03115577790357519\n",
            "\n",
            "\n",
            "A1:\n",
            "Q2:\n",
            "Rho =  0.48399310122686723\n",
            "p =  0.0027822035685411816\n",
            "\n",
            "\n",
            "A1:\n",
            "Q3:\n",
            "Rho =  0.565798595986671\n",
            "p =  0.0003227312954321932\n",
            "\n",
            "\n",
            "A1:\n",
            "Q4:\n",
            "Rho =  0.630632661427228\n",
            "p =  3.744058621849894e-05\n",
            "\n",
            "\n",
            "A1:\n",
            "Q5:\n",
            "Rho =  0.4271562417632878\n",
            "p =  0.009367947409070286\n",
            "\n",
            "\n",
            "A2:\n",
            "Q1:\n",
            "Rho =  0.19180536399919287\n",
            "p =  0.2624320268574069\n",
            "\n",
            "\n",
            "A2:\n",
            "Q2:\n",
            "Rho =  0.2146171695716535\n",
            "p =  0.20876603766842428\n",
            "\n",
            "\n",
            "A2:\n",
            "Q3:\n",
            "Rho =  0.5007325841549967\n",
            "p =  0.0018682740747486834\n",
            "\n",
            "\n",
            "A2:\n",
            "Q4:\n",
            "Rho =  0.5361802898312802\n",
            "p =  0.0007499378910803894\n",
            "\n",
            "\n",
            "A2:\n",
            "Q5:\n",
            "Rho =  0.4042224146990389\n",
            "p =  0.014481072375130655\n",
            "\n",
            "\n",
            "A3:\n",
            "Q1:\n",
            "Rho =  0.3779644730092272\n",
            "p =  0.023038339947883273\n",
            "\n",
            "\n",
            "A3:\n",
            "Q2:\n",
            "Rho =  0.38012312072333565\n",
            "p =  0.02220483998804147\n",
            "\n",
            "\n",
            "A3:\n",
            "Q3:\n",
            "Rho =  0.6631060506455426\n",
            "p =  1.047578639413085e-05\n",
            "\n",
            "\n",
            "A3:\n",
            "Q4:\n",
            "Rho =  0.4556641901461847\n",
            "p =  0.005226172508243841\n",
            "\n",
            "\n",
            "A3:\n",
            "Q5:\n",
            "Rho =  0.407070400451245\n",
            "p =  0.013740124408812539\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-shot\n",
        "print(\"A1:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a1_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a1_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a1_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a1_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a1_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a2_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a2_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a2_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a2_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a2_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a3_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a3_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a3_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a3_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a3_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxZEwdjN7nKF",
        "outputId": "ab8ca431-7234-43a7-ec95-e0ca8d4365b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1:\n",
            "Q1:\n",
            "Rho =  nan\n",
            "p =  nan\n",
            "\n",
            "\n",
            "A1:\n",
            "Q2:\n",
            "Rho =  0.4096311025152638\n",
            "p =  0.013101462752146008\n",
            "\n",
            "\n",
            "A1:\n",
            "Q3:\n",
            "Rho =  0.5205884609545358\n",
            "p =  0.0011341635229375347\n",
            "\n",
            "\n",
            "A1:\n",
            "Q4:\n",
            "Rho =  0.4446412788608937\n",
            "p =  0.006587178818212982\n",
            "\n",
            "\n",
            "A1:\n",
            "Q5:\n",
            "Rho =  0.6301723490899106\n",
            "p =  3.808316254599702e-05\n",
            "\n",
            "\n",
            "A2:\n",
            "Q1:\n",
            "Rho =  nan\n",
            "p =  nan\n",
            "\n",
            "\n",
            "A2:\n",
            "Q2:\n",
            "Rho =  0.15430334996209188\n",
            "p =  0.36889538679932155\n",
            "\n",
            "\n",
            "A2:\n",
            "Q3:\n",
            "Rho =  0.5940589695611211\n",
            "p =  0.00013356268186996652\n",
            "\n",
            "\n",
            "A2:\n",
            "Q4:\n",
            "Rho =  0.5006856103432309\n",
            "p =  0.0018704157082432102\n",
            "\n",
            "\n",
            "A2:\n",
            "Q5:\n",
            "Rho =  0.580006210227905\n",
            "p =  0.00020921925699410296\n",
            "\n",
            "\n",
            "A3:\n",
            "Q1:\n",
            "Rho =  nan\n",
            "p =  nan\n",
            "\n",
            "\n",
            "A3:\n",
            "Q2:\n",
            "Rho =  0.47915742374995496\n",
            "p =  0.003110024708405117\n",
            "\n",
            "\n",
            "A3:\n",
            "Q3:\n",
            "Rho =  0.7210201137220399\n",
            "p =  7.040816090357907e-07\n",
            "\n",
            "\n",
            "A3:\n",
            "Q4:\n",
            "Rho =  0.656489083549774\n",
            "p =  1.3747829963901585e-05\n",
            "\n",
            "\n",
            "A3:\n",
            "Q5:\n",
            "Rho =  0.6447985949409263\n",
            "p =  2.18751381974944e-05\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(SpearmanRConstantInputWarning())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Two-shot\n",
        "print(\"A1:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a1_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a1_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a1_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a1_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a1_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a2_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a2_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a2_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a2_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a2_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = spearmanr(preds_q1, a3_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = spearmanr(preds_q2, a3_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = spearmanr(preds_q3, a3_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = spearmanr(preds_q4, a3_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = spearmanr(preds_q5, a3_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Yv2srXEJME",
        "outputId": "fe900aea-e8bb-4657-9b95-5dbfa0333f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1:\n",
            "Q1:\n",
            "Rho =  0.3597531123369121\n",
            "p =  0.03115577790357519\n",
            "\n",
            "\n",
            "A1:\n",
            "Q2:\n",
            "Rho =  0.5696551598485589\n",
            "p =  0.0002874687260690696\n",
            "\n",
            "\n",
            "A1:\n",
            "Q3:\n",
            "Rho =  0.6075745430783167\n",
            "p =  8.501392651636377e-05\n",
            "\n",
            "\n",
            "A1:\n",
            "Q4:\n",
            "Rho =  0.5629553803385252\n",
            "p =  0.00035115113323739634\n",
            "\n",
            "\n",
            "A1:\n",
            "Q5:\n",
            "Rho =  0.7224654409426133\n",
            "p =  6.526573427828223e-07\n",
            "\n",
            "\n",
            "A2:\n",
            "Q1:\n",
            "Rho =  0.19180536399919287\n",
            "p =  0.2624320268574069\n",
            "\n",
            "\n",
            "A2:\n",
            "Q2:\n",
            "Rho =  0.266443538229318\n",
            "p =  0.11623176318003522\n",
            "\n",
            "\n",
            "A2:\n",
            "Q3:\n",
            "Rho =  0.6887995090948066\n",
            "p =  3.4112744936054274e-06\n",
            "\n",
            "\n",
            "A2:\n",
            "Q4:\n",
            "Rho =  0.6508859286235019\n",
            "p =  1.7217941471318604e-05\n",
            "\n",
            "\n",
            "A2:\n",
            "Q5:\n",
            "Rho =  0.6066891087757375\n",
            "p =  8.76226524345307e-05\n",
            "\n",
            "\n",
            "A3:\n",
            "Q1:\n",
            "Rho =  0.3779644730092272\n",
            "p =  0.023038339947883273\n",
            "\n",
            "\n",
            "A3:\n",
            "Q2:\n",
            "Rho =  0.3900135044513915\n",
            "p =  0.01869934321171734\n",
            "\n",
            "\n",
            "A3:\n",
            "Q3:\n",
            "Rho =  0.5334753598770609\n",
            "p =  0.000806886396906794\n",
            "\n",
            "\n",
            "A3:\n",
            "Q4:\n",
            "Rho =  0.45212818007716715\n",
            "p =  0.0056335525153890405\n",
            "\n",
            "\n",
            "A3:\n",
            "Q5:\n",
            "Rho =  0.4746760901646803\n",
            "p =  0.003443329077102871\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each in all_prompts[36:72]: # 6, 6, 6, 6, 6, 6\n",
        "    print(each)"
      ],
      "metadata": {
        "id": "bhK1YixNPUzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Three-shot\n",
        "print(\"A1:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a1_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a1_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a1_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a1_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a1_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a2_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a2_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a2_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a2_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a2_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a3_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a3_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a3_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a3_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a3_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxgF4HZL9R0_",
        "outputId": "92bd6b2c-4842-4531-d60b-2e53d4a5a109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1:\n",
            "Q1:\n",
            "Rho =  0.35975311233691204\n",
            "p =  0.031155777903575203\n",
            "\n",
            "\n",
            "A1:\n",
            "Q2:\n",
            "Rho =  0.497836282969315\n",
            "p =  0.002004415516464869\n",
            "\n",
            "\n",
            "A1:\n",
            "Q3:\n",
            "Rho =  0.5442477655948227\n",
            "p =  0.0006006524805892604\n",
            "\n",
            "\n",
            "A1:\n",
            "Q4:\n",
            "Rho =  0.6022701394626141\n",
            "p =  0.00010175279714208205\n",
            "\n",
            "\n",
            "A1:\n",
            "Q5:\n",
            "Rho =  0.4150694167010262\n",
            "p =  0.011827864344576895\n",
            "\n",
            "\n",
            "A2:\n",
            "Q1:\n",
            "Rho =  0.1918053639991929\n",
            "p =  0.26243202685740713\n",
            "\n",
            "\n",
            "A2:\n",
            "Q2:\n",
            "Rho =  0.18172434016970188\n",
            "p =  0.28881291839239004\n",
            "\n",
            "\n",
            "A2:\n",
            "Q3:\n",
            "Rho =  0.49720837544445545\n",
            "p =  0.0020350511031055666\n",
            "\n",
            "\n",
            "A2:\n",
            "Q4:\n",
            "Rho =  0.5261805156277664\n",
            "p =  0.0009800081906783757\n",
            "\n",
            "\n",
            "A2:\n",
            "Q5:\n",
            "Rho =  0.41519340695849155\n",
            "p =  0.011800095657353253\n",
            "\n",
            "\n",
            "A3:\n",
            "Q1:\n",
            "Rho =  0.3779644730092273\n",
            "p =  0.023038339947883218\n",
            "\n",
            "\n",
            "A3:\n",
            "Q2:\n",
            "Rho =  0.374523232994072\n",
            "p =  0.024420622489172313\n",
            "\n",
            "\n",
            "A3:\n",
            "Q3:\n",
            "Rho =  0.6511684794727156\n",
            "p =  1.702549153086384e-05\n",
            "\n",
            "\n",
            "A3:\n",
            "Q4:\n",
            "Rho =  0.44996889686186714\n",
            "p =  0.005895535448447481\n",
            "\n",
            "\n",
            "A3:\n",
            "Q5:\n",
            "Rho =  0.3795290152207225\n",
            "p =  0.02243169941400079\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-shot\n",
        "print(\"A1:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a1_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a1_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a1_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a1_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a1_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a2_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a2_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a2_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a2_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a2_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a3_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a3_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a3_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a3_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a3_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z73kArk37zeT",
        "outputId": "1e04da16-6433-4201-833f-783db14c9f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1:\n",
            "Q1:\n",
            "Rho =  nan\n",
            "p =  nan\n",
            "\n",
            "\n",
            "A1:\n",
            "Q2:\n",
            "Rho =  0.4140276697322967\n",
            "p =  0.012063365367067315\n",
            "\n",
            "\n",
            "A1:\n",
            "Q3:\n",
            "Rho =  0.494918204046779\n",
            "p =  0.0021502916864054966\n",
            "\n",
            "\n",
            "A1:\n",
            "Q4:\n",
            "Rho =  0.4295156513844953\n",
            "p =  0.008942493365440587\n",
            "\n",
            "\n",
            "A1:\n",
            "Q5:\n",
            "Rho =  0.6419970757530069\n",
            "p =  2.4380461482676502e-05\n",
            "\n",
            "\n",
            "A2:\n",
            "Q1:\n",
            "Rho =  nan\n",
            "p =  nan\n",
            "\n",
            "\n",
            "A2:\n",
            "Q2:\n",
            "Rho =  0.15113182318762075\n",
            "p =  0.37893625132656944\n",
            "\n",
            "\n",
            "A2:\n",
            "Q3:\n",
            "Rho =  0.5809351195183401\n",
            "p =  0.00020323168085842002\n",
            "\n",
            "\n",
            "A2:\n",
            "Q4:\n",
            "Rho =  0.4847199118241301\n",
            "p =  0.0027356325897672363\n",
            "\n",
            "\n",
            "A2:\n",
            "Q5:\n",
            "Rho =  0.6042242070232713\n",
            "p =  9.526928103816069e-05\n",
            "\n",
            "\n",
            "A3:\n",
            "Q1:\n",
            "Rho =  nan\n",
            "p =  nan\n",
            "\n",
            "\n",
            "A3:\n",
            "Q2:\n",
            "Rho =  0.47014920054630716\n",
            "p =  0.0038111069279622148\n",
            "\n",
            "\n",
            "A3:\n",
            "Q3:\n",
            "Rho =  0.6955771262930224\n",
            "p =  2.489422610454916e-06\n",
            "\n",
            "\n",
            "A3:\n",
            "Q4:\n",
            "Rho =  0.6509968357725415\n",
            "p =  1.7142166334007856e-05\n",
            "\n",
            "\n",
            "A3:\n",
            "Q5:\n",
            "Rho =  0.6479072685515591\n",
            "p =  1.937048803718172e-05\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two-shot\n",
        "print(\"A1:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a1_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a1_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a1_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a1_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A1:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a1_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a2_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a2_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a2_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a2_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A2:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a2_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q1:\")\n",
        "rho, p = pearsonr(preds_q1, a3_q1)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q2:\")\n",
        "rho, p = pearsonr(preds_q2, a3_q2)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q3:\")\n",
        "rho, p = pearsonr(preds_q3, a3_q3)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q4:\")\n",
        "rho, p = pearsonr(preds_q4, a3_q4)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"A3:\")\n",
        "print(\"Q5:\")\n",
        "rho, p = pearsonr(preds_q5, a3_q5)\n",
        "print(\"Rho = \", rho)\n",
        "print(\"p = \", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vddKbJ9EdoL",
        "outputId": "a127037d-7bfd-4efd-fb9e-73531d36d4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1:\n",
            "Q1:\n",
            "Rho =  0.35975311233691204\n",
            "p =  0.031155777903575203\n",
            "\n",
            "\n",
            "A1:\n",
            "Q2:\n",
            "Rho =  0.5803810000880091\n",
            "p =  0.00020678466712258802\n",
            "\n",
            "\n",
            "A1:\n",
            "Q3:\n",
            "Rho =  0.5825248321362804\n",
            "p =  0.00019334017585443116\n",
            "\n",
            "\n",
            "A1:\n",
            "Q4:\n",
            "Rho =  0.547396100288584\n",
            "p =  0.0005499728564205586\n",
            "\n",
            "\n",
            "A1:\n",
            "Q5:\n",
            "Rho =  0.44143650158916675\n",
            "p =  0.007035901283422926\n",
            "\n",
            "\n",
            "A2:\n",
            "Q1:\n",
            "Rho =  0.1918053639991929\n",
            "p =  0.26243202685740713\n",
            "\n",
            "\n",
            "A2:\n",
            "Q2:\n",
            "Rho =  0.2581988897471611\n",
            "p =  0.1284021677100856\n",
            "\n",
            "\n",
            "A2:\n",
            "Q3:\n",
            "Rho =  0.680050551144063\n",
            "p =  5.061063959737835e-06\n",
            "\n",
            "\n",
            "A2:\n",
            "Q4:\n",
            "Rho =  0.6237933129047376\n",
            "p =  4.807730697015782e-05\n",
            "\n",
            "\n",
            "A2:\n",
            "Q5:\n",
            "Rho =  0.47134999226939883\n",
            "p =  0.00371037633636375\n",
            "\n",
            "\n",
            "A3:\n",
            "Q1:\n",
            "Rho =  0.3779644730092273\n",
            "p =  0.023038339947883218\n",
            "\n",
            "\n",
            "A3:\n",
            "Q2:\n",
            "Rho =  0.3815291812286869\n",
            "p =  0.021675515647252248\n",
            "\n",
            "\n",
            "A3:\n",
            "Q3:\n",
            "Rho =  0.5177456541245096\n",
            "p =  0.0012204404106634322\n",
            "\n",
            "\n",
            "A3:\n",
            "Q4:\n",
            "Rho =  0.45872660150200906\n",
            "p =  0.004894141427772592\n",
            "\n",
            "\n",
            "A3:\n",
            "Q5:\n",
            "Rho =  0.3815931219822954\n",
            "p =  0.021651696050319573\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7uU6iFBvEeEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **One-shot**"
      ],
      "metadata": {
        "id": "U7w8uY9x9kC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Annotation Instructions: \n",
        "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
        "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
        "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
        "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
        "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
        "Interesting (1 - 3): Is the response dull/interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
        "Overall Quality (1 - 5): Given your answers above, what is your overall impression of this utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
        "Person 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
        "Person 1:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
        "Person 2:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 3\n",
        "3. Maintains Context: 3\n",
        "4. Interesting: 3\n",
        "5. Overall Quality: 5\n",
        "\n",
        "\n",
        "Context:\n",
        "Person 1:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
        "Person 2:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
        "Person 1:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
        "Person 2:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
        "\n",
        "Generated response: \n",
        "Agent: i think he 's a great player . i think he 's a great player .\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
        "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
        "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
        "4. Interesting (1 - 3): Is the response dull or interesting?\n",
        "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
        "\n",
        "Answers:\n",
        "1. Understandable: 1\n",
        "2. Natural: 2\n",
        "3. Maintains Context: 2\n",
        "4. Interesting: 2\n",
        "5. Overall Quality: 2\"\"\"\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "GuzhLTJp9pxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Zero-shot**"
      ],
      "metadata": {
        "id": "ZC1HoI679mty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_here)\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNfs0nVuiHC4",
        "outputId": "b5ffd912-c956-4ace-a4aa-4e1ccc25518b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Human Evaluation of Chatbot Outputs:\n",
            "\n",
            "Context:\n",
            "Person 1: so , i 'm reading the latest film from studio ghibli is out the tale of princess kaguya . dunno if you 're familiar with them , but studio ghibli has made a lot of great animated films , like spirited away , and princess mononoke \n",
            "Person 2:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
            "Person 1:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
            "Person 2:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
            "Person 1:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 4\n",
            "2. 4\n",
            "3. 4\n",
            "4. 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[1]\n",
        "prompt_here = f\"\"\"\n",
        "Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\"\"\"\n",
        "print(prompt_here)\n",
        "result = get_likert_feedback([prompt_here])\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4Ygj2-Lhw7f",
        "outputId": "bac8667b-bec2-4d57-da0d-698b27869d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Human Evaluation of Chatbot Outputs:\n",
            "\n",
            "Context:\n",
            "Person 1: i think that jon gruden is a sensible loss for the team , \n",
            "Person 2:  what do you mean by sensible loss ? i think john gruden is a huge mistake for the team . \n",
            "Person 1:  well i think his a good player , hard to replace , that s what i meant or at least in the raiders team his become an important piece for the coach \n",
            "Person 2:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
            "Person 1:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
            "Person 2:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
            "Person 1:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: i like the giants best , you ? . he did demand a high salary . he 's the highest paid defensive player in the nfl . i guess the raiders tied up too much money in carr and gruden .\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 4\n",
            "2. 4\n",
            "3. 4\n",
            "4. 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[2]\n",
        "prompt_here = f\"\"\"\n",
        "Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\"\"\"\n",
        "print(prompt_here)\n",
        "result = get_likert_feedback([prompt_here])\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYC47rDjiPWR",
        "outputId": "74919276-4544-4219-d658-7d58e0872f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Human Evaluation of Chatbot Outputs:\n",
            "\n",
            "Context:\n",
            "Person 1: hello \n",
            "Person 2:  hi . the nfl seems to be at the end of its days . \n",
            "Person 1:  that 's what people seem to be saying everywhere , but i do n't know . they have gotten through scandals and issues before . i 'm not counting them out yet . \n",
            "Person 2:  what about the problems with the ncaa though ? the nfl needs the players . \n",
            "Person 1:  i get that and it is valid , but it 's like any sport . if 1 person quits , there are 5 waiting to take their place . if players do n't want to play , then they should move along . \n",
            "Person 2:  what about the fans though . people might get bored of a game when the quality goes down . \n",
            "Person 1:  that is true . everything runs in cycles though . i liken it to a losing team having an empty stadium and a winning team selling out . fans are fickle . their ... our views are important , but we come and go . \n",
            "Person 2:  i wonder whether letting women into the game would create interest , get more fans . \n",
            "Person 1:  oh , it absolutely would . it would be like ... and i know i am going to butcher the name here , but when manon reheaume played in the nhl . my only concern is that if mishandled it might come off like a gimmick . \n",
            "Person 2:  i see your point . long term , will women stay ? true . \n",
            "Person 1:  i feel like ... there are enough talented women athletes out there , that a woman kicker or qb is possible , perhaps a wide receiver . \n",
            "Person 2:  women can be tough too . would a coach like bill belichick hire a woman if she could help him win the super bowl ? \n",
            "Person 1:  this is going to come off sounding bad , but it is n't meant to . i think anyone in the front office would look at it from the perspective of generating revenue and views . the sponsors would love the coverage . \n",
            "Person 2:  belichick has done well in the post season , so i think he 's looking at it from a strategic point of view . the sponsors would tie her presence into a bunch of social issues and products . \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: oh absolutely . belichek is looking at it from the right angle too . he wants to win , that 's what he is paid for . i think the guy would hire a green martian if he thought it would guarantee an extra td .\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 4\n",
            "2. 4\n",
            "3. 4\n",
            "4. 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **With Header**"
      ],
      "metadata": {
        "id": "81BF9V0hmbO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "likert_header = \"\"\"\n",
        "\n",
        "HUMAN EVALUATION OF CHATBOT OUTPUTS\n",
        "\n",
        "\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "\n",
        "Dialog histories between person A and person B (the contexts) are listed under \"EXAMPLES\" below. \n",
        "You are required to answer the questions posed at the end of each example on how appropriate/correct the generated response by the agent is, with respect to the context.\n",
        "Respond to the questions using a 1-to-5 Likert scale (1 being very negative, 5 being very positive).\n",
        "\n",
        "\n",
        "\n",
        "TERMS USED:\n",
        "\n",
        "\n",
        "Person 1 -- an individual engaging in dialog with Person 2\n",
        "Person 2 -- an individual engaging in dialog with Person 1\n",
        "Context -- an incomplete conversation between Person 1 and Person 2 (the dialog history so far)\n",
        "Generated response -- a continuation of the conversation presented in the context, said by either Person 1 or Person 2, depending on who said the preceding sentence\n",
        "Questions about the agent's response -- a set of four questions asked to evaluate the quality of the agent's response with respect to the dialog history (context) that has taken place upto that point.\n",
        "Answers -- human responses on a 1-5 Likert scale on how good the agent's generated response is in the given context\n",
        "\n",
        "\n",
        "EXAMPLES:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XEFMcid4je7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[0]\n",
        "prompt_here = f\"\"\"\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\"\"\"\n",
        "print(prompt_here)\n",
        "result = get_likert_feedback([prompt_here], likert_header)\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXbtwAZsmUTK",
        "outputId": "1d2ba225-ac67-42de-d4fe-3d485c9267b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Context:\n",
            "Person 1: so , i 'm reading the latest film from studio ghibli is out the tale of princess kaguya . dunno if you 're familiar with them , but studio ghibli has made a lot of great animated films , like spirited away , and princess mononoke \n",
            "Person 2:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
            "Person 1:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
            "Person 2:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
            "Person 1:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 3\n",
            "2. 3\n",
            "3. 3\n",
            "4. 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[1]\n",
        "prompt_here = f\"\"\"\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\"\"\"\n",
        "print(prompt_here)\n",
        "result = get_likert_feedback([prompt_here], likert_header)\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1HD3zTDl1v5",
        "outputId": "092d9093-332a-4c35-84e2-801eb8632bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Context:\n",
            "Person 1: i think that jon gruden is a sensible loss for the team , \n",
            "Person 2:  what do you mean by sensible loss ? i think john gruden is a huge mistake for the team . \n",
            "Person 1:  well i think his a good player , hard to replace , that s what i meant or at least in the raiders team his become an important piece for the coach \n",
            "Person 2:  john gruden is an nfl head coach . he 's not a player . the 33 - 13 loss to the rams was just the beginning of a miserable season . are you familiar with the nfl ? \n",
            "Person 1:  oh i see , i guess i m confusing him with a player of the team , what was his name i think it was khalil mack , and i do follow some games what about you ? \n",
            "Person 2:  football is one of my favorite sports and i follow all 32 teams . khalil mack was traded to the bears by john gruden for some picks . they definitely felt his absence . i do n't know why they did n't just resign him . \n",
            "Person 1:  maybe he demanded a high salary ? what is your favorite nfl team ? \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: i like the giants best , you ? . he did demand a high salary . he 's the highest paid defensive player in the nfl . i guess the raiders tied up too much money in carr and gruden .\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 3\n",
            "2. 3\n",
            "3. 3\n",
            "4. 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[2]\n",
        "prompt_here = f\"\"\"\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\"\"\"\n",
        "print(prompt_here)\n",
        "result = get_likert_feedback([prompt_here], likert_header)\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QMFlhyJlhqv",
        "outputId": "c14caf6d-3ed6-4a96-8fe5-bb58061545ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Context:\n",
            "Person 1: hello \n",
            "Person 2:  hi . the nfl seems to be at the end of its days . \n",
            "Person 1:  that 's what people seem to be saying everywhere , but i do n't know . they have gotten through scandals and issues before . i 'm not counting them out yet . \n",
            "Person 2:  what about the problems with the ncaa though ? the nfl needs the players . \n",
            "Person 1:  i get that and it is valid , but it 's like any sport . if 1 person quits , there are 5 waiting to take their place . if players do n't want to play , then they should move along . \n",
            "Person 2:  what about the fans though . people might get bored of a game when the quality goes down . \n",
            "Person 1:  that is true . everything runs in cycles though . i liken it to a losing team having an empty stadium and a winning team selling out . fans are fickle . their ... our views are important , but we come and go . \n",
            "Person 2:  i wonder whether letting women into the game would create interest , get more fans . \n",
            "Person 1:  oh , it absolutely would . it would be like ... and i know i am going to butcher the name here , but when manon reheaume played in the nhl . my only concern is that if mishandled it might come off like a gimmick . \n",
            "Person 2:  i see your point . long term , will women stay ? true . \n",
            "Person 1:  i feel like ... there are enough talented women athletes out there , that a woman kicker or qb is possible , perhaps a wide receiver . \n",
            "Person 2:  women can be tough too . would a coach like bill belichick hire a woman if she could help him win the super bowl ? \n",
            "Person 1:  this is going to come off sounding bad , but it is n't meant to . i think anyone in the front office would look at it from the perspective of generating revenue and views . the sponsors would love the coverage . \n",
            "Person 2:  belichick has done well in the post season , so i think he 's looking at it from a strategic point of view . the sponsors would tie her presence into a bunch of social issues and products . \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: oh absolutely . belichek is looking at it from the right angle too . he wants to win , that 's what he is paid for . i think the guy would hire a green martian if he thought it would guarantee an extra td .\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 3\n",
            "2. 3\n",
            "3. 3\n",
            "4. 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **One-shot, no header**"
      ],
      "metadata": {
        "id": "b3-Yj5ZtmoM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "each['responses'][0]['']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcycHc4MnE33",
        "outputId": "6a4a7cf8-5403-4556-94ba-b15181e9bb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': \"well , but time probably added to the value , no ? i wonder if the grandson found a honus wagner . is n't that the super valuable one ? in the 90s i think wayne gretzky bought one as an investment . \\n\",\n",
              " 'model': 'Original Ground Truth',\n",
              " 'Understandable': [1, 1, 1],\n",
              " 'Natural': [3, 3, 3],\n",
              " 'Maintains Context': [3, 3, 2],\n",
              " 'Engaging': [3, 3, 3],\n",
              " 'Uses Knowledge': [1, 1, 1],\n",
              " 'Overall': [5, 5, 4]}"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[3]\n",
        "prompt_here = f\"\"\"\n",
        "\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
        "1. {each['responses'][0]}\"\"\"\n",
        "print(prompt_here)\n",
        "\n",
        "# result = get_likert_feedback([prompt_here], likert_one_shot)\n",
        "# for each in result:\n",
        "#     print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5au48YyOmztx",
        "outputId": "b6e8876f-e6ba-45c1-c462-2a4288e74fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Context:\n",
            "Person 1: hi there , how 's it going ? \n",
            "Person 2:  it 's going great ! which do you prefer , football or baseball ? \n",
            "Person 1:  oh i guess baseball . although i do n't have time to see many games anymore . \n",
            "Person 2:  baseball is the american pastime . japanese are surprised to discover this fact . \n",
            "Person 1:  yeah , i guess they see it as being their own . they have their own fan culture around it . what is your favorite sport ? \n",
            "Person 2:  i like both baseball and football , but i usually follow them around playoff time . do n't have much time for games . \n",
            "Person 1:  yeah the seasons are so long that it 's tough to get really immersed . especially baseball . it 's what , 162 games ? \n",
            "Person 2:  162 , plus playoffs . soon they 'll be playing until christmas . until 2005 , a married couple scheduled all the games for the mlb . they must have had special software or something . \n",
            "Person 1:  yeah . although i think they had done it since the 80s . maybe they did the first few seasons on a commodore 64 lol ? \n",
            "Person 2:  the old c64 ! classic . i do n't remember any good sports games on that though . football , baseball , soccer . probably not easy to do on a c64 . \n",
            "Person 1:  yeah . i know they had accounting software lol , my dad used it . we had the minnesota fats pool game and i think one soccer one . but it was such a different era . no madden style graphics \n",
            "Person 2:  i wonder whether they had a version of kickball on the c64 . the canadians call the game soccer - baseball . \n",
            "Person 1:  yeah i 've read that somewhere . when i was a kid , we played a kind of kickball called rounders at camp . our counselor was english . he kept telling us \" run to fourth ! \" and we were like , \" you mean home ? run home ? \" \n",
            "Person 2:  baseball is american ! i do n't know the english would want with it . i bet the english do n't collect \" rounders \" cards the way we collect baseball cards . \n",
            "Person 1:  right ? i wonder if they have cricket cards lol ? i think they have stickers for soccer . \n",
            "Person 2:  some guy found $ 3 million dollars of baseball cards from the 1900s . i wonder what he did with the money . \n",
            "Person 1:  yeah . that 's an amazing find . i heard they had been hidden since the 40s . \n",
            "Person 2:  thanks , grandpa ! i bet grandpa wishes he had cashed them in before he cashed out . \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: well , but time probably added to the value , no ? i wonder if the grandson found a honus wagner . is n't that the super valuable one ? in the 90s i think wayne gretzky bought one as an investment .\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "likert_one_shot = \"\"\"\n",
        "Human Evaluation of Chatbot Outputs:\n",
        "\n",
        "Context:\n",
        "Person 1: hi there , how 's it going ? \n",
        "Person 2:  it 's going great ! which do you prefer , football or baseball ? \n",
        "Person 1:  oh i guess baseball . although i do n't have time to see many games anymore . \n",
        "Person 2:  baseball is the american pastime . japanese are surprised to discover this fact . \n",
        "Person 1:  yeah , i guess they see it as being their own . they have their own fan culture around it . what is your favorite sport ? \n",
        "Person 2:  i like both baseball and football , but i usually follow them around playoff time . do n't have much time for games . \n",
        "Person 1:  yeah the seasons are so long that it 's tough to get really immersed . especially baseball . it 's what , 162 games ? \n",
        "Person 2:  162 , plus playoffs . soon they 'll be playing until christmas . until 2005 , a married couple scheduled all the games for the mlb . they must have had special software or something . \n",
        "Person 1:  yeah . although i think they had done it since the 80s . maybe they did the first few seasons on a commodore 64 lol ? \n",
        "Person 2:  the old c64 ! classic . i do n't remember any good sports games on that though . football , baseball , soccer . probably not easy to do on a c64 . \n",
        "Person 1:  yeah . i know they had accounting software lol , my dad used it . we had the minnesota fats pool game and i think one soccer one . but it was such a different era . no madden style graphics \n",
        "Person 2:  i wonder whether they had a version of kickball on the c64 . the canadians call the game soccer - baseball . \n",
        "Person 1:  yeah i 've read that somewhere . when i was a kid , we played a kind of kickball called rounders at camp . our counselor was english . he kept telling us \" run to fourth ! \" and we were like , \" you mean home ? run home ? \" \n",
        "Person 2:  baseball is american ! i do n't know the english would want with it . i bet the english do n't collect \" rounders \" cards the way we collect baseball cards . \n",
        "Person 1:  right ? i wonder if they have cricket cards lol ? i think they have stickers for soccer . \n",
        "Person 2:  some guy found $ 3 million dollars of baseball cards from the 1900s . i wonder what he did with the money . \n",
        "Person 1:  yeah . that 's an amazing find . i heard they had been hidden since the 40s . \n",
        "Person 2:  thanks , grandpa ! i bet grandpa wishes he had cashed them in before he cashed out . \n",
        "\n",
        "\n",
        "Generated response: \n",
        "Agent: well , but time probably added to the value , no ? i wonder if the grandson found a honus wagner . is n't that the super valuable one ? in the 90s i think wayne gretzky bought one as an investment .\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
        "1. 1\n",
        "2. 3\n",
        "3. 3\n",
        "4. 3\"\"\""
      ],
      "metadata": {
        "id": "ifOwWjwfmvh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# three_prompt = \"\"\"\"\"\"\n",
        "each = tc_usr_data[0]\n",
        "prompt_here = f\"\"\"\n",
        "\n",
        "Context:\n",
        "\"\"\"\n",
        "for i in range(len([p for p in each['context'].split(\"\\n\") if p != \"\"])):\n",
        "    if i % 2 == 0:\n",
        "        prompt_here += \"Person 1: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "    else:\n",
        "        prompt_here += \"Person 2: \" + each['context'].split(\"\\n\")[i] + \"\\n\"\n",
        "prompt_here += f\"\"\"\n",
        "\n",
        "Generated response: \n",
        "Agent: {each['responses'][0]['response'].strip()}\n",
        "\n",
        "Questions about the agent's response:\n",
        "1. Is the response understandable in the context of the dialog history?\n",
        "2. Is the response naturally written?\n",
        "3. Does the response serve as a valid continuation of the conversation history?\n",
        "4. Is the response dull/interesting?\n",
        "\n",
        "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\"\"\"\n",
        "print(prompt_here)\n",
        "result = get_likert_feedback([prompt_here], likert_one_shot)\n",
        "for each in result:\n",
        "    print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cx1AOrDmV0J",
        "outputId": "f1afe8df-7a02-4148-9883-7b97285a2529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Context:\n",
            "Person 1: so , i 'm reading the latest film from studio ghibli is out the tale of princess kaguya . dunno if you 're familiar with them , but studio ghibli has made a lot of great animated films , like spirited away , and princess mononoke \n",
            "Person 2:  i do n't think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \n",
            "Person 1:  yeah , sadly , disney ( which owns the american rights to the films ) does n't tend to promote them very much . i think they 're worried they 'll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they 're worth checking out . \n",
            "Person 2:  i do n't watch them very often . apparently there was a showing of the recent film in a park in d.c . that 's one u.s . city i have n't been to \n",
            "Person 1:  sadly , i have n't been to dc either , although i 've always wanted to visit there . apparently there 's a lot of interesting going down this summer . they 're having a crab feast at the navy - marine corps stadium . they 'll have 100 gallons of crab soup ! can you imagine that much soup ? \n",
            "\n",
            "\n",
            "Generated response: \n",
            "Agent: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\n",
            "\n",
            "Questions about the agent's response:\n",
            "1. Is the response understandable in the context of the dialog history?\n",
            "2. Is the response naturally written?\n",
            "3. Does the response serve as a valid continuation of the conversation history?\n",
            "4. Is the response dull/interesting?\n",
            "\n",
            "Answers (Respond to the questions using a 1-to-5 likert scale. (1: very negative, 5: very positive):\n",
            "\n",
            "1. 5\n",
            "2. 5\n",
            "3. 5\n",
            "4. 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUE185FkmnE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-XNVKBICmnBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GPT-2**"
      ],
      "metadata": {
        "id": "kW6Cc2ybRgME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4F_PiozRhza",
        "outputId": "9372d12a-54fe-4c4a-ab0f-641c81eaa65d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "660"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_all_prompts.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_all_prompts, f1)\n",
        "with open(\"pc_all_prompts.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_all_prompts, f1)"
      ],
      "metadata": {
        "id": "R3MrThYh2W2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_context4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_context4, f1)\n",
        "with open(\"pc_context4.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_context4, f1)"
      ],
      "metadata": {
        "id": "JHOOMGJLVeq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prompts[36]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "F1szj-CtVvY_",
        "outputId": "06be4443-4e18-480e-e1c2-3fc96ea26a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\nContext:\\nPerson 1:  i have not seen it . tell me about the soundtrack . \\nPerson 2:  it is very sci fi , and super inspiring . it is made by daft punk , i love that duo ! \\nPerson 1:  i love that they negotiated with their robot helmets on . seems like something they would do . \\nPerson 2:  incognito style ! ! and very simple , they just needed a good breakfast with pancakes to say yes \\n\\nGenerated response: \\nAgent: did you watch the chapelle show ? the one where prince made them pancakes after a basketball game ?\\n\\nQuestions about the agent's response:\\n1. Understandable (0 - 1): Is the response understandable given the previous context?\\n2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\\n3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\\n4. Interesting (1 - 3): Is the response dull or interesting?\\n5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\\n\\nAnswers:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tc_all_labels.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(tc_all_labels, f1)\n",
        "with open(\"pc_all_labels.pkl\", \"wb\") as f1:\n",
        "    pkl.dump(pc_all_labels, f1)"
      ],
      "metadata": {
        "id": "rTmqiQNlZZT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tc_all_prompts[0]"
      ],
      "metadata": {
        "id": "32MF9HJ8iL2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "fcfad63f-8151-4f6e-fa2a-95edf3903d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\nContext:\\nPerson 1:  i do n\\'t think i have heard of them . i have heard that one of the directors recently passed away , and his last film was nominated for an academy award \\nPerson 2:  yeah , sadly , disney ( which owns the american rights to the films ) does n\\'t tend to promote them very much . i think they \\'re worried they \\'ll cut into their \" home grown \" market . anyway , dunno if you even like animated movies , but they \\'re worth checking out . \\nPerson 1:  i do n\\'t watch them very often . apparently there was a showing of the recent film in a park in d.c . that \\'s one u.s . city i have n\\'t been to \\nPerson 2:  sadly , i have n\\'t been to dc either , although i \\'ve always wanted to visit there . apparently there \\'s a lot of interesting going down this summer . they \\'re having a crab feast at the navy - marine corps stadium . they \\'ll have 100 gallons of crab soup ! can you imagine that much soup ? \\n\\nFacts:\\nfrom left , emma baker , daniel saperstein and taylor mulitz of flasher will perform this summer \\'s final fort reno concert . ( jared soares for the washington post ) monday , july 30 25th birthday celebration at national postal museum : celebrate 25 years of this institution devoted to the long history of the u.s . postal service with daytime festivities that include cupcakes , birthday postcards , a photo booth and a special scavenger hunt with prizes . 11 a.m. to 2 p.m. free . tuesday , july 31 \" the color purple \" at kennedy center : the tony award - winning musical revival , based on the pulitzer prize - winning alice walker novel of the same name , features jazz , ragtime , gospel and blues with a story about an african american woman named celie surviving poverty in the south during the 1930s . through aug . 26 . $ 69-$149 . ask a harry potter scholar at southeast neighborhood library : come to this talk from tolanda henderson , a librarian from george washington university , who has used the j.k . rowling book series as a text in academia . commune with other muggles who prove that it \\'s not just kids and young adults who obsess about the boy who lived . 7 p.m. free . wednesday , aug . 1 rico nasty at the fillmore silver spring : two summers ago , rico nasty was a teenage loudmouth from the maryland suburbs , generating buzz on youtube for spitting surly , rainbow - tinted rhymes . now , after signing a deal with atlantic records , the 21-year - old singer is on her way to becoming one of the brightest voices in rap music .\\n\\nGenerated response: \\nPerson 1: i recently met a girl who lives in that area , and she said the nightlife is worth visiting for . it sounds like many of the events feature jazz music . do you listen to jazz very often ?\\n\\nQuestions about the generated response:\\n1. Understandable (0 - 1): Is the response understandable given the previous context?\\n2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\\n3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\\n4. Interesting (1 - 3): Is the response dull or interesting?\\n5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-K8qD0yN2SqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}