{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTHRiW_GB2VR",
    "outputId": "88d62438-c924-4249-a58a-3710245b2103"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsantra/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from pytorch_lightning import seed_everything\n",
    "import pickle as pkl\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "# os.chdir(\"/content/drive/MyDrive/iitkgp-mtp-dialog-response-generation\")\n",
    "RANDOM_SEED = 50\n",
    "seed_everything(RANDOM_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "EEpo1Yk4V2-B",
    "outputId": "f9d325a7-8989-4114-b231-36112b540fbd"
   },
   "outputs": [],
   "source": [
    "with open(\"tc_all_prompts.pkl\", \"rb\") as f1:\n",
    "    tc_all_prompts = pkl.load(f1)\n",
    "\n",
    "with open(\"tc_all_labels.pkl\", \"rb\") as f1:\n",
    "    tc_all_labels = pkl.load(f1)\n",
    "\n",
    "with open(\"pc_all_prompts.pkl\", \"rb\") as f1:\n",
    "    pc_all_prompts = pkl.load(f1)\n",
    "\n",
    "with open(\"pc_all_labels.pkl\", \"rb\") as f1:\n",
    "    pc_all_labels = pkl.load(f1)\n",
    "\n",
    "pc_all_prompts_labelled = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled = [-1] * len(tc_all_prompts)\n",
    "pc_all_prompts_labelled_understandable = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled_understandable = [-1] * len(tc_all_prompts)\n",
    "pc_all_prompts_labelled_natural = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled_natural = [-1] * len(tc_all_prompts)\n",
    "pc_all_prompts_labelled_context = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled_context = [-1] * len(tc_all_prompts)\n",
    "pc_all_prompts_labelled_interesting = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled_interesting = [-1] * len(tc_all_prompts)\n",
    "pc_all_prompts_labelled_facts = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled_facts = [-1] * len(tc_all_prompts)\n",
    "pc_all_prompts_labelled_overall = [-1] * len(pc_all_prompts)\n",
    "tc_all_prompts_labelled_overall = [-1] * len(tc_all_prompts)\n",
    "\n",
    "int2word = {\n",
    "    \"understandable\": {0: \"no\", 1: \"yes\"},\n",
    "    \"natural\": {1: \"no\", 2: \"somewhat\", 3: \"yes\"},\n",
    "    \"context\": {1: \"no\", 2: \"somewhat\", 3: \"yes\"},\n",
    "    \"interesting\": {1: \"dull\", 2: \"somewhat interesting\", 3: \"interesting\"},\n",
    "    \"facts\": {0: \"no\", 1: \"yes\"},\n",
    "    \"overall\": {1: \"very bad\", 2: \"bad\", 3: \"neutral\", 4: \"good\", 5: \"very good\"}\n",
    "}\n",
    "change_int_to_word = True\n",
    "\n",
    "def replace_in_q(q):\n",
    "    q = q.replace(\"Interesting (1 - 3)\", \"Interesting (dull/somewhat interesting/interesting)\")\\\n",
    "        .replace(\"(1 - 3)\", \"(no/somewhat/yes)\")\\\n",
    "        .replace(\"(1 - 5)\", \"(very bad/bad/neutral/good/very good)\")\\\n",
    "        .replace(\"(0 - 1)\", \"(no/yes)\")\n",
    "    return q\n",
    "\n",
    "for i, each in enumerate(pc_all_prompts):\n",
    "    prompt_here = pc_all_prompts[i]\n",
    "    label_1 = round(np.mean(np.array(pc_all_labels[i][0])))\n",
    "    label_2 = round(np.mean(np.array(pc_all_labels[i][1])))\n",
    "    label_3 = round(np.mean(np.array(pc_all_labels[i][2])))\n",
    "    label_4 = round(np.mean(np.array(pc_all_labels[i][3])))\n",
    "    label_5 = round(np.mean(np.array(pc_all_labels[i][4])))\n",
    "    label_6 = round(np.mean(np.array(pc_all_labels[i][5])))\n",
    "    # all_prompts[i] = prefix + each + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Overall Quality: {str(label_5)}\"\n",
    "    # pc_all_prompts_labelled[i] = each.lstrip() + f\"\\n1. Understandable: {str(label_1)}\\n2. Natural: {str(label_2)}\\n3. Maintains Context: {str(label_3)}\\n4. Interesting: {str(label_4)}\\n5. Uses Knowledge: {str(label_5)}\\n6. Overall Quality: {str(label_6)}\"\n",
    "    before_questions = each.lstrip()[:each.find(\"\\n1.\")]\n",
    "    before_questions_nofacts = before_questions[:before_questions.find(\"Facts:\")] + before_questions[before_questions.find(\"Generated \"):]\n",
    "    if change_int_to_word:\n",
    "        pc_all_prompts_labelled[i] = replace_in_q(each.lstrip() + f\"\"\"\\n1. {str(int2word[\"understandable\"][label_1])}\\n2. {str(int2word[\"natural\"][label_2])}\\n3. {str(int2word[\"context\"][label_3])}\\n4. {str(int2word[\"interesting\"][label_4])}\\n5. {str(int2word[\"facts\"][label_5])}\\n6. {str(int2word[\"overall\"][label_6])}\"\"\")\n",
    "        pc_all_prompts_labelled_understandable[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n1.\"):each.find(\"\\n2.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"understandable\"][label_1])}\"\"\")\n",
    "        pc_all_prompts_labelled_natural[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n2.\"):each.find(\"\\n3.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"natural\"][label_2])}\"\"\")\n",
    "        pc_all_prompts_labelled_context[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n3.\"):each.find(\"\\n4.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"context\"][label_3])}\"\"\")\n",
    "        pc_all_prompts_labelled_interesting[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n4.\"):each.find(\"\\n5.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"interesting\"][label_4])}\"\"\")\n",
    "        pc_all_prompts_labelled_facts[i] = replace_in_q(before_questions + each.lstrip()[each.find(\"\\n5.\"):each.find(\"\\n6.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"facts\"][label_5])}\"\"\")\n",
    "        pc_all_prompts_labelled_overall[i] = replace_in_q(before_questions + each.lstrip()[each.find(\"\\n6.\"):each.find(\"\\n\\nAnswers\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"overall\"][label_6])}\"\"\")\n",
    "    else:\n",
    "        pc_all_prompts_labelled[i] = each.lstrip() + f\"\"\"\\n1. {str(label_1)}\\n2. {str(label_2)}\\n3. {str(label_3)}\\n4. {str(label_4)}\\n5. {str(label_5)}\\n6. {str(label_6)}\"\"\"\n",
    "        pc_all_prompts_labelled_understandable[i] = each.lstrip()[:each.find(\"\\n2.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_1)}\"\"\"\n",
    "        pc_all_prompts_labelled_natural[i] = before_questions_nofacts + each.lstrip()[each.find(\"\\n2.\"):each.find(\"\\n3.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_2)}\"\"\"\n",
    "        pc_all_prompts_labelled_context[i] = before_questions_nofacts + each.lstrip()[each.find(\"\\n3.\"):each.find(\"\\n4.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_3)}\"\"\"\n",
    "        pc_all_prompts_labelled_interesting[i] = before_questions_nofacts + each.lstrip()[each.find(\"\\n4.\"):each.find(\"\\n5.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_4)}\"\"\"\n",
    "        pc_all_prompts_labelled_facts[i] = before_questions + each.lstrip()[each.find(\"\\n5.\"):each.find(\"\\n6.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_5)}\"\"\"\n",
    "        pc_all_prompts_labelled_overall[i] = before_questions + each.lstrip()[each.find(\"\\n6.\"):each.find(\"\\n\\nAnswers\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_6)}\"\"\"\n",
    "\n",
    "for i, each in enumerate(tc_all_prompts):\n",
    "    prompt_here = tc_all_prompts[i]\n",
    "    label_1 = round(np.mean(np.array(tc_all_labels[i][0])))\n",
    "    label_2 = round(np.mean(np.array(tc_all_labels[i][1])))\n",
    "    label_3 = round(np.mean(np.array(tc_all_labels[i][2])))\n",
    "    label_4 = round(np.mean(np.array(tc_all_labels[i][3])))\n",
    "    label_5 = round(np.mean(np.array(tc_all_labels[i][4])))\n",
    "    label_6 = round(np.mean(np.array(tc_all_labels[i][5])))\n",
    "    before_questions = each.lstrip()[:each.find(\"\\n1.\")]\n",
    "    before_questions_nofacts = before_questions[:before_questions.find(\"Facts:\")] + before_questions[before_questions.find(\"Generated \"):]\n",
    "    if change_int_to_word:\n",
    "        tc_all_prompts_labelled[i] = replace_in_q(each.lstrip() + f\"\"\"\\n1. {str(int2word[\"understandable\"][label_1])}\\n2. {str(int2word[\"natural\"][label_2])}\\n3. {str(int2word[\"context\"][label_3])}\\n4. {str(int2word[\"interesting\"][label_4])}\\n5. {str(int2word[\"facts\"][label_5])}\\n6. {str(int2word[\"overall\"][label_6])}\"\"\")\n",
    "        tc_all_prompts_labelled_understandable[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n1.\"):each.find(\"\\n2.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"understandable\"][label_1])}\"\"\")\n",
    "        tc_all_prompts_labelled_natural[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n2.\"):each.find(\"\\n3.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"natural\"][label_2])}\"\"\")\n",
    "        tc_all_prompts_labelled_context[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n3.\"):each.find(\"\\n4.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"context\"][label_3])}\"\"\")\n",
    "        tc_all_prompts_labelled_interesting[i] = replace_in_q(before_questions_nofacts + each.lstrip()[each.find(\"\\n4.\"):each.find(\"\\n5.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"interesting\"][label_4])}\"\"\")\n",
    "        tc_all_prompts_labelled_facts[i] = replace_in_q(before_questions + each.lstrip()[each.find(\"\\n5.\"):each.find(\"\\n6.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"facts\"][label_5])}\"\"\")\n",
    "        tc_all_prompts_labelled_overall[i] = replace_in_q(before_questions + each.lstrip()[each.find(\"\\n6.\"):each.find(\"\\n\\nAnswers\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(int2word[\"overall\"][label_6])}\"\"\")\n",
    "    else:\n",
    "        tc_all_prompts_labelled[i] = each.lstrip() + f\"\"\"\\n1. {str(label_1)}\\n2. {str(label_2)}\\n3. {str(label_3)}\\n4. {str(label_4)}\\n5. {str(label_5)}\\n6. {str(label_6)}\"\"\"\n",
    "        tc_all_prompts_labelled_understandable[i] = each.lstrip()[:each.find(\"\\n2.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_1)}\"\"\"\n",
    "        tc_all_prompts_labelled_natural[i] = before_questions_nofacts + each.lstrip()[each.find(\"\\n2.\"):each.find(\"\\n3.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_2)}\"\"\"\n",
    "        tc_all_prompts_labelled_context[i] = before_questions_nofacts + each.lstrip()[each.find(\"\\n3.\"):each.find(\"\\n4.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_3)}\"\"\"\n",
    "        tc_all_prompts_labelled_interesting[i] = before_questions_nofacts + each.lstrip()[each.find(\"\\n4.\"):each.find(\"\\n5.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_4)}\"\"\"\n",
    "        tc_all_prompts_labelled_facts[i] = before_questions + each.lstrip()[each.find(\"\\n5.\"):each.find(\"\\n6.\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_5)}\"\"\"\n",
    "        tc_all_prompts_labelled_overall[i] = before_questions + each.lstrip()[each.find(\"\\n6.\"):each.find(\"\\n\\nAnswers\")][:-3] + f\"\"\"\\n\\nAnswers: \\n1. {str(label_6)}\"\"\"\n",
    "\n",
    "remove_question_number = True\n",
    "# if remove_question_number:\n",
    "for i, each in enumerate(pc_all_prompts_labelled_overall):\n",
    "    pc_all_prompts_labelled_overall[i] = each.replace(\"Given your answers above, w\", \"W\")\n",
    "for i, each in enumerate(tc_all_prompts_labelled_overall):\n",
    "    tc_all_prompts_labelled_overall[i] = each.replace(\"Given your answers above, w\", \"W\")\n",
    "\n",
    "for i, each in enumerate(pc_all_prompts_labelled_facts):\n",
    "    pc_all_prompts_labelled_facts[i] = each.replace(\"response is conditioned\", \"response is supposed to be conditioned\")\n",
    "    pc_all_prompts_labelled_facts[i] = each.replace(\"how well does the\", \"does the\")\n",
    "for i, each in enumerate(tc_all_prompts_labelled_facts):\n",
    "    tc_all_prompts_labelled_facts[i] = each.replace(\"response is conditioned\", \"response is supposed to be conditioned\")\n",
    "    tc_all_prompts_labelled_facts[i] = each.replace(\"how well does the\", \"does the\")\n",
    "        \n",
    "# for i, each in enumerate(pc_all_prompts):\n",
    "#     pc_all_prompts_understandable[i] = each[:each.find(\"Facts\")] + each[each.find(\"Generated response:\"):]\n",
    "# for i, each in enumerate(tc_all_prompts):\n",
    "#     tc_all_prompts_understandable[i] = each[:each.find(\"Facts\")] + each[each.find(\"Generated response:\"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Facts:\n",
      "Person 1's statement: i also have a dog walking business.\n",
      "Person 1's statement: i've three dogs.\n",
      "Person 1's statement: my father was a door to door salesman.\n",
      "Person 1's statement: i am in an open polyamorous relationship.\n",
      "Person 1's statement: i like to watch the olympics.\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Understandable (no/yes): Is the response understandable given the previous context?\n",
      "2. Natural (no/somewhat/yes): Does the response seem like something that a person would naturally say?\n",
      "3. Maintains Context (no/somewhat/yes): Does the response serve as a valid continuation of the preceding conversation?\n",
      "4. Interesting (dull/somewhat interesting/interesting): Is the response dull or interesting?\n",
      "5. Uses Knowledge (no/yes): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
      "6. Overall Quality (very bad/bad/neutral/good/very good): Given your answers above, what is your overall impression of the quality of the generated response?\n",
      "\n",
      "Answers:\n",
      "1. yes\n",
      "2. yes\n",
      "3. yes\n",
      "4. dull\n",
      "5. no\n",
      "6. good\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixoBYhGR3Yz_",
    "outputId": "b3c96ce3-dc14-4abe-b992-a1ab5ea51aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Understandable (no/yes): Is the response understandable given the previous context?\n",
      "\n",
      "Answers: \n",
      "1. yes\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled_understandable[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QT6RBUBj-Hyw",
    "outputId": "1f071cda-ea43-4186-a711-8444b514be9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Natural (no/somewhat/yes): Does the response seem like something that a person would naturally say?\n",
      "\n",
      "Answers: \n",
      "1. yes\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled_natural[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Maintains Context (no/somewhat/yes): Does the response serve as a valid continuation of the preceding conversation?\n",
      "\n",
      "Answers: \n",
      "1. yes\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled_context[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Interesting (dull/somewhat interesting/interesting): Is the response dull or interesting?\n",
      "\n",
      "Answers: \n",
      "1. dull\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled_interesting[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Facts:\n",
      "Person 1's statement: i also have a dog walking business.\n",
      "Person 1's statement: i've three dogs.\n",
      "Person 1's statement: my father was a door to door salesman.\n",
      "Person 1's statement: i am in an open polyamorous relationship.\n",
      "Person 1's statement: i like to watch the olympics.\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Uses Knowledge (no/yes): Given the facts that the response is conditioned on, does the response use the facts?\n",
      "\n",
      "Answers: \n",
      "1. no\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled_facts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1: lead singer for a band , music teacher\n",
      "Person 2: wow nice are you really good ?\n",
      "Person 1: millions of plays on soundcloud\n",
      "Person 2: really would you share or are you shy\n",
      "\n",
      "Facts:\n",
      "Person 1's statement: i also have a dog walking business.\n",
      "Person 1's statement: i've three dogs.\n",
      "Person 1's statement: my father was a door to door salesman.\n",
      "Person 1's statement: i am in an open polyamorous relationship.\n",
      "Person 1's statement: i like to watch the olympics.\n",
      "\n",
      "Generated response: \n",
      "Person 1: ha ha i'm so shy\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Overall Quality (very bad/bad/neutral/good/very good): What is your overall impression of the quality of the generated response?\n",
      "\n",
      "Answers: \n",
      "1. good\n"
     ]
    }
   ],
   "source": [
    "print(pc_all_prompts_labelled_overall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "skcyesH4ZwRo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM, GPTNeoModel, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, random_split, Subset\n",
    "import random\n",
    "from torch import cuda\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "b414398958934630a1f07430acdeafa9",
      "59fd10d3d2644ee0bece610f0d1d7d7d",
      "7c3843bf14b84b098a001d3a3a162472",
      "9d7f86b822864828a769e2948725d33e",
      "5160ca7fca294cb2808cf79c3b1c1ac7",
      "01ddd9f605a64c1ba2d7a7eb415a630e",
      "33c7841c474444f68db828cff78c4151",
      "7f3ae46c89c44a7d9b35d21f7fe61db4",
      "9e33ac1b3c9844dd9e22c8d593bccd3f",
      "9f6c37d44c0e4501b672185bafd91ce5",
      "179d08c447cd484ba2bba7998ce77b7e",
      "564bf6e7a4dd45f98574bd7b5711fbfa",
      "4dac7b069cd341a592a85c58195e799b",
      "14b1ace190e94d9882ad752e5840983c",
      "1ef32dbc999e45e8b3b0d3c325aad241",
      "dad7aab67309470ea012e445557293bc",
      "2e6dd9a9379144119e079c4fc7d9ee64",
      "7497fef7647e44cda15d6a1ee7162cff",
      "9475c60459ba417eae3f27b2f514df41",
      "390591739f4a45479de9854efcce4b84",
      "97ba8889cc704a169a0cc5c38bab163e",
      "45f92ddf47f942d19917dd7dead25f38",
      "e0e2e8fe2ca2456d9aeb0d3d153d1a4b",
      "ddd8acb558a54845a2c7d52107017ac4",
      "b63e314272dd46e1bd0d4af5e43bdda5",
      "6f3cd3eaf9184faea6a7da918ce5ad19",
      "a039e29c0e3f46e989509a5749f0dd3e",
      "d7720c56e12a47458676ff74ba9e57d4",
      "8ff5d8e3fb2a4056ad4a829ffd856e90",
      "8b04d790167b486d98b4a29cf86799e8",
      "bac90dabd8d04784b8865292c6eee401",
      "3f4a92d3d1554ba4a6fdfb9a440585b2",
      "d59c75d2075347c1a877def8d3623dd5",
      "55b2cd074d114c9fa16b8e2d983a6011",
      "333b1bcae55d4f1299dcf58442e6ab28",
      "5866b713c4694746abe5bd203189f1dd",
      "307d499b9fb04f9eac6966f5d9875b4a",
      "2636c624a2c3432092c2ccfcaf0603e6",
      "f2cbb330da034a47b32fa4dac818fd9c",
      "1b1373fb25f3422bba527684d6481c45",
      "74528482b74d4360a81ea060a3a12583",
      "7bb31ebaf23a4d8586073a2de456df2a",
      "84ee9778c41a4c81b5d802d9e3f692a4",
      "244f2ce637ce4c9e992ef7fbdae29b2c"
     ]
    },
    "id": "oc72dGqRZwRp",
    "outputId": "cf4b0fe4-204b-4afe-8aca-0e2cc37e6e6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_checkpoint = \"gpt2-medium\"\n",
    "model_checkpoint = \"gpt2-large\"\n",
    "# model_checkpoint = \"bigscience/bloom-560m\"\n",
    "# model_checkpoint = \"bigscience/bloom-1b1\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint,\n",
    "                            bos_token=\"<|startoftext|>\",\n",
    "                            eos_token=\"<|endoftext|>\",\n",
    "                            pad_token=\"<|pad|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "3c47249c03a74b2d90fa37e03f202c49",
      "14eae0a060b3450dab363d8522c835da",
      "6b0c15beeb424103805d5c077bfa790e",
      "1049bc8923e4419a8ee59d1d455599af",
      "9082f05fd0094172bd827454471c98f6",
      "f16de126b68547ff8b0e9ee412375369",
      "a6caeb338c8b4d66b5ec2eb013649a93",
      "b2bf7d0d2f85489c8e8727896ed6eb35",
      "e097880aab944e5286abd4087b9a7581",
      "ea382ab4622f495094a40e02eed3e4ae",
      "b290356d9fe84264af97be2da3dc1b08"
     ]
    },
    "id": "Yr3ZG4kIZwRp",
    "outputId": "fc0d5243-df52-474d-c3a1-a4ec15a7a5f5"
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_checkpoint).to(device)\n",
    "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
    "# Resize the token embeddings because we've just added 3 new tokens \n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "1800\n",
      "453\n",
      "2112\n"
     ]
    }
   ],
   "source": [
    "tc_lines = []\n",
    "for a, b, c, d, e, f in zip(tc_all_prompts_labelled_understandable, tc_all_prompts_labelled_natural, tc_all_prompts_labelled_context, tc_all_prompts_labelled_interesting, tc_all_prompts_labelled_facts, tc_all_prompts_labelled_overall):\n",
    "    tc_lines.append(a)\n",
    "    tc_lines.append(b)\n",
    "    tc_lines.append(c)\n",
    "    tc_lines.append(d)\n",
    "    tc_lines.append(e)\n",
    "    tc_lines.append(f)\n",
    "\n",
    "pc_lines = []\n",
    "for a, b, c, d, e, f in zip(pc_all_prompts_labelled_understandable, pc_all_prompts_labelled_natural, pc_all_prompts_labelled_context, pc_all_prompts_labelled_interesting, pc_all_prompts_labelled_facts, pc_all_prompts_labelled_overall):\n",
    "    pc_lines.append(a)\n",
    "    pc_lines.append(b)\n",
    "    pc_lines.append(c)\n",
    "    pc_lines.append(d)\n",
    "    pc_lines.append(e)\n",
    "    pc_lines.append(f)\n",
    "\n",
    "max_length = 512\n",
    "tc_descriptions = [description for description in tc_lines if len(tokenizer.encode(description)) < max_length-2]\n",
    "pc_descriptions = [description for description in pc_lines if len(tokenizer.encode(description)) < max_length-2]\n",
    "pc_max_length = max([len(tokenizer.encode(description)) for description in pc_descriptions])\n",
    "tc_max_length = max([len(tokenizer.encode(description)) for description in tc_descriptions])\n",
    "print(pc_max_length)\n",
    "print(len(pc_descriptions))\n",
    "print(tc_max_length)\n",
    "print(len(tc_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yUJVak-5ZwRq"
   },
   "outputs": [],
   "source": [
    "class PromptsDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in txt_list:\n",
    "            # Encode the descriptions using the GPT-Neo tokenizer\n",
    "            encodings_dict = tokenizer(\"<|startoftext|>\" \n",
    "                                        + txt +    \n",
    "                                        \"<|endoftext|>\",\n",
    "                                        truncation=True,\n",
    "                                        max_length=max_length, \n",
    "                                        padding='max_length')\n",
    "            input_ids = torch.tensor(encodings_dict['input_ids'])    \n",
    "            self.input_ids.append(input_ids)\n",
    "            mask = torch.tensor(encodings_dict['attention_mask'])\n",
    "            self.attn_masks.append(mask)\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "\n",
    "tc_dataset = PromptsDataset(tc_descriptions, tokenizer, max_length) \n",
    "pc_dataset = PromptsDataset(pc_descriptions, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tc_train_size = int(0.7 * len(tc_dataset))\n",
    "# pc_train_size = int(0.7 * len(pc_dataset))\n",
    "\n",
    "tc_train_size = 1512\n",
    "pc_train_size = 1260\n",
    "\n",
    "tc_val_size = 288\n",
    "pc_val_size = 270\n",
    "\n",
    "tc_test_size = 312 \n",
    "pc_test_size = 270 \n",
    "\n",
    "tc_train_dataset = Subset(tc_dataset, range(tc_train_size))\n",
    "pc_train_dataset = Subset(pc_dataset, range(pc_train_size))\n",
    "\n",
    "tc_val_dataset = Subset(tc_dataset, range(tc_train_size, tc_train_size + tc_val_size))\n",
    "pc_val_dataset = Subset(pc_dataset, range(pc_train_size, pc_train_size + pc_val_size))\n",
    "\n",
    "tc_test_dataset = Subset(tc_dataset, range(tc_train_size + tc_val_size, tc_train_size + tc_val_size + tc_test_size))\n",
    "pc_test_dataset = Subset(pc_dataset, range(pc_train_size + pc_val_size, pc_train_size + pc_val_size + pc_test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2word = {\n",
    "    \"understandable\": {0: \"no\", 1: \"yes\"},\n",
    "    \"natural\": {1: \"no\", 2: \"somewhat\", 3: \"yes\"},\n",
    "    \"context\": {1: \"no\", 2: \"somewhat\", 3: \"yes\"},\n",
    "    \"interesting\": {1: \"dull\", 2: \"somewhat interesting\", 3: \"interesting\"},\n",
    "    \"facts\": {0: \"no\", 1: \"yes\"},\n",
    "    \"overall\": {1: \"very bad\", 2: \"bad\", 3: \"neutral\", 4: \"good\", 5: \"very good\"}\n",
    "}\n",
    "\n",
    "label2int = {\n",
    "    \"understandable\": {\"no\": 0, \"yes\": 1},\n",
    "    \"natural\" : {\"no\": 1, \"somewhat\": 2, \"yes\": 3},\n",
    "    \"context\": {\"no\": 1, \"somewhat\": 2, \"yes\": 3},\n",
    "    \"interesting\": {\"dull\": 1, \"somewhat interesting\": 2, \"interesting\": 3},\n",
    "    \"facts\": {\"no\": 0, \"yes\": 1},\n",
    "    \"overall\": {\"very bad\": 1, \"bad\": 2, \"neutral\": 3, \"good\": 4, \"very good\": 5},\n",
    "}\n",
    "\n",
    "tc_pc_concat_testdataset = torch.utils.data.ConcatDataset([tc_test_dataset, pc_test_dataset])\n",
    "test_lines = []\n",
    "test_labels = []\n",
    "for i, each in enumerate(tc_pc_concat_testdataset):\n",
    "    datapoint = tokenizer.decode(tc_pc_concat_testdataset[i][0], skip_special_tokens=True)\n",
    "    unlabelled_here = \".\".join(datapoint.split(\".\")[:-1]) + \". \"\n",
    "    test_lines.append(unlabelled_here)\n",
    "    if \"Is the response dull or interesting\" in unlabelled_here:\n",
    "        label_int = label2int[\"interesting\"][datapoint.replace(unlabelled_here, \"\")]\n",
    "    elif \"overall impression of the quality\" in unlabelled_here:\n",
    "        label_int = label2int[\"overall\"][datapoint.replace(unlabelled_here, \"\")]\n",
    "    elif \"facts that the response is conditioned\" in unlabelled_here:\n",
    "        label_int = label2int[\"facts\"][datapoint.replace(unlabelled_here, \"\")]\n",
    "    elif \"understandable given the previous context\" in unlabelled_here:\n",
    "        label_int = label2int[\"understandable\"][datapoint.replace(unlabelled_here, \"\")]\n",
    "    elif \"valid continuation of the preceding conversation\" in unlabelled_here:\n",
    "        label_int = label2int[\"context\"][datapoint.replace(unlabelled_here, \"\")]\n",
    "    elif \"something that a person would naturally say\" in unlabelled_here:\n",
    "        label_int = label2int[\"natural\"][datapoint.replace(unlabelled_here, \"\")]\n",
    "    test_labels.append(label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UHhqY0_jW_Fl"
   },
   "outputs": [],
   "source": [
    "tc_pc_concat_traindataset = torch.utils.data.ConcatDataset([tc_train_dataset, pc_train_dataset])\n",
    "tc_pc_concat_valdataset = torch.utils.data.ConcatDataset([tc_val_dataset, tc_val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lMe7W26tZwRr"
   },
   "outputs": [],
   "source": [
    "lr=2e-5\n",
    "bs=10\n",
    "ne=10\n",
    "training_args = TrainingArguments(output_dir=f'gpt2large-epoch10-singlequestions-try2-pctc-lr{lr}-bs{bs}-ne{ne}',\n",
    "                                  overwrite_output_dir=False,\n",
    "                                  num_train_epochs=ne,\n",
    "                                  learning_rate=lr,\n",
    "                                  save_strategy='epoch',\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_strategy=\"epoch\",\n",
    "                                  logging_first_step=True,\n",
    "                                #   logging_steps=200,\n",
    "                                #   save_steps =1000,\n",
    "#                                   per_device_train_batch_size=1,\n",
    "                                  auto_find_batch_size=True,\n",
    "                                  gradient_accumulation_steps=bs,\n",
    "                                #   warmup_steps=500,\n",
    "                                  weight_decay=0.01,  \n",
    "                                  load_best_model_at_end=True,\n",
    "                                  fp16=False,\n",
    "                                  )\n",
    "                                #   logging_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hy2VO_zPZwRr",
    "outputId": "5b39fb0d-3f13-4644-fa70-a20fc86c54b1"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args,  \n",
    "                  train_dataset=tc_pc_concat_traindataset,\n",
    "                  eval_dataset=tc_pc_concat_valdataset, \n",
    "                  # This custom collate function is necessary \n",
    "                  # to built batches of data\n",
    "                  data_collator=lambda data: \n",
    "              {'input_ids': torch.stack([f[0] for f in data]),       \n",
    "               'attention_mask': torch.stack([f[1] for f in data]),\n",
    "               'labels': torch.stack([f[0] for f in data])}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsantra/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/accelerate/memory_utils.py:23: FutureWarning: memory_utils has been reorganized to utils.memory. Import `find_executable_batchsize` from the main `__init__`: `from accelerate import find_executable_batch_size` to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/bsantra/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2772\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 80\n",
      "  Gradient Accumulation steps = 10\n",
      "  Total optimization steps = 340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/340 : < :, Epoch 0.03/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2772\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 80\n",
      "  Gradient Accumulation steps = 10\n",
      "  Total optimization steps = 690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/690 00:16 < 1:35:51, 0.12 it/s, Epoch 0.04/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training process!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### EVAL #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file gpt2large-singlequestions-pctc-lr1e-05-bs10-ne3/checkpoint-819/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2-large\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1280,\n",
      "  \"n_head\": 20,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 36,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50258,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading weights file gpt2large-singlequestions-pctc-lr1e-05-bs10-ne3/checkpoint-819/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2large-singlequestions-pctc-lr1e-05-bs10-ne3/checkpoint-819/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = f'gpt2large-singlequestions-pctc-lr1e-05-bs10-ne3/checkpoint-819/'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
    "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
    "# Resize the token embeddings because we've just added 3 new tokens \n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([tokenizer(test_lines[0]).input_ids]).to(device)\n",
    "print(input_ids)\n",
    "print(tokenizer.decode(input_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n"
     ]
    }
   ],
   "source": [
    "predicted_q1 = []\n",
    "predicted_q2 = []\n",
    "predicted_q3 = []\n",
    "predicted_q4 = []\n",
    "predicted_q5 = []\n",
    "predicted_q6 = []\n",
    "labels_q1 = []\n",
    "labels_q2 = []\n",
    "labels_q3 = []\n",
    "labels_q4 = []\n",
    "labels_q5 = []\n",
    "labels_q6 = []\n",
    "# test_labels\n",
    "\n",
    "label2int = {\n",
    "    \"understandable\": {\"no\": 0, \"yes\": 1},\n",
    "    \"natural\" : {\"no\": 1, \"somewhat\": 2, \"yes\": 3},\n",
    "    \"context\": {\"no\": 1, \"somewhat\": 2, \"yes\": 3},\n",
    "    \"interesting\": {\"dull\": 1, \"somewhat interesting\": 2, \"interesting\": 3},\n",
    "    \"facts\": {\"no\": 0, \"yes\": 1},\n",
    "    \"overall\": {\"very bad\": 1, \"bad\": 2, \"neutral\": 3, \"good\": 4, \"very good\": 5},\n",
    "}\n",
    "for i, each in enumerate(test_lines):\n",
    "    print(i)\n",
    "    tokenized = tokenizer(each)\n",
    "    input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
    "    unlabelled_here = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "    if len(input_ids[0]) < 1000:\n",
    "        generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
    "        ## do_sample=False enables greedy decoding\n",
    "        predicted_label = tokenizer.batch_decode(generation, skip_special_tokens=True)[0].replace(each, \"\").lstrip().rstrip()\n",
    "        if \"understandable given the previous context\" in unlabelled_here:\n",
    "            label_int = label2int[\"understandable\"][predicted_label]\n",
    "            predicted_q1.append(label_int)\n",
    "            labels_q1.append(test_labels[i])\n",
    "        elif \"something that a person would naturally say\" in unlabelled_here:\n",
    "            label_int = label2int[\"natural\"][predicted_label]\n",
    "            predicted_q2.append(label_int)\n",
    "            labels_q2.append(test_labels[i])\n",
    "        elif \"valid continuation of the preceding conversation\" in unlabelled_here:\n",
    "            label_int = label2int[\"context\"][predicted_label]\n",
    "            predicted_q3.append(label_int)\n",
    "            labels_q3.append(test_labels[i])\n",
    "        elif \"Is the response dull or interesting\" in unlabelled_here:\n",
    "            label_int = label2int[\"interesting\"][predicted_label]\n",
    "            predicted_q4.append(label_int)\n",
    "            labels_q4.append(test_labels[i])\n",
    "        elif \"facts that the response is conditioned\" in unlabelled_here:\n",
    "            label_int = label2int[\"facts\"][predicted_label]\n",
    "            predicted_q5.append(label_int)\n",
    "            labels_q5.append(test_labels[i])\n",
    "        elif \"overall impression of the quality\" in unlabelled_here:\n",
    "            label_int = label2int[\"overall\"][predicted_label]\n",
    "            predicted_q6.append(label_int)\n",
    "            labels_q6.append(test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "83\n",
      "91\n",
      "112\n",
      "101\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_q1))\n",
    "print(len(predicted_q2))\n",
    "print(len(predicted_q3))\n",
    "print(len(predicted_q4))\n",
    "print(len(predicted_q5))\n",
    "print(len(predicted_q6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2738\n"
     ]
    }
   ],
   "source": [
    "print(len(tc_pc_concat_traindataset))\n",
    "print(len(tc_pc_concat_traindataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "no\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "bad\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "no\n",
      "good\n",
      "interesting\n",
      "neutral\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "neutral\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "no\n",
      "somewhat\n",
      "bad\n",
      "somewhat\n",
      "bad\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "bad\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "good\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "no\n",
      "good\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "dull\n",
      "yes\n",
      "bad\n",
      "bad\n",
      "no\n",
      "bad\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "dull\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "bad\n",
      "somewhat\n",
      "good\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "good\n",
      "no\n",
      "good\n",
      "yes\n",
      "dull\n",
      "good\n",
      "neutral\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "neutral\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "good\n",
      "no\n",
      "no\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "neutral\n",
      "dull\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "bad\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "neutral\n",
      "no\n",
      "neutral\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "good\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "bad\n",
      "somewhat\n",
      "interesting\n",
      "bad\n",
      "neutral\n",
      "interesting\n",
      "good\n",
      "good\n",
      "dull\n",
      "dull\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "dull\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "no\n",
      "bad\n",
      "somewhat\n",
      "dull\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "no\n",
      "dull\n",
      "somewhat\n",
      "good\n",
      "good\n",
      "somewhat\n",
      "bad\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "bad\n",
      "no\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "good\n",
      "interesting\n",
      "bad\n",
      "interesting\n",
      "bad\n",
      "bad\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "no\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "somewhat\n",
      "bad\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "no\n",
      "no\n",
      "good\n",
      "somewhat\n",
      "somewhat\n",
      "good\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "bad\n",
      "interesting\n",
      "somewhat\n",
      "bad\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "bad\n",
      "good\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "no\n",
      "interesting\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "dull\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "dull\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "no\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "no\n",
      "good\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "no\n",
      "good\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "bad\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "yes\n",
      "neutral\n",
      "somewhat\n",
      "neutral\n",
      "interesting\n",
      "no\n",
      "somewhat\n",
      "bad\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "bad\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "neutral\n",
      "neutral\n",
      "no\n",
      "no\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "bad\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "interesting\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "bad\n",
      "yes\n",
      "bad\n",
      "bad\n",
      "no\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "somewhat\n",
      "yes\n",
      "good\n",
      "somewhat\n",
      "dull\n",
      "interesting\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "good\n",
      "no\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "somewhat\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "dull\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "dull\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "no\n",
      "no\n",
      "somewhat\n",
      "dull\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "no\n",
      "good\n",
      "good\n",
      "no\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "bad\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "no\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "no\n",
      "interesting\n",
      "somewhat\n",
      "neutral\n",
      "yes\n",
      "neutral\n",
      "no\n",
      "no\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "good\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "bad\n",
      "no\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "bad\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "no\n",
      "dull\n",
      "dull\n",
      "no\n",
      "no\n",
      "yes\n",
      "dull\n",
      "no\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "dull\n",
      "somewhat\n",
      "yes\n",
      "bad\n",
      "dull\n",
      "yes\n",
      "no\n",
      "bad\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "no\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "bad\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "good\n",
      "dull\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "neutral\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "no\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "good\n",
      "no\n",
      "good\n",
      "no\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "dull\n",
      "somewhat\n",
      "good\n",
      "bad\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "no\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "no\n",
      "dull\n",
      "dull\n",
      "interesting\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "bad\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "no\n",
      "somewhat\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "bad\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "somewhat\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "yes\n",
      "dull\n",
      "dull\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "neutral\n",
      "bad\n",
      "dull\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "somewhat\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "no\n",
      "good\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "bad\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "yes\n",
      "no\n",
      "yes\n",
      "neutral\n",
      "somewhat\n",
      "no\n",
      "no\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "good\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "good\n",
      "yes\n",
      "bad\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "dull\n",
      "good\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "good\n",
      "interesting\n",
      "good\n",
      "no\n",
      "good\n",
      "interesting\n",
      "interesting\n",
      "neutral\n",
      "no\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "dull\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "dull\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "dull\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "dull\n",
      "good\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "good\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "dull\n",
      "interesting\n",
      "no\n",
      "good\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "bad\n",
      "dull\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "good\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "bad\n",
      "neutral\n",
      "bad\n",
      "yes\n",
      "no\n",
      "no\n",
      "interesting\n",
      "somewhat\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "dull\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "dull\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "dull\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "dull\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "good\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "bad\n",
      "yes\n",
      "dull\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "dull\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "dull\n",
      "somewhat\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "good\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "no\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "dull\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "bad\n",
      "interesting\n",
      "bad\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "somewhat\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "good\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "good\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "good\n",
      "good\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "good\n",
      "yes\n",
      "dull\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "good\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "good\n",
      "interesting\n",
      "good\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "good\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "good\n",
      "good\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "no\n",
      "no\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "good\n",
      "no\n",
      "good\n",
      "interesting\n",
      "interesting\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "neutral\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "good\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "dull\n",
      "interesting\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "dull\n",
      "dull\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "bad\n",
      "yes\n",
      "somewhat\n",
      "neutral\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "neutral\n",
      "interesting\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "bad\n",
      "no\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "good\n",
      "somewhat\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "yes\n",
      "good\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "good\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "bad\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "no\n",
      "good\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "yes\n",
      "bad\n",
      "good\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "interesting\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "good\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "good\n",
      "good\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "good\n",
      "neutral\n",
      "yes\n",
      "dull\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "dull\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "neutral\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "dull\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "neutral\n",
      "neutral\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "good\n",
      "yes\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "neutral\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "no\n",
      "good\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "bad\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "interesting\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "no\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "bad\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "yes\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "dull\n",
      "interesting\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "no\n",
      "dull\n",
      "yes\n",
      "good\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "good\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "yes\n",
      "neutral\n",
      "good\n",
      "no\n",
      "interesting\n",
      "no\n",
      "good\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "interesting\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "somewhat\n",
      "somewhat\n",
      "good\n",
      "no\n",
      "no\n",
      "good\n",
      "yes\n",
      "bad\n",
      "good\n",
      "no\n",
      "good\n",
      "good\n",
      "yes\n",
      "good\n",
      "yes\n",
      "yes\n",
      "neutral\n",
      "interesting\n",
      "somewhat\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "somewhat\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "good\n",
      "no\n",
      "good\n",
      "interesting\n",
      "yes\n",
      "good\n",
      "no\n",
      "yes\n",
      "interesting\n",
      "neutral\n",
      "no\n",
      "somewhat\n",
      "yes\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "somewhat\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "interesting\n",
      "somewhat\n",
      "interesting\n",
      "good\n",
      "good\n",
      "yes\n",
      "good\n",
      "somewhat\n",
      "interesting\n",
      "yes\n",
      "yes\n",
      "interesting\n",
      "somewhat\n",
      "good\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tc_pc_concat_traindataset)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtc_pc_concat_traindataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3432\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3430\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/tokenization_utils.py:931\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode\u001b[39m(\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    923\u001b[0m     token_ids: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    928\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_use_source_tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_source_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 931\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_ids_to_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;66;03m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;66;03m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;66;03m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     sub_texts \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/tokenization_utils.py:907\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m    906\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index)\n\u001b[0;32m--> 907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_special_tokens \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_ids\u001b[49m:\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_decoder:\n",
      "File \u001b[0;32m~/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1274\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_ids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_special_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;124;03m    `List[int]`: List the ids of the special tokens(`'<unk>'`, `'<cls>'`, etc.) mapped to class attributes.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1274\u001b[0m     all_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m\n\u001b[1;32m   1275\u001b[0m     all_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(all_toks)\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_ids\n",
      "File \u001b[0;32m~/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1250\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_special_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    `List[str]`: All the special tokens (`'<unk>'`, `'<cls>'`, etc.) mapped to class attributes.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03m    Convert tokens of `tokenizers.AddedToken` type to string.\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1250\u001b[0m     all_toks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens_extended\u001b[49m]\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_toks\n",
      "File \u001b[0;32m~/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1266\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_tokens_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_value \u001b[38;5;129;01min\u001b[39;00m set_attr\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1265\u001b[0m     all_toks \u001b[38;5;241m=\u001b[39m all_toks \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mlist\u001b[39m(attr_value) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr_value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m [attr_value])\n\u001b[0;32m-> 1266\u001b[0m all_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mOrderedDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_toks\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_toks\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "overall_labels = \n",
    "for i in range(len(tc_pc_concat_traindataset)):\n",
    "    label_here = tokenizer.decode(tc_pc_concat_traindataset[i][0], skip_special_tokens=True).split()[-1]\n",
    "    if label_here in overall_labels:\n",
    "        print(label_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[3, 3, 2, 3, 1, 2, 2, 1, 3, 3, 3, 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 1, 3, 2, 2, 2, 2, 3, 2, 2, 3, 1, 3, 3, 3, 2, 2, 3, 3, 1, 3, 1, 2, 2, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 2, 3, 3, 3, 3, 2, 3, 2, 3, 3] \n",
      "\n",
      "[3, 2, 1, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 2, 2, 1, 3, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 1, 3, 1, 3, 1, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[2, 3, 3, 2, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 1, 2, 2, 2, 1, 3, 2, 3, 1, 3, 3, 2, 3, 2, 2, 3, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 1, 2, 3, 3, 2, 1, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 2, 3, 3, 3, 1, 3, 3, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 3, 1, 3, 3, 3, 2] \n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1] \n",
      "\n",
      "[2, 5, 2, 3, 2, 5, 2, 4, 1, 5, 1, 4, 1, 2, 5, 3, 2, 2, 2, 5, 4, 4, 3, 2, 3, 5, 3, 3, 1, 2, 5, 2, 3, 1, 1, 5, 3, 3, 4, 3, 4, 5, 2, 2, 5, 1, 5, 4, 1, 1, 4, 4, 2, 3, 4, 3, 4, 4, 5, 4, 3, 3, 5, 2, 4, 3, 4, 5, 5, 3, 4, 4, 3, 3, 2, 5, 3, 3, 5, 5, 3, 1, 3, 4, 4, 4, 5, 5, 4, 5, 5, 3, 5, 5, 3, 2, 4, 5, 4, 4, 2, 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(labels_q1, \"\\n\")\n",
    "print(labels_q2, \"\\n\")\n",
    "print(labels_q3, \"\\n\")\n",
    "print(labels_q4, \"\\n\")\n",
    "print(labels_q5, \"\\n\")\n",
    "print(labels_q6, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2] \n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## epoch 4\n",
    "print(predicted_q1, \"\\n\")\n",
    "print(predicted_q2, \"\\n\")\n",
    "print(predicted_q3, \"\\n\")\n",
    "print(predicted_q4, \"\\n\")\n",
    "print(predicted_q5, \"\\n\")\n",
    "print(predicted_q6, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[3, 2, 3, 3, 3, 3, 2, 1, 3, 2, 1, 1, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 1, 3, 2, 3, 3, 3, 2, 2, 3, 1, 2, 1, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[3, 1, 3, 1, 2, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2] \n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1] \n",
      "\n",
      "[4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 5, 4, 5, 5, 5, 4, 4, 5, 4, 5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## epochs=10, lr=2e-5, bs=10\n",
    "print(predicted_q1, \"\\n\")\n",
    "print(predicted_q2, \"\\n\")\n",
    "print(predicted_q3, \"\\n\")\n",
    "print(predicted_q4, \"\\n\")\n",
    "print(predicted_q5, \"\\n\")\n",
    "print(predicted_q6, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 2, 1, 1, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] \n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0] \n",
      "\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## epoch 3\n",
    "print(predicted_q1, \"\\n\")\n",
    "print(predicted_q2, \"\\n\")\n",
    "print(predicted_q3, \"\\n\")\n",
    "print(predicted_q4, \"\\n\")\n",
    "print(predicted_q5, \"\\n\")\n",
    "print(predicted_q6, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 1, 3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 1, 3, 2, 3, 3, 2, 1, 2, 3, 2, 2, 1, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[3, 1, 1, 3, 1, 3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] \n",
      "\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## epoch 2\n",
    "print(predicted_q1, \"\\n\")\n",
    "print(predicted_q2, \"\\n\")\n",
    "print(predicted_q3, \"\\n\")\n",
    "print(predicted_q4, \"\\n\")\n",
    "print(predicted_q5, \"\\n\")\n",
    "print(predicted_q6, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2] \n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## epoch 1\n",
    "print(predicted_q1, \"\\n\")\n",
    "print(predicted_q2, \"\\n\")\n",
    "print(predicted_q3, \"\\n\")\n",
    "print(predicted_q4, \"\\n\")\n",
    "print(predicted_q5, \"\\n\")\n",
    "print(predicted_q6, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pearson_spearman_corr(preds_q1, avg_q1, preds_q2, avg_q2, preds_q3, avg_q3, preds_q4, avg_q4, preds_q5, avg_q5, preds_q6, avg_q6):\n",
    "    print(\"PEARSON CORRELATION:\")\n",
    "    print(\"Q1:\")\n",
    "    rho, p = pearsonr(preds_q1, avg_q1)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q2:\")\n",
    "    rho, p = pearsonr(preds_q2, avg_q2)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q3:\")\n",
    "    rho, p = pearsonr(preds_q3, avg_q3)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q4:\")\n",
    "    rho, p = pearsonr(preds_q4, avg_q4)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q5:\")\n",
    "    rho, p = pearsonr(preds_q5, avg_q5)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q6:\")\n",
    "    rho, p = pearsonr(preds_q6, avg_q6)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"SPEARMAN CORRELATION:\")\n",
    "    print(\"Q1:\")\n",
    "    rho, p = spearmanr(preds_q1, avg_q1)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q2:\")\n",
    "    rho, p = spearmanr(preds_q2, avg_q2)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q3:\")\n",
    "    rho, p = spearmanr(preds_q3, avg_q3)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q4:\")\n",
    "    rho, p = spearmanr(preds_q4, avg_q4)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q5:\")\n",
    "    rho, p = spearmanr(preds_q5, avg_q5)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Q6:\")\n",
    "    rho, p = spearmanr(preds_q6, avg_q6)\n",
    "    print(\"Rho = \", rho)\n",
    "    print(\"p = \", p)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEARSON CORRELATION:\n",
      "Q1:\n",
      "Rho =  -0.05462842470431956\n",
      "p =  0.5931655956007832\n",
      "\n",
      "\n",
      "Q2:\n",
      "Rho =  0.006505118409748642\n",
      "p =  0.953456882222216\n",
      "\n",
      "\n",
      "Q3:\n",
      "Rho =  0.12035278408675669\n",
      "p =  0.25580698387456907\n",
      "\n",
      "\n",
      "Q4:\n",
      "Rho =  0.06593054455671633\n",
      "p =  0.4897743833181122\n",
      "\n",
      "\n",
      "Q5:\n",
      "Rho =  0.059057722312233885\n",
      "p =  0.5574405295094135\n",
      "\n",
      "\n",
      "Q6:\n",
      "Rho =  nan\n",
      "p =  nan\n",
      "\n",
      "\n",
      "SPEARMAN CORRELATION:\n",
      "Q1:\n",
      "Rho =  -0.054628424704319715\n",
      "p =  0.593165595600782\n",
      "\n",
      "\n",
      "Q2:\n",
      "Rho =  0.0242753059693034\n",
      "p =  0.8275564053321658\n",
      "\n",
      "\n",
      "Q3:\n",
      "Rho =  0.1317974756233523\n",
      "p =  0.21301119507458474\n",
      "\n",
      "\n",
      "Q4:\n",
      "Rho =  0.07367642766150788\n",
      "p =  0.4401020765307063\n",
      "\n",
      "\n",
      "Q5:\n",
      "Rho =  0.059057722312233885\n",
      "p =  0.5574405295094149\n",
      "\n",
      "\n",
      "Q6:\n",
      "Rho =  nan\n",
      "p =  nan\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsantra/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/bsantra/miniconda3/envs/dialog-systems/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4878: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    }
   ],
   "source": [
    "preds_q1 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
    "avg_q1 = labels_q1\n",
    "preds_q2 = [3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "avg_q2 = labels_q2\n",
    "preds_q3 = [3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 2, 1, 1, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "avg_q3 = labels_q3\n",
    "preds_q4 = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] \n",
    "avg_q4 = labels_q4\n",
    "preds_q5 = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0] \n",
    "avg_q5 = labels_q5\n",
    "preds_q6 = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4] \n",
    "avg_q6 = labels_q6\n",
    "\n",
    "get_pearson_spearman_corr(preds_q1, avg_q1, preds_q2, avg_q2, preds_q3, avg_q3, preds_q4, avg_q4, preds_q5, avg_q5, preds_q6, avg_q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Context:\n",
      "Person 1: hello, how are you this evening? do you like sports? \n",
      "Person 2:  i m great, and yeah i do like to watch sports, basketball, hockey, soccer and even swimming, what about you? \n",
      "\n",
      "Generated response: \n",
      "Person 1: i do not but i am more into swimming myself. i don't like sports, but i do know there are some really boring swimming competitions\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Interesting (dull/somewhat interesting/interesting): Is the response dull or interesting?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Context:\n",
      "Person 1:  right? i wonder if they have cricket cards lol? i think they have stickers for soccer. \n",
      "Person 2:  some guy found $ 3 million dollars of baseball cards from the 1900s. i wonder what he did with the money. \n",
      "Person 1:  yeah. that's an amazing find. i heard they had been hidden since the 40s. \n",
      "Person 2:  thanks, grandpa! i bet grandpa wishes he had cashed them in before he cashed out. \n",
      "\n",
      "Generated response: \n",
      "Person 1: well, but time probably added to the value, no? i wonder if the grandson found a honus wagner. isn't that the super valuable one? in the 90s i think wayne gretzky bought one as an investment.\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Interesting (dull/somewhat interesting/interesting): Is the response dull or interesting?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Context:\n",
      "Person 1:  that's interesting. i would be curious. there is only 2 african americans in the country music hall of fame. i wonder who they are? \n",
      "Person 2:  i'm not sure either. i don't recall any african american artists in country music. do you know what the fender stratocaster is? \n",
      "Person 1:  i remember charley pride. he might be one.... and yes! it's a guitar. i think a lot jazz and some blues musicians use it. \n",
      "Person 2:  oh! fender, i see that now! thanks for clarifying! do you play any instruments? \n",
      "\n",
      "Generated response: \n",
      "Person 1: i do love the guitar. did you know u2 opened for themselves?\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Interesting (dull/somewhat interesting/interesting): Is the response dull or interesting?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Context:\n",
      "Person 1:  hi there! i do! i love watching the olympic events. how about you? \n",
      "Person 2:  same here. i do not swim that much but i occasionally go to the pool every once and a while. i also enjoy watching swimming in the olympics ; \n",
      "Person 1:  did you know cornell students are actually required to pass a basic swim test before they can graduate? \n",
      "Person 2:  i think that that is a good idea! native americans also introduced the british to the front crawl. \n",
      "\n",
      "Generated response: \n",
      "Person 1: that is pretty cool. i wonder if they ever used the breaststroke before they beat the british who only used the breaststroke?\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Understandable (no/yes): Is the response understandable given the previous context?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Context:\n",
      "Person 1:  that is odd. so what do you think of trump. \n",
      "Person 2:  i like trump \n",
      "Person 1:  me too. i think he needs to calm down a little bit sometimes but he is a smart dude. \n",
      "Person 2:  yeah i never liked trump before he was president. i think he's doing a great job with all that he's been dealt. \n",
      "\n",
      "Facts:\n",
      "there hasn't been a us president who wasn't a republican or a democrat since 1853\n",
      "\n",
      "Generated response: \n",
      "Person 1: trump is a republican. did you know there has nt been a president who was nt a republican or democrat since 1853\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Uses Knowledge (no/yes): Given the facts that the response is conditioned on, does the response use the facts?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Context:\n",
      "Person 1:  crazy! do you like books? when you zoom into the white house on google maps you can see barack obama \n",
      "Person 2:  really? i like books a bunch but like exercise too. reading is a complex brain process decoding symbols into meaning when you think about it. challenging for some. \n",
      "Person 1:  do u speed read? the world record for speed reading is held by anne jones, with a reading speed of 4,700 words per minute \n",
      "Person 2:  not really, but i'm pretty fast so maybe?? i wouldn't know how you tell. reading can be an escape for some but different for different people how they see things or don't see things \n",
      "\n",
      "Facts:\n",
      "cs lewis and tolkien held \" you laugh you lose \" competitions when reading terrible poetry\n",
      "\n",
      "Generated response: \n",
      "Person 1: i agree. i wonder if the world record holder for speed reading comprehension\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Overall Quality (very bad/bad/neutral/good/very good): What is your overall impression of the quality of the generated response?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Context:\n",
      "Person 1:  yeah apparently him and pocahontas were a live at the same time. \n",
      "Person 2:  pocahontas was a real person? i though she was a character in a movie, turns out its based on a true story, \n",
      "Person 1:  yeah i know, right. well another one of his words is laughing stock, haha. \n",
      "Person 2:  yeah so do you like to dance? \n",
      "\n",
      "Generated response: \n",
      "Person 1: i do! i love shakespeare. i think he is a great actor and also a great writer\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Understandable (no/yes): Is the response understandable given the previous context?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Context:\n",
      "Person 1:  it's very interesting. so is the fact that the sun is 4x less dense than earth. \n",
      "Person 2:  i know it is much larger but i don't think it has any solidity to it so that's interesting. another science fact is that when earth was formed a day was only 5.5 hours long. \n",
      "Person 1:  i didn't know that. i wonder why. there is a place on earth where there is less gravity than the rest of the planet. it is the hudson bay region of canada. \n",
      "Person 2:  i wonder how much affect that has? is it enough to change weights in any way? i wonder. i do also know that we are running out of helium and will essentially be out of the gas by the end of the 21st century. \n",
      "\n",
      "Facts:\n",
      "new google employees are called'nooglers'and are given a propeller beanie cap to wear on their first friday.\n",
      "\n",
      "Generated response: \n",
      "Person 1: i'm not sure. i wonder if the employees who wear propeller cap is called nooglers?\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Uses Knowledge (no/yes): Given the facts that the response is conditioned on, does the response use the facts?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Context:\n",
      "Person 1: hello did you know that 80 percent of the earths natural forests have already been destroyed? \n",
      "Person 2:  i heard it but i'm skeptical. that sounds far too high and what's the definition of \" natural. \n",
      "Person 1:  not sure in this case. when the earth was formed the days were only 5.5 hours long! \n",
      "Person 2:  that was 5.5 hours of sunlit hell in magma and lava. bummer, they are saying we will be out of helium by the end of the century. \n",
      "\n",
      "Facts:\n",
      "if earth s entire history was viewed as a 24 hour period, humans would only represent 1 minute and 17 seconds.\n",
      "\n",
      "Generated response: \n",
      "Person 1: wow, i can't believe we're destroying the world. if we viewed the earth's history as a 24 hour period, humans would only have existed for 1 minute and 17 seconds. and in that time, we've managed to completely destroy the planet.\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Overall Quality (very bad/bad/neutral/good/very good): What is your overall impression of the quality of the generated response?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "Context:\n",
      "Person 1:  i love football both college and nfl, do you have a favorite nfl team of the 32? \n",
      "Person 2:  i'm a new england patriots fan and huge fan of tom brady how about you? \n",
      "Person 1:  nice i am a vikings fan, not doing so hot as of late. i also like the university of iowa hawkeyes, did you know they paint their opponents locker room pink? \n",
      "Person 2:  no i didn't know this. did you know that in the 60's top bowlers made twice as much as the top football players? \n",
      "\n",
      "Facts:\n",
      "- that the highest score ever in a football game occurred in 1916 when georgia tech defeated cumberland 222 - 0\n",
      "\n",
      "Generated response: \n",
      "Person 1: yeah, that is crazy. i would think bowling would have too much more. i think that might be why they would do it on tv like college or something, but the way it was a very different back then, like 222 - 0 haha.\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Overall Quality (very bad/bad/neutral/good/very good): What is your overall impression of the quality of the generated response?\n",
      "\n",
      "Answers: \n",
      "1. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    print(test_lines[i])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " good\n"
     ]
    }
   ],
   "source": [
    "line = test_lines[9]\n",
    "tokenized = tokenizer(line)\n",
    "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
    "if len(input_ids[0]) < 1000:\n",
    "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
    "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0].replace(line, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-Lr4gEjsC13",
    "outputId": "0236dd88-a8e3-4f75-f755-276681f645ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2-medium\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 1024,\n",
      "  \"n_special\": 0,\n",
      "  \"pad_token_id\": 50258,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading weights file gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-tc-medium-lm-lr1e-05-bs10-ne4/checkpoint-46.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = f'gpt2-tc-medium-lm-lr{lr}-bs{bs}-ne{ne}/checkpoint-46'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
    "# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
    "# Resize the token embeddings because we've just added 3 new tokens \n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmIOa_VMPDJD",
    "outputId": "31515e3c-336c-4760-ae10-bf378da9f4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Person 1:  the guy is a machine! but he needs a better stage name. maybe president banana? \n",
      "Person 2:  i do not think the president of zimbabwe would be happy about that \n",
      "Person 1:  he could be the artist formerly known as president banana? i don't really care as long as i can listen to him on the radio! i love two things on my radio : indonesian pop music and electromagnetic storms from jupiter. those are my go to listening pleasures! \n",
      "Person 2:  yeah that is so cool that if you turn your radio to am, you may capture jupiter's storms \n",
      "\n",
      "Generated response: \n",
      "Person 1: that might be banned in canada. the law says that all stations must have 40 % of the music played be canadian!\n",
      "\n",
      "Questions about the generated response:\n",
      "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
      "\n",
      "Answers:\n",
      "1. 1\n"
     ]
    }
   ],
   "source": [
    "each = \"\"\"Context:\n",
    "Person 1:  the guy is a machine! but he needs a better stage name. maybe president banana? \n",
    "Person 2:  i do not think the president of zimbabwe would be happy about that \n",
    "Person 1:  he could be the artist formerly known as president banana? i don't really care as long as i can listen to him on the radio! i love two things on my radio : indonesian pop music and electromagnetic storms from jupiter. those are my go to listening pleasures! \n",
    "Person 2:  yeah that is so cool that if you turn your radio to am, you may capture jupiter's storms \n",
    "\n",
    "Facts:\n",
    "according to canadian law, all radios are required to have at least 40 % of the music played be canadian.\n",
    "\n",
    "Generated response: \n",
    "Person 1: that might be banned in canada. the law says that all stations must have 40 % of the music played be canadian!\n",
    "\n",
    "Questions about the generated response:\n",
    "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
    "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
    "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
    "4. Interesting (1 - 3): Is the response dull or interesting?\n",
    "5. Uses Knowledge (0 - 1): Given the facts that the response is conditioned on, how well does the response use the facts?\n",
    "6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "tokenized = tokenizer(each)\n",
    "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
    "if len(input_ids[0]) < 1000:\n",
    "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
    "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "lYwqK4VSdE-7",
    "outputId": "91147a3b-28c8-4f0c-daee-8db3ced709d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:\\n1. 1\\n2. 2\\n3. 2\\n4. 3\\n5. 1\\n6. 4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tc_train_dataset[0][0], skip_special_tokens=True)[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "oD198sdYcThx",
    "outputId": "168da023-6fd3-4461-fba2-32fa5340e120"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'e is conditioned on, how well does the response use the facts?\\n6. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of the generated response?\\n\\nAnswers:'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_unlabelled_test[0][-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wIlq-ROIYFU"
   },
   "outputs": [],
   "source": [
    "tc_test_dataset = tc_unlabelled_test\n",
    "for i, each in enumerate(tc_test_dataset):\n",
    "    # print(each)\n",
    "    tokenized = tokenizer(each + \"\\n\")\n",
    "    input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
    "    input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "    if len(input_ids[0]) < 1000:\n",
    "        generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=3, temperature=0.1)\n",
    "        print(f\"\\nnum = {i}\")\n",
    "        print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0].replace(input_text, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYUmEFNS2-Me",
    "outputId": "35f283fd-caef-401a-f4fb-7923927d9083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "num = 0\n",
      "1. 1\n",
      "\n",
      "num = 1\n",
      "1. 1\n",
      "\n",
      "num = 2\n",
      "1. 1\n",
      "\n",
      "num = 3\n",
      "1. 1\n",
      "\n",
      "num = 4\n",
      "1. 1\n",
      "\n",
      "num = 5\n",
      "1. 1\n",
      "\n",
      "num = 6\n",
      "1. 1\n",
      "\n",
      "num = 7\n",
      "1. 1\n",
      "\n",
      "num = 8\n",
      "1. 1\n",
      "\n",
      "num = 9\n",
      "1. 1\n",
      "\n",
      "num = 10\n",
      "1. Understand (0 - 1): Is the response understandable given the previous context?\n",
      "\n",
      "num = 11\n",
      "1. 1\n",
      "\n",
      "num = 12\n",
      "1. 1\n",
      "\n",
      "num = 13\n",
      "1. Understand (0 - 1): Is the response understandable given the previous?\n",
      "\n",
      "num = 14\n",
      "1. 1\n",
      "\n",
      "num = 15\n",
      "1. 1\n",
      "\n",
      "num = 16\n",
      "1. 1\n",
      "\n",
      "num = 17\n",
      "1. 1\n",
      "\n",
      "num = 18\n",
      "1. 1\n",
      "\n",
      "num = 19\n",
      "1. 1\n",
      "\n",
      "num = 20\n",
      "1. 1\n",
      "\n",
      "num = 21\n",
      "1. 1\n",
      "\n",
      "num = 22\n",
      "1. 1\n",
      "\n",
      "num = 23\n",
      "1. 1\n",
      "\n",
      "num = 24\n",
      "1. 1\n",
      "\n",
      "num = 25\n",
      "1. 1\n",
      "\n",
      "num = 26\n",
      "1. 1\n",
      "\n",
      "num = 27\n",
      "1. 1\n",
      "\n",
      "num = 28\n",
      "1. 1\n",
      "\n",
      "num = 29\n",
      "1. Understand (0 - 1): Is the response understandable given the previous?\n",
      "\n",
      "num = 30\n",
      "1. 1\n",
      "\n",
      "num = 31\n",
      "1. 1\n",
      "\n",
      "num = 32\n",
      "1. Understand (0 - 1): Is the response understandable given the previous context?\n",
      "\n",
      "2 (1 - 3): Does the response seem like something?\n",
      " (1 - 3)\n",
      "\n",
      "3. Natural ( 1 - 3): Does the response seem like something?\n",
      " (1 1 - 3)\n",
      " (1 - 3)\n",
      "\n",
      "num = 33\n",
      "1. 1\n",
      "\n",
      "num = 34\n",
      "1. 1\n",
      "\n",
      "num = 35\n",
      "1. 1\n",
      "\n",
      "num = 36\n",
      "1. 1\n",
      "\n",
      "num = 37\n",
      "1. 1\n",
      "\n",
      "num = 38\n",
      "1. 1\n",
      "\n",
      "num = 39\n",
      "1. 1\n",
      "\n",
      "num = 40\n",
      "1. 1\n",
      "\n",
      "num = 41\n",
      "1. 1\n",
      "\n",
      "num = 42\n",
      "1. 1\n",
      "\n",
      "num = 43\n",
      "1. 1\n",
      "\n",
      "num = 44\n",
      "1. 1\n",
      "\n",
      "num = 45\n",
      "1. 1\n",
      "\n",
      "num = 46\n",
      "1. 1\n",
      "\n",
      "num = 47\n",
      "1. 1\n",
      "\n",
      "num = 48\n",
      "1. 1\n",
      "\n",
      "num = 49\n",
      "1. 1\n",
      "\n",
      "num = 50\n",
      "1. 1\n",
      "\n",
      "num = 51\n",
      "1. 1\n",
      "\n",
      "num = 52\n",
      "1. 1\n",
      "\n",
      "num = 53\n",
      "1. Understand (0 - 1): Is the response understandable given the previous context?\n",
      "\n",
      "2 (1): Is the response understandable given the previous context?\n",
      " (1): Is the response understandable given the previous context?\n"
     ]
    }
   ],
   "source": [
    "#### UNDERSTANDABLE ####\n",
    "tc_test_dataset = tc_unlabelled_test\n",
    "for i, each in enumerate(tc_test_dataset):\n",
    "    # print(each)\n",
    "    tokenized = tokenizer(each + \"\\n\")\n",
    "    input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
    "    input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "    if len(input_ids[0]) < 1000:\n",
    "        generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=3, temperature=0.1)\n",
    "        print(f\"\\nnum = {i}\")\n",
    "        print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0].replace(input_text, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zlv1pLA_ubRQ",
    "outputId": "16834113-5d0e-4431-9cc9-8787b2d3db96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey theres\n"
     ]
    }
   ],
   "source": [
    "str1 = \"hey there\"\n",
    "tokenized = tokenizer(str1)\n",
    "input_ids = torch.tensor([tokenized.input_ids]).to(device)\n",
    "generation = model.generate(input_ids, do_sample=False, max_new_tokens=100, num_beams=5)\n",
    "print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pmHEgrOy6Hr"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([test_dataset[0][0].tolist()]).to(device)\n",
    "if len(input_ids[0]) < 1000:\n",
    "    generation = model.generate(input_ids, do_sample=False, max_new_tokens=24, num_beams=5)\n",
    "    print(tokenizer.batch_decode(generation, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btRopY8m1QSa",
    "outputId": "b603d1e1-b070-448c-9b96-578c1380d9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|> Human Evaluation of Chatbot Outputs:\n",
      "\n",
      "Annotation Instructions: \n",
      "You will be given a conversation between two individuals. You will then be given a potential chatbot-generated response for the next turn in the conversation. Your task is to rate the response on several metrics. The response for one metric should not influence other metrics. For example, if a response is not understandable or has grammatical errors - you should try to ignore this when considering whether it maintains context or if it is interesting.\n",
      "The following are the metrics and corresponding rating scales that each response is required to be rated on:\n",
      "Understandable (0 - 1): Is the response understandable in the context of the history? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say. A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.\n",
      "Natural (1 - 3): Is the response naturally written? A score of 1 (bad) means that the response is unnatural. A score of 2 (ok) means the response is strange, but not entirely unnatural. A response of 3 (good) means that the response is natural.\n",
      "Maintains Context (1 - 3): Does the response serve as a valid continuation of the conversation history? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history. A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g.,in a generic way) and shifts the conversation topic. A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.\n",
      "Interesting (1 - 3): Is the response dull/interesting? A score of 1 (dull) means that the response is generic and dull. A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought). A score of 3 (interesting) means the response is very interesting or presents an interesting fact.\n",
      "Overall Quality (1 - 5): Given your answers above, what is your overall impression of this utterance? A score of 1 (very bad) means the response is completely invalid, and it would be difficult to recover the conversation after this. A score of 2 (bad) means that the response is valid, but otherwise poor in quality. A score of 3 (neutral) means the response is neither good nor bad, and has no negative qualities, but no positive ones either. A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw. A score of 5 (very good) means this response is good and does not have any strong flaws.\n",
      "\n",
      "\n",
      "Context:\n",
      "Person 1:  i did see the movie, i thought it was bad as well, i liked the book better, i like reading you can learn many interesting facts, like why the area code of new york is 212. \n",
      "Person 2:  ya i think it was because that was the fastest number that you could dial with a rotary phone? crazy how that stuff carries over until even today!! \n",
      "Person 1:  it is! there s a lot things we need to discover still though, i'm kind of worried the cables carrying phone and internet are underwater, at least some of them. \n",
      "Person 2:  ya it's only about 3 inches thick, i wonder how it is protected? is it just a cable or are there safeguards in place in case like a ship sinks and crushes it, etc \n",
      "\n",
      "Generated response: \n",
      "Agent: i think that is a good idea, i think it would be a great idea to put flamethrowers on the back of cars in south africa\n",
      "\n",
      "Questions about the agent's response:\n",
      "1. Understandable (0 - 1): Is the response understandable given the previous context?\n",
      "2. Natural (1 - 3): Does the response seem like something that a person would naturally say?\n",
      "3. Maintains Context (1 - 3): Does the response serve as a valid continuation of the preceding conversation?\n",
      "4. Interesting (1 - 3): Is the response dull or interesting?\n",
      "5. Overall Quality (1 - 5): Given your answers above, what is your overall impression of the quality of this utterance?\n",
      "\n",
      "Answers:\n",
      "1. Understandable: 0\n",
      "2. Natural: 2\n",
      "3. Maintains Context: 1\n",
      "4. Interesting: 2\n",
      "5. Overall Quality: 2<|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(test_dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1rBCbBzbpiu"
   },
   "outputs": [],
   "source": [
    "for each in test_dataset:\n",
    "    input_ids = torch.tensor([each[0].tolist()]).to('cuda')\n",
    "    if len(input_ids[0]) < 1000:\n",
    "        outputs = model.generate(input_ids, do_sample=False, max_new_tokens=24, num_beams=5)\n",
    "        print(str(tokenizer.decode(input_ids[0])))\n",
    "        model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        print(model_response)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(len(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk5JXW4ntE2j"
   },
   "outputs": [],
   "source": [
    "tokenized['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmkS1KZMrJgB"
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# prompt = \"hey there\"\n",
    "# tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
    "# input_ids = tokenized['input_ids'].to('cuda')\n",
    "\n",
    "outputs = model.generate(torch.tensor([test_dataset[0][0].tolist()]).to('cuda'), do_sample=False, max_new_tokens=100, num_beams=5)\n",
    "print(\"Prompt: \" + str(tokenizer.decode(input_ids[0])))\n",
    "model_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "# feedback_starts = model_response.find(\"Feedback: \")\n",
    "print(\"Model Response: \" + model_response)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avR-qFFKtCCJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMJBxSuUDyJYzQK5HNQlQMS",
   "collapsed_sections": [
    "WOo3yMBdBiMc",
    "3YN57Ed3zfwA",
    "SCb0yf9Fyzya"
   ],
   "include_colab_link": true,
   "mount_file_id": "1fqofXKvH9-oVoTzpixyuGDIP-9czb_aZ",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ddd9f605a64c1ba2d7a7eb415a630e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1049bc8923e4419a8ee59d1d455599af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea382ab4622f495094a40e02eed3e4ae",
      "placeholder": "",
      "style": "IPY_MODEL_b290356d9fe84264af97be2da3dc1b08",
      "value": " 1.52G/1.52G [00:30&lt;00:00, 55.1MB/s]"
     }
    },
    "14b1ace190e94d9882ad752e5840983c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9475c60459ba417eae3f27b2f514df41",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_390591739f4a45479de9854efcce4b84",
      "value": 1042301
     }
    },
    "14eae0a060b3450dab363d8522c835da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f16de126b68547ff8b0e9ee412375369",
      "placeholder": "",
      "style": "IPY_MODEL_a6caeb338c8b4d66b5ec2eb013649a93",
      "value": "Downloading: 100%"
     }
    },
    "179d08c447cd484ba2bba7998ce77b7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b1373fb25f3422bba527684d6481c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ef32dbc999e45e8b3b0d3c325aad241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97ba8889cc704a169a0cc5c38bab163e",
      "placeholder": "",
      "style": "IPY_MODEL_45f92ddf47f942d19917dd7dead25f38",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 2.94MB/s]"
     }
    },
    "244f2ce637ce4c9e992ef7fbdae29b2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2636c624a2c3432092c2ccfcaf0603e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e6dd9a9379144119e079c4fc7d9ee64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307d499b9fb04f9eac6966f5d9875b4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84ee9778c41a4c81b5d802d9e3f692a4",
      "placeholder": "",
      "style": "IPY_MODEL_244f2ce637ce4c9e992ef7fbdae29b2c",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 5.88MB/s]"
     }
    },
    "333b1bcae55d4f1299dcf58442e6ab28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2cbb330da034a47b32fa4dac818fd9c",
      "placeholder": "",
      "style": "IPY_MODEL_1b1373fb25f3422bba527684d6481c45",
      "value": "Downloading: 100%"
     }
    },
    "33c7841c474444f68db828cff78c4151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "390591739f4a45479de9854efcce4b84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c47249c03a74b2d90fa37e03f202c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14eae0a060b3450dab363d8522c835da",
       "IPY_MODEL_6b0c15beeb424103805d5c077bfa790e",
       "IPY_MODEL_1049bc8923e4419a8ee59d1d455599af"
      ],
      "layout": "IPY_MODEL_9082f05fd0094172bd827454471c98f6"
     }
    },
    "3f4a92d3d1554ba4a6fdfb9a440585b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f92ddf47f942d19917dd7dead25f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dac7b069cd341a592a85c58195e799b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e6dd9a9379144119e079c4fc7d9ee64",
      "placeholder": "",
      "style": "IPY_MODEL_7497fef7647e44cda15d6a1ee7162cff",
      "value": "Downloading: 100%"
     }
    },
    "5160ca7fca294cb2808cf79c3b1c1ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b2cd074d114c9fa16b8e2d983a6011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_333b1bcae55d4f1299dcf58442e6ab28",
       "IPY_MODEL_5866b713c4694746abe5bd203189f1dd",
       "IPY_MODEL_307d499b9fb04f9eac6966f5d9875b4a"
      ],
      "layout": "IPY_MODEL_2636c624a2c3432092c2ccfcaf0603e6"
     }
    },
    "564bf6e7a4dd45f98574bd7b5711fbfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dac7b069cd341a592a85c58195e799b",
       "IPY_MODEL_14b1ace190e94d9882ad752e5840983c",
       "IPY_MODEL_1ef32dbc999e45e8b3b0d3c325aad241"
      ],
      "layout": "IPY_MODEL_dad7aab67309470ea012e445557293bc"
     }
    },
    "5866b713c4694746abe5bd203189f1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74528482b74d4360a81ea060a3a12583",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7bb31ebaf23a4d8586073a2de456df2a",
      "value": 1355256
     }
    },
    "59fd10d3d2644ee0bece610f0d1d7d7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01ddd9f605a64c1ba2d7a7eb415a630e",
      "placeholder": "",
      "style": "IPY_MODEL_33c7841c474444f68db828cff78c4151",
      "value": "Downloading: 100%"
     }
    },
    "6b0c15beeb424103805d5c077bfa790e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2bf7d0d2f85489c8e8727896ed6eb35",
      "max": 1520013706,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e097880aab944e5286abd4087b9a7581",
      "value": 1520013706
     }
    },
    "6f3cd3eaf9184faea6a7da918ce5ad19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f4a92d3d1554ba4a6fdfb9a440585b2",
      "placeholder": "",
      "style": "IPY_MODEL_d59c75d2075347c1a877def8d3623dd5",
      "value": " 456k/456k [00:00&lt;00:00, 2.53MB/s]"
     }
    },
    "74528482b74d4360a81ea060a3a12583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7497fef7647e44cda15d6a1ee7162cff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bb31ebaf23a4d8586073a2de456df2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c3843bf14b84b098a001d3a3a162472": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f3ae46c89c44a7d9b35d21f7fe61db4",
      "max": 718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e33ac1b3c9844dd9e22c8d593bccd3f",
      "value": 718
     }
    },
    "7f3ae46c89c44a7d9b35d21f7fe61db4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84ee9778c41a4c81b5d802d9e3f692a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b04d790167b486d98b4a29cf86799e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ff5d8e3fb2a4056ad4a829ffd856e90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9082f05fd0094172bd827454471c98f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9475c60459ba417eae3f27b2f514df41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97ba8889cc704a169a0cc5c38bab163e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d7f86b822864828a769e2948725d33e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f6c37d44c0e4501b672185bafd91ce5",
      "placeholder": "",
      "style": "IPY_MODEL_179d08c447cd484ba2bba7998ce77b7e",
      "value": " 718/718 [00:00&lt;00:00, 8.56kB/s]"
     }
    },
    "9e33ac1b3c9844dd9e22c8d593bccd3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f6c37d44c0e4501b672185bafd91ce5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a039e29c0e3f46e989509a5749f0dd3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6caeb338c8b4d66b5ec2eb013649a93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b290356d9fe84264af97be2da3dc1b08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2bf7d0d2f85489c8e8727896ed6eb35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b414398958934630a1f07430acdeafa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59fd10d3d2644ee0bece610f0d1d7d7d",
       "IPY_MODEL_7c3843bf14b84b098a001d3a3a162472",
       "IPY_MODEL_9d7f86b822864828a769e2948725d33e"
      ],
      "layout": "IPY_MODEL_5160ca7fca294cb2808cf79c3b1c1ac7"
     }
    },
    "b63e314272dd46e1bd0d4af5e43bdda5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b04d790167b486d98b4a29cf86799e8",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bac90dabd8d04784b8865292c6eee401",
      "value": 456318
     }
    },
    "bac90dabd8d04784b8865292c6eee401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d59c75d2075347c1a877def8d3623dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7720c56e12a47458676ff74ba9e57d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dad7aab67309470ea012e445557293bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddd8acb558a54845a2c7d52107017ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7720c56e12a47458676ff74ba9e57d4",
      "placeholder": "",
      "style": "IPY_MODEL_8ff5d8e3fb2a4056ad4a829ffd856e90",
      "value": "Downloading: 100%"
     }
    },
    "e097880aab944e5286abd4087b9a7581": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0e2e8fe2ca2456d9aeb0d3d153d1a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddd8acb558a54845a2c7d52107017ac4",
       "IPY_MODEL_b63e314272dd46e1bd0d4af5e43bdda5",
       "IPY_MODEL_6f3cd3eaf9184faea6a7da918ce5ad19"
      ],
      "layout": "IPY_MODEL_a039e29c0e3f46e989509a5749f0dd3e"
     }
    },
    "ea382ab4622f495094a40e02eed3e4ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f16de126b68547ff8b0e9ee412375369": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2cbb330da034a47b32fa4dac818fd9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
